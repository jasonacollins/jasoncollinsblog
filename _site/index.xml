<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Jason Collins blog</title>
<link>https://www.jasoncollins.blog/</link>
<atom:link href="https://www.jasoncollins.blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Behavioural economics, data science and artificial intelligence.</description>
<generator>quarto-1.7.23</generator>
<lastBuildDate>Fri, 05 Sep 2025 06:00:00 GMT</lastBuildDate>
<item>
  <title>A week of links</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/a-week-of-links-107.html</link>
  <description><![CDATA[ 




<p>This week, language, language models and replication:</p>
<ol type="1">
<li><p><a href="https://www.neelnanda.io/mechanistic-interpretability/getting-started">How To Become A Mechanistic Interpretability Researcher</a>: So much great material in here, even if you’re just interested in getting across LLM foundations.</p></li>
<li><p>From that list, <a href="https://www.arena.education/curriculum">ARENA’s AI Safety course</a> is fantastic - again, even if you are just interested in LLM foundations.</p></li>
<li><p><a href="https://pair.withgoogle.com/explorables/grokking/">Do Machine Learning Models Memorize or Generalize?</a>: A great explainer on grokking.</p></li>
<li><p>After hearing it mentioned on <a href="https://www.dwarkesh.com/p/sholto-douglas-trenton-bricken">Dwarkesh’s podcast episode</a> with Sholto Douglas and Trenton Bricken, I’ve been reading <a href="https://www.dwarkesh.com/p/symbolic-species">The Symbolic Species by Terrence Deacon</a>. I’ve learnt a lot about language, although I must admit that my eyes glaze over (as always) during the extended discussion of brain parts. Definitely worth the read (and listen to the podcast episode too).</p></li>
<li><p><a href="https://www.cambridge.org/core/journals/judgment-and-decision-making/article/on-the-process-and-value-of-direct-close-replications-a-rejoinder-to-shafir-and-cheeks-2024-commentary-on-chandrashekar-et-al-2021/024729A4F4D39748587CEEFC1F5C327C">On the process and value of direct close replications: A rejoinder to Shafir and Cheek’s (2024) commentary on Chandrashekar et al.&nbsp;(2021)</a>: So often failures to replicate experimental results are met with a load of waffle about context, precise experimental conduct and the like. Shafir and Cheek provided one such example. Chandrashekar and Gilad Feldman provide a fantastic response.</p></li>
</ol>



 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/a-week-of-links-107.html</guid>
  <pubDate>Fri, 05 Sep 2025 06:00:00 GMT</pubDate>
</item>
<item>
  <title>Why I don’t trust most human-AI interaction experimental research</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/why-i-dont-trust-most-human-ai-interaction-experimental-research.html</link>
  <description><![CDATA[ 




<p>Experimental psychology research before the mid-2010s was a mess. The field was littered with papers with weak to non-existent theoretical foundations. Experimental data was unavailable. (The statement “data is available on request” is <a href="https://osf.io/preprints/psyarxiv/jbu9r_v1">somewhat of a joke</a>.) The experiments involved small samples and barely significant p-values. File drawers were overflowing with the carcasses of experiments that didn’t quite get the result hoped for. The <a href="https://sites.stat.columbia.edu/gelman/research/unpublished/p_hacking.pdf">forking paths</a> in the data analysis allowed multiple shots at goal.</p>
<p>Those poor practices were most starkly revealed with the publication of the Open Science Collaboration’s <a href="https://doi.org/10.1126/science.aac4716">review</a> of the replicability of psychological science. 36% of psychology papers replicated. The stream of failed replications continues.</p>
<p>Today, however, things look better, at least methodologically. Pre-registration and open experimental materials and data are becoming common, if not required. Many journals and reviewers take these elements as table stakes for publication. Registered reports are now an option. Theory is still often weak and those file drawers remain full, but at least the presence of preregistration repositories gives us a sense of what is in them. PNAS and other tabloids continue to be PNAS, but don’t hope for miracles.</p>
<p>Psychology was, of course, not the only field to suffer a replication crisis and shift practices. Experimental economics has improved, despite coming through the crisis less tarnished than psychology. Many fields and the associated journals have adopted open science practices. If an experimental field hasn’t adjusted its practices in the last decade you need to question what is going on.</p>
<p>Which brings me to my experience in the human-AI and human-computer interaction literature. This literature largely concerns how we get better decisions or actions when people interact with AI, algorithms and other automated decision rules. How do we get people to use beneficial AI? How do we get “complementary performance”, where the performance of the human-AI combination is better than the human or AI by themselves? How do we help calibrate user trust in AI tools?</p>
<p>I’ve been writing and thinking about the topic for close to a decade now. My first article in Behavioural Scientist (<a href="https://behavioralscientist.org/dont-touch-computer/">Don’t Touch The Computer</a>) argued that often we should take the human out of the loop. In the last year or so I’ve been working on how to use AI in improving financial decision making. I’ve read 100s of experimental papers in the field looking for ideas and evidence.</p>
<p>What I have seen is depressing. I hoped to find a field that had learned from psychology’s mistakes. Instead I found a field operating as if the replication crisis never happened. Weak theory. Negligible pre-registration. Forking paths. Underpowered experiments. The data is unavailable. (Less than 10% of papers I have read have data openly available in a repository.) Typically, there isn’t even a statement that data is available on request. The experimental materials are often well described in the paper - many human-AI interaction papers have quite novel models and software interfaces - but the detail isn’t sufficient for you to construct the models or software yourself. And this isn’t an old problem. These are papers from the last decade, some even from this year. There are exceptions and a few great papers, but I can’t see any trend in the right direction.</p>
<p>I’m always looking for new ideas for practical application. And a first step in that process is replication. Unfortunately, absent open data and experimental materials, we can’t reproduce or replicate the experiment. And when you look at the weak theory and forking paths in the analysis, it’s hard to give the result sufficient credence to the idea to test it in a lab or field context.</p>
<p>I’ve emailed a lot of authors asking for the experimental data and materials. In around 20% of cases, I’ve received an email in less than 24 hours with the materials, plus an offer to help if they could be useful. These are typically academics in economics, management and business schools who I suppose come from a culture where practices have changed. However, in most cases I simply haven’t received a response. Computer science and human-computer interaction researchers: it’s crickets.</p>
<p>Part of me wants to be understanding. They’re busy. Is it worth their taking their time to respond to a random from Australia who has written three sentences along the lines of “I like your paper/idea and am keen to replicate in a financial services context, can you share your data and materials”?</p>
<p>But on the other hand, they’ve gone to the effort to publish the paper (typically in a conference proceeding) and they want us to take their idea seriously. (Actually, maybe that’s not what they want. They just want the publication on their record and have moved on.) Unless their materials are a shambles, it should be minimal effort to share them. (If they don’t have it in a state to share, that’s another robustness flag.) The data is also of minimal sensitivity, involving bespoke abstract tasks in the lab. Post it to a public repository and you’re done with my and every following request.</p>
<p>There isn’t much encouragement for data sharing from the major publishing forums either. Here’s the data sharing policy of some of the conferences in human-AI interaction, the venues for many of the papers I have read:</p>
<blockquote class="blockquote">
<p><a href="https://chi2025.acm.org/for-authors/papers/">CHI conference on Human Factors in Computing Systems</a>: “Reproducibility: Where relevant, authors are strongly encouraged to provide supplementary materials to support practices around research reproducibility as much as possible. Please refer to the requirements for supplementary materials below.” They indicate how seriously they take it when the supplementary materials section is headed “Step 2. Prepare Supplementary Materials (Optional)”.</p>
</blockquote>
<blockquote class="blockquote">
<p><a href="https://neurips.cc/public/guides/CodeSubmissionPolicy">Conference on Neural Information Processing Systems (NeurIPS)</a>: “If any of the main contributions of your paper depends on an&nbsp;experimental result, you are strongly encouraged to submit code that produces this result. If you are using a&nbsp;new dataset, you are also encouraged to submit the dataset.”</p>
</blockquote>
<blockquote class="blockquote">
<p><a href="https://iui.acm.org/2025/call_for_papers.html">ACM Conference on Intelligent User Interfaces</a>: “Submitting supplemental material (e.g.&nbsp;questionnaires, demo videos of applications, data sheets) is optional but encouraged.”</p>
</blockquote>
<p>After a fair bit of digging, I did find the following <a href="https://www.acm.org/publications/policies/digital-artifacts">ACM policy</a> - it’s buried enough I expect most paper submitters wouldn’t even read it:</p>
<blockquote class="blockquote">
<p>Submission and Publication of Digital Artifacts as Supplemental Material</p>
<p>ACM does not require, but strongly recommends, that authors of ACM published Works provide access to the artifacts used to conduct research reported on in their published Works.</p>
</blockquote>
<p>I can tell from the lack of data for most experimental papers that this optionality is used by authors. Welcome to 2010.</p>
<p>So, is there a coming replication crisis for human-computer interaction?</p>
<p>Unfortunately, I don’t think so. When you need a bespoke machine learning algorithm or software interface, the replication simply isn’t going to happen. Although most psychology papers aren’t replicated, enough can be replicated at low cost to enable a view of the robustness of the field. I fear too many human-AI interaction papers exceed that cost threshold.</p>
<p>What I expect instead is filtering by practitioners. Many of the readers of the human-AI interaction literature, like me, are after practical solutions. Practitioners are going to filter the good from the bad, as what doesn’t work won’t get used. The A-B testing culture in AI and design teams allows that. I see the same thing in applied behavioural science (those few external readers of the psychology literature). There are a bunch of ideas that the applied community recognises as ineffective, despite there being no “failed” replication of the original experiment. We’d simply moved on. The “sign at the top” experiment was already dead among practitioners before the <a href="../posts/a-default-of-disbelief.html">failed replications and fraud emerged</a>.</p>
<p>In the longer term, I hope some decent practices will eventually filter into the field and we can simply forget about the current body of research. There are a few computer science academics that have open sourced their experimental setups on GitHub (thank you!) and made data available. Surely someone is paying attention and giving greater weight to their work. I am. There are also some platforms built for others to use, although there doesn’t seem to be much of a culture of using them yet. (Here’s <a href="https://github.com/gagb/caja">one</a> developed by Gagan Bansal and friends, as described in <a href="https://doi.org/10.1609/hcomp.v7i1.5285">this paper</a>.)</p>
<p>In the meantime, I’m taking what I read with a grain of salt. A while ago I posted that we should approach the psychology literature with a “<a href="../posts/a-default-of-disbelief.html">default of disbelief</a>”. If you see an interesting experimental result indicating a new phenomena or result, update your beliefs in only the mildest way. Don’t trust it until you see concordant results from independent pre-registered replications. I’m reading the human-AI interaction literature in the same way.</p>



 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/why-i-dont-trust-most-human-ai-interaction-experimental-research.html</guid>
  <pubDate>Wed, 11 Jun 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Economists’ Genetic Blindspot: The Data We’re Not Collecting</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/economists-genetic-blindspot-the-data-were-not-collecting.html</link>
  <description><![CDATA[ 




<p>This article was intended for a different forum. When that didn’t work out, I decided to park it here.</p>
<p>–</p>
<p>Professor of Sociology William H. Sewell was deeply interested in social mobility. Do career aspirations affect career achievement? Do individual and social traits underlie those aspirations? Despite some preliminary research in the 1950s, Sewell lacked the data to answer these questions.</p>
<p>In 1962, Sewell <a href="https://doi.org/10.1016/S0276-5624%2803%2920001-9">made a lucky discovery</a>: sitting unused in a University of Wisconsin administration building were the survey schedules and punch cards from a 1957 survey on the educational plans of all Wisconsin high school seniors. Now he had what he needed. He randomly selected 10,317 of these seniors and, in 1964, sent postcard surveys to their parents, asking about the seniors’ education, career aspirations, and socioeconomic status. Eighty-seven per cent of the parents responded. A 1975 telephone survey of the graduates themselves had a response rate of 89 per cent.</p>
<p>These steps began the Wisconsin Longitudinal Study; longitudinal studies observe subjects over time. In 1977, the survey expanded to include randomly selected siblings of the graduates. By 2020, the survey had accumulated over 60 years of data. The high school graduates were 81 years old.</p>
<p>In 2006-07 was a significant milestone. Saliva sample kits for genetic analysis were posted to participants. Kits were mailed in 2011 to those who missed the first round. Overall, 64 per cent of graduates and 36 per cent of siblings provided samples, covering about half of the 18,000 participants.</p>
<p>As genetic data doesn’t change, these samples enriched 50 years of data, including that initial collection in 1957. Each new collection, such as those in 2011 and 2020, is also augmented by this genetic data.</p>
<p>In 2018, Daniel Belsky and colleagues published <a href="https://doi.org/10.1073/pnas.1801238115">a paper</a> in the Proceedings of the National Academy of Sciences using the Wisconsin Longitudinal Study’s genetic data. For each student, they calculated an education “polygenic score”, a measure of the genetic influence on educational attainment. Students with higher scores had higher career success and social rank than their parents did in 1957. They were upwardly mobile. This observation held within families: siblings with higher scores achieved more as well.</p>
<p>As genetics are the cause of many phenomena we study, genetic data can be of immense value. Studying the mechanisms of DNA transmission and recombination between generations can help policymakers investigating issues such as social mobility, poverty, and inequality. We could assess interventions, from education to tax reform to childcare. By learning which interventions work, we could allocate public resources more efficiently. Kathryn Paige Harden makes the case for the value of genetic analysis comprehensively in the excellent <a href="https://press.princeton.edu/books/hardcover/9780691190808/the-genetic-lottery">The Genetic Lottery: Why DNA Matters for Social Equality</a>. In what follows, I will remake that case in only the most superficial way.</p>
<p>However, there is a major barrier to using genetic data in this way: most of the datasets we use to investigate socio-economic phenomena do not include genetic data, preventing us from including genetics in our analyses.</p>
<p>We should address this problem by collecting genetic data from the participants in longitudinal research. As our DNA is fixed for life, we should supplement old longitudinal data with genetic data, enriching decades of past work. The addition of genetic data to the Wisconsin Longitudinal Survey provides a template.</p>
<p>We could also be bringing genetic data to bear in our experimental work. The addition of genetic data to experimental panels could provide rich insight into the heterogeneity of behaviour.</p>
<p>Importantly, we can do this now. While many discussions on genetic data in social science focus on growing sample size, new tools and future possibilities, existing tools can give us insight today and bring future possibilities to life.</p>
<p>In what follows, I will first touch on two topics of interest to economists (my own profession): using genetic transmission to infer causation and some examples of genetic data applied to questions of social mobility and inequality. That will take me to my main point, that we should be supplementing our core research datasets with genetic data now.</p>
<section id="causation" class="level1">
<h1>Causation</h1>
<p>There is abundant data indicating the intergenerational persistence of educational outcomes and socioeconomic status. Here are two Australian examples (I’ll lean on material from my home country, which I know best): A Year 9 student (aged 14-15) whose parents have a bachelor’s degree or higher will, on average, have numeracy skills almost <a href="https://www.pc.gov.au/inquiries/completed/school-agreement/report/school-agreement.pdf">four years ahead of those of classmates</a> whose parents do not have a bachelor’s degree. A child born in Australia to a family in the bottom 20 per cent of parental incomes <a href="https://doi.org/10.1016/j.labeco.2020.101861">has a 12 per cent chance</a> of being in the top 20 per cent of incomes 30 years later.</p>
<p>For an economic policymaker, these statistics raise questions. Do the children of educated, wealthy parents have an unfair advantage? Would equalising wealth through taxes and transfers close the intergenerational gap? Designing robust solutions requires accurately assessing causality, but a correlation between child and parent outcomes does not prove that higher parental education or socioeconomic class <em>causes</em> outcomes in the next generation. We need to consider if a third factor might be “confounding” the result.</p>
<p>A likely third factor is genetics. Children and parents share DNA. If parents genetically transmitted traits like intelligence and conscientiousness to their children, we could see a correlation between the child and parent even if parental education or income had no direct effect on the child. It should not be controversial to say that genetics <em>could</em> underlie this result: the <a href="https://doi.org/10.1111/1467-8721.00084">first law of behaviour genetics</a> is that all human behavioural traits are heritable.</p>
<p>The genetic confound raises the question of how to infer the cause. Economists are infatuated with causation; absent a randomised controlled trial, they scour the world for interesting data sets and quasi-experiments to tease out causality. This pursuit led to innovative approaches to infer causation. Economists celebrate the “<a href="https://en.wikipedia.org/wiki/Credibility_revolution">credibility revolution</a>”, demanding rigorous study design.</p>
<p>An example quasi-experiment concerns <a href="https://en.wikipedia.org/wiki/May_68">protests in Paris in May 1968</a>, which led authorities to be lenient in university entrance exams. <a href="https://doi.org/10.1086/522071">Eric Maurin and Sandra McNally studied</a> students who barely passed despite the increased leniency, and likely would not have been accepted in other years. These students earned higher future wages, and, in turn, their children obtained more education. As the riot did not affect the genetics of the parents, we can take the change in schooling as the cause.</p>
<p>Economists’ focus on causation does have a benefit. The social science literature is littered with studies for which genetics is an obvious confound. There are fewer examples in the economics literature (that is my impression, at least). Although economists rarely discuss genetics, they prefer experimental designs that avoid confounds. That, however, places a constraint on the questions that we can answer. Thankfully, overcoming the genetic confound does not always require a city to descend into riots.</p>
<hr>
<p>Human genomes consist of 3 billion base pairs, with over 99 per cent of base pairs the same from person to person. Most of the variation between people are single nucleotide polymorphisms (SNPs), changes in just one base pair that are present in at least 1 per cent of the population. Genetic databases, like the Wisconsin Longitudinal Study, typically contain samples of SNPs. If you’ve taken a DNA test from companies like 23andMe (R.I.P.) or MyHeritage, they analysed your SNPs too.</p>
<p>Research using SNP data suggests that most traits are polygenic: that is, many genes underlie the traits’ heritability. For example, one study <a href="https://doi.org/10.1038/s41588-022-01016-z">identified 3,952 SNPs</a> linked to educational attainment. This reflects a proposed <a href="https://doi.org/10.1177/0963721415580430">fourth law of behaviour genetics</a>: ‘A typical human behavioural trait is associated with very many genetic variants, each of which accounts for a very small percentage of the behavioural variability.’</p>
<p>A long list of SNPs alone is not useful for examining social science outcomes. As a result, scientists developed polygenic scores, a weighted count of SNPs enhancing a trait. To give an example, <a href="https://doi.org/10.1177/0956797616643070">one study</a> found that a person in the 84th percentile of polygenic scores for educational attainment was 19 per cent more likely to complete a university degree than someone with an average score. It may not sound like much, but this is a similar effect size to that of many social and cultural factors, like family socioeconomic status.</p>
<p>Despite the apparent link between polygenic scores and outcomes, this is again correlation and not proof of causation. Does a link between polygenic score and outcome mean genetics <em>caused</em> the difference? We cannot jump to an answer of “yes”. Population stratification may be at play, where genetic differences arise between groups due to historical, cultural and social factors. For example, intermarriage among highly educated groups can lead to genetic variant concentration over time, showing genetics to be a historic contingency and not truly causal. We can at least rule out reverse causation; education does not alter DNA.</p>
<p>However, the nature of DNA transmission from parent to child provides a mechanism by which we can get closer to the cause. Your genetic material is organized into 23 pairs of chromosomes, one-half of each pair coming from each of your father and mother. Each parent’s chromosomes in turn came from your grandparents, but you didn’t receive exact copies of your grandparents’ chromosomes. During the creation of your parents’ eggs and sperm, your grandparents’ chromosomes were spliced together, resulting in each egg or sperm having different combinations of your grandparents’ chromosomes. Women create about 45 splices, and men create about 26. The result is that siblings receive a random draw from each parent’s chromosomes. This draw involves <a href="https://doi.org/10.1038/ng917">a small number of chunks</a> (around 23+45=68 from the mother and 23+26=49 from the father), not each of the three billion base pairs independently. Because of this small number of chunks, the genetic relatedness between siblings can vary significantly from the average of 50 per cent, with most siblings sharing between <a href="https://doi.org/10.1371/journal.pgen.0020041">43 per cent and 57 per cent</a> of their genetic material. My identical twin sons share only 41 per cent of their DNA with their younger brother.</p>
<p>Understanding how DNA is transmitted provides a fantastic opportunity. Historically, behaviour genetics relied on comparing identical and fraternal twins or examining adoptees. Relatedness data now allows an <a href="https://doi.org/10.1371/journal.pgen.0020041">extension of the twin study methodology</a> to families without twins. The lower variation in relatedness between siblings (as compared to identical versus fraternal twins) reduces the ability to link between genes and outcomes, but this is offset by the larger samples available when you are no longer constrained to twin samples. <a href="https://doi.org/10.1038/s41588-018-0178-9">Researchers have since expanded this methodology</a> to include broader population samples, not just siblings, to estimate the heritability of traits like educational attainment.</p>
<p>Within-family variation in SNPs also allows us to calculate more robust polygenic scores. Since each sibling’s set of SNPs is the outcome of a lottery, causation is <a href="https://doi.org/10.1371/journal.pbio.3002511">less susceptible to bias</a>.</p>
<p>Another opportunity arises because some genetic variants are not passed from parent to child. If these non-transmitted variants affect child outcomes, we can rule out genetic transmission and focus on environmental channels such as socioeconomic status. <a href="https://doi.org/10.1038/s41562-020-0862-5">Kathryn Paige Harden and Philipp Koellinger</a> call this a ‘virtual parent’ design, which mimics adoption studies in that the children are raised by someone with different genes. <a href="https://doi.org/10.1126/science.aan6877">Kong and colleagues</a> used this premise to show that the effect of the non-transmitted variants on child education was 30 per cent as strong as the transmitted polygenic score.</p>
<p>The methodologies underlying this research are still in development and subject to some interesting debates. Are we <a href="https://www.google.com/search?q=https://doi.org/10.1101/2024.10.01.24314703">effectively controlling for population stratification</a> when we don’t have family-based samples? However, that is not a barrier to building data now, and further data collection will support resolving such debates.</p>
</section>
<section id="illustrating-the-applications" class="level1">
<h1>Illustrating the applications</h1>
<p>For all of the evidence indicating their influence, genes are not destiny. An example is <a href="https://doi.org/10.2307/2553675">Arthur Goldberger’s</a> thought experiment about eyeglasses. Poor eyesight due to genetics might be corrected by an environmental intervention.</p>
<p>Although Goldberger made this point to argue against using heritability in policy development, studies of intergenerational status have shown genes and environment are interconnected. Methodologies such as those described above can help us understand the causes of transmission, explore what policy interventions are most prospective and examine the distributional effects of those policies.</p>
<p>This article is not a comprehensive review of policy relevant research, but below are some brief illustrations related to social mobility and intergenerational transmission of socioeconomic status to give a flavour of the questions that can be illuminated with genetic data.</p>
<hr>
<p>What is the optimal level of social mobility?</p>
<p>I don’t know the answer to that question, but any answer requires us to consider genetics. With genetic endowments, random sorting will not emerge in a society with equal environments. Consider the following. A <a href="https://doi.org/10.1007/s10888-019-09413-x">study of Finnish twins</a> found a substantial genetic effect on lifetime earnings: around 40 per cent of the variance in women’s earnings and around half for men’s. Twenty-one other studies in Australia, Sweden and the United States produced similar estimates for genetic contribution, with the effect of shared environment, comprising common environmental factors such as parental socioeconomic status, being around 9 per cent. This is the <a href="https://doi.org/10.1111/1467-8721.00084">second law of behaviour genetics</a> in action: the effect of being raised in the same family is smaller than the effect of genes. However, is heritability capturing an inherent characteristic of the child, the parental response to the child’s genotype, or the environment created due to the parental genotype that is also shared with the child?</p>
<p>Analyses using genetic data are nascent, but they can shed light on this question. Polygenic scores for education are <a href="https://doi.org/10.1073/pnas.1801238115">linked to higher socioeconomic status</a> and <a href="https://doi.org/10.1093/jeea/jvz072">better labour outcomes</a>, even among siblings. However, those who grow up in high-status households tend to have higher college completion and better socioeconomic outcomes independent of their score. Further, there is a stronger relationship between polygenic scores and college completion in higher socioeconomic groups. While this pattern may partly reflect unobserved genetic variation - polygenic scores capture only some of the heritability of traits - this evidence suggests an opportunity to improve outcomes for talented students in low-status families.</p>
<p>There is growing research into the transmission of skills, one of the pathways by which socioeconomic status might persist. <a href="https://doi.org/10.1257/aer.20220456">One study</a> identified three genetic pathways: the direct genetic effect, whereby both parent and child have genes that increase their skills; parental investment in children with higher polygenic scores; and parents with higher genetic factors themselves investing more in their children. This study indicated that ignoring genetics overestimates the effect of parental investment on child skills, but that the environment created by the parent, influenced by their genetics, also matters, at least for the children aged seven years or less examined in this study. Examining these investments may provide intervention ideas.</p>
<p>Another study used genetic data to provide insight into the accumulation of wealth. People with a higher polygenic score for years of schooling <a href="https://doi.org/10.1086/705415">had greater household wealth at retirement</a>. Those with scores in the 84th percentile had over $150,000 extra wealth. A polygenic score premium persisted even after controlling for education and income, suggesting the score captures other skills. One policy insight comes from a gene-environment interaction. The relationship between wealth and polygenic score was four times as large for those without defined benefit pensions, which involve a guaranteed income and require few decisions about money allocation. Those with lower polygenic scores tended to struggle with managing their retirement investments, indicating that freedom can harm those who find complex financial decisions difficult. This finding could inform policy. In Australia, compulsory defined accumulation plans divert a portion of income into tax-advantaged retirement accounts that cannot be accessed until retirement. This is an ‘eyeglasses’ solution to the problem, albeit everyone gets eyeglasses regardless of need. A more targeted response might be Australia’s relatively generous means-tested pension system.</p>
<p>Genetic factors may also illuminate the distributional effects of policy. Taxes on tobacco were intended to curb usage, but as Jason Fletcher argued in a <a href="https://doi.org/10.1371/journal.pone.0050576">speculative article</a>, genetically disadvantaged populations might bear a higher burden. Variants of nicotine receptor genes may trigger different responses; those with higher reward responses in the brain didn’t reduce smoking despite the higher cost. This suggests that diversion through nicotine substitutes may be more effective than taxes for some populations.</p>
<p>Examples of heterogeneous genetic responses to policy interventions are growing. Raising the minimum school leaving age <a href="https://doi.org/10.1073/pnas.1802909115">reduced the body mass index</a> of those genetically prone to obesity. Students with low polygenic scores attending <a href="https://doi.org/10.1038/s41539-020-0060-2">advantaged schools</a> were less likely to drop out of math classes. Similarly, <a href="https://doi.org/10.1093/jeea/jvz072">the relationship</a> between polygenic scores and high school dropout was weaker in higher socioeconomic families, suggesting an ability to buffer against the worst outcomes. A useful heuristic to consider whether responses might vary with genetics is to consider whether they vary with education, income, or other socioeconomic factors. Genetics likely underlies many of these non-genetic variables.</p>
<p>The small but growing body of research provides a consistent picture: genetics influence social mobility and interact with environmental factors in non-obvious ways. Absent genetics, we struggle to assess the causes and overlook insights that can help us evaluate interventions.</p>
</section>
<section id="the-practical-steps" class="level1">
<h1>The practical steps</h1>
<p>Despite the above examples, there are many unexploited opportunities to use genetic data in economics and policy development. The literature is rich but small.</p>
<p>However, to exploit these opportunities, we need to enhance our datasets with genetic data. We need to build the genetic infrastructure. When economists plan research using longitudinal datasets or experimental panels, they shouldn’t have to think about how to collect saliva samples or the cost of genetic analysis. The genetic data should be there by default.</p>
<section id="enhancing-longitudinal-data" class="level3">
<h3 class="anchored" data-anchor-id="enhancing-longitudinal-data">Enhancing longitudinal data</h3>
<p>Longitudinal data sets are valuable for their multidimensionality over time, allowing researchers to track changes and examine the participants’ life paths. Ask an applied economist about their most valuable research resource, and they will often point to longitudinal data.</p>
<p>In Australia, our best-known longitudinal dataset is the Household, Income and Labour Dynamics in Australia (HILDA) Survey. Begun in 2001 with a sample of <a href="https://www.dss.gov.au/about-the-department/longitudinal-studies/living-in-australia-hilda-household-income-and-labour-dynamics-in-australia-overview">over 7,000 households</a>, 22 years of data are now available to researchers. <a href="https://melbourneinstitute.unimelb.edu.au/hilda/publications/journal-articles">Over 1,000 papers</a> have been published using HILDA data on topics ranging from <a href="https://doi.org/10.1007/s00148-017-0667-7">how losing a job affects who does chores at home</a> to the <a href="https://doi.org/10.1016/j.jebo.2015.02.004">effect of stock market performance on well-being</a> to <a href="https://doi.org/10.1111/1475-4932.12641">intergenerational social mobility</a>.</p>
<p>In the United States, perhaps the best-known longitudinal surveys are the <a href="https://en.wikipedia.org/wiki/National_Longitudinal_Surveys">National Longitudinal Surveys</a> (NLS) sponsored by the U.S. Bureau of Labour Statistics. These include the <a href="https://www.nlsinfo.org/">National Longitudinal Study of Youth</a> 1979 (tracking subjects born between 1957 and 1964) and 1997 (tracking subjects born between 1980 and 1984). Named for their starting years, both studies are still running today.</p>
<p>What makes these longitudinal resources valuable is the sheer depth of the surveys across topic areas and time. HILDA includes data on ancestry, children, education, finance, health, housing, labour force outcomes, skills and relationships. The challenge, however, is that even with the richness of the resource, it can take some ingenuity to infer what is causing the observed outcomes. Researchers use mechanisms such as the ordering of events, assuming causation must flow forward through time. But this typically has severe constraints.</p>
<p>Again, genetics provides a potential tool. If seeking to examine how parent behaviour affects child outcomes over time, genetic data could be used to disentangle environmental and genetic causes, and where genetic, examine the pathways by which the genetics operate. Even where genetic data does not identify causation, it might provide insight.</p>
<p>Unfortunately, many of our most valuable longitudinal datasets do not have associated genetic data. There are a few exceptions, including the Wisconsin Longitudinal Study and others that underlie the examples in this article. The <a href="https://www.teds.ac.uk/">Twins Early Development Study</a>, which has been tracking 15,000 twins born in the UK between 1994 and 1996, is now augmented with genetic data. The Dunedin study and the National Longitudinal Survey on Adolescent Health also contain genetic data. There are others, some of which underlie the examples in this article.</p>
<p>For every longitudinal dataset, we should augment data collection with genetic data. This does not apply only to new surveys. We could augment existing surveys with that data. Genetic data obtained from participants today could be used to analyse Round 1 HILDA or National Longitudinal Survey data. There are many studies where people have been tracked for decades where participants are still available. If genetic data collection is extended to families, many of the approaches to causation described in this article become available. The Wisconsin Longitudinal Study is an example of this occurring.</p>
<p>The nature of longitudinal surveys makes genetic sampling prospective. Longitudinal surveys have the benefit of a strong relationship with the participants. Participants already provide much sensitive information and may be willing to contribute genetic data. Most longitudinal surveys already have strong privacy protocols in place, controlling access to data based on sensitivity. Similar privacy measures can be applied to genetic data, addressing concerns such as the use of the genetic data to identify individuals. Instead of making the SNP data directly available, a set of polygenic scores and relatedness data within families could be released. If researchers need access to more detailed data, the existing access controls for the more sensitive longitudinal data provide prior art. The Wisconsin Longitudinal Study has such tiered access, with more stringent applications for SNP data than for aggregated polygenic scores.</p>
<p>The sheer volume of research from the major longitudinal surveys makes sampling highly cost-effective. With costs comfortably below $100 per person, the cost of genotyping for, say, the NLS Youth Surveys or HILDA is less than $1 million each. Sample collection can be done by post. The thousands of papers using this data, not to mention its use in government and by policymakers, make this a high-value step.</p>
<p>The cost-effectiveness will only increase. Genotyping and sequencing are becoming cheaper. Soon genetic samples will expand to the whole genome, capturing more rare variants and mitigating problems of population stratification. The polygenic scores that can be constructed with the genetic data will only increase in power.</p>
</section>
<section id="enhancing-experimental-data" class="level3">
<h3 class="anchored" data-anchor-id="enhancing-experimental-data"><strong>Enhancing experimental data</strong></h3>
<p>While most of the above discussion has been focussed on research using longitudinal datasets, there is also an opportunity to use genetic data to increase insight from experimental work.</p>
<p>Historically, students have been the typical subjects in economics or psychology experiments. They’re cheap and widely available on university campuses. This reliance on a narrow population slice led to an <a href="https://doi.org/10.1017/S0140525X0999152X">inevitable (at least in hindsight) critique</a>. Behaviour varies across populations. The standard experimental subject - someone Western, Educated, Industrialised, Rich and Democratic (WEIRD) - is not representative. The resulting data skew exists both <a href="https://doi.org/10.1257/aer.91.2.73">across populations or societies</a> and within them. College-educated students are not representative of those without a college education. The same holds for the rich and the poor.</p>
<p>One solution is to broaden subject pools. Today, experiments are less often conducted with students (although it’s unclear whether experimental participants sourced through Amazon’s crowdsourcing platform Mechanical Turk are more representative of humanity).</p>
<p>Another approach has been to examine how participants’ responses vary within experiments. Behavioural economists often point to <a href="https://doi.org/10.1038/s41562-021-01143-3">heterogeneity</a> as the future of applied behavioural science. People vary in capabilities, resources, goals and preferences. As a result, behavioural economists need to move beyond a one-size-fits-all philosophy and use <a href="https://doi.org/10.1017/bpp.2020.7">personalised nudges</a>. Practically, researchers address this by collecting data on gender, income, education and other demographic variables and studying how responses vary with demographic differences.</p>
<p>Genetics may enhance our understanding of heterogeneity. Per the first law of behavioural genetics, genetics may drive variability in experimental behaviour. Further, many characteristics that we identify as a source of variation may not capture the underlying cause. Genetic data can help us determine whether wealthy people respond differently because they are richer, or because they have characteristics that tend to lead to wealth. Genetic data offers a way to check that randomised controlled trials are balanced - that is, to test the assumption that each group is the same. It also allows us to increase the power of the analysis - our ability to detect an effect - by accounting for some of the variation between the experimental participants.</p>
<p>Integrating genetic data into experiments can let us investigate associations discovered in observational data. For example, the link between polygenic scores for <a href="https://doi.org/10.1086/705415">educational attainment and wealth at retirement</a> may be due to differences in the ability to make complex decisions. We could investigate that hypothesis through experiments examining how complex decision-making skills vary with the polygenic score. Experiments could provide a test bed for interventions, or at least inform policy discussions.</p>
<p>Enabling the use of genetics in experimental work requires building panels - collections of people who have registered to participate in experiments - with genetic data available for each participant. Each panel member could be genotyped, with the experimenter provided with polygenic scores for a range of outcomes of interest for each participant. The aggregated nature of these scores makes reidentification near impossible. As the effect sizes associated with polygenic scores are typically as strong or stronger than those for many social science interventions, genetic effects could be detected in experiments with as <a href="https://doi.org/10.1038%2Fs41588-018-0147-3">few participants as the typical lab experiment</a>.</p>
<p>A version of this has been done in the past with panels of twins, although in that case the genetic data is typically limited to whether the twins are mono- or dizygotic. For example, <a href="https://twins.org.au/research/research-with-us/">Twins Research Australia</a> maintains a panel of 35,000 twin pairs, which researchers may apply to access existing data or run a new study. One team of researchers developed the <a href="https://doi.org/10.26193/TTQEBQ">Australian Twins Economic Preferences Survey</a> using that data.</p>
<p>Incorporating genetic data into experimental work may be a bigger challenge than for longitudinal data, as there are no ready-made data collection and access arrangements. These would require investment. However, genotyping or sequencing cost are unlikely to be prohibitive. As panel participants typically participate in many experiments, the cost of the genetic tests could be spread over them. Since genetic data doesn’t change - unlike other attributes measured in experimental studies - it only needs to be collected once. Further, genetic data is concrete and not self-reported, so is thereby more consistent and reliable.</p>
<p>Alternatively, existing genetic research resources could be expanded in purpose. The UK Biobank database contains genetic, lifestyle and health data for half a million UK participants (albeit it could be stronger with <a href="https://doi.org/10.1038/s41586-024-07721-5">more family-based participants</a>). Estonia, Iceland and the Scandinavian countries have large genetic databases. These could provide experimental participants together with polygenic scores. Experimental data then forms part of the growing data resource. Commercial providers such as 23andMe with large customer databases could even seek alternative revenue sources by facilitating the provision of participants for experimental studies.</p>
<p>Critical to the value of any future data sets is representative population sampling. However, polygenic scores are typically developed from homogeneous population groups, most commonly with European ancestry. As a result, polygenic scores cannot simply be plugged into analyses of diverse groups. Genetic data itself doesn’t solve the WEIRD problem if research panels remain WEIRD. These are the important but ultimately tractable issues we should be grappling with.</p>
<hr>
<p>My PhD was on the link between human evolution and economic growth. When I presented a draft of my PhD research proposal, the first comment I received was that I should refuse any grants from men with funny little moustaches and straight-arm salutes. Although that commenter came around, this initial reaction is a typical response to a discussion of genetics in social science.</p>
<p>That ‘fear’ of the implications of genetics, however, is not the only obstacle to its use. Genetic data is simply not available for many studies. Its absence makes it easy to ignore. If the authors don’t mention genetics in their analysis, few peer reviewers will criticise them for overlooking an obvious confound. They can’t ask for further analysis when the data is not there.</p>
<p>The result is that, despite examples of the type I have discussed above, the potential for genetics to inform our thinking on important policy questions is untapped. I trawled policy-focused papers on social mobility in Australia, including <a href="https://www.google.com/search?q=https://s3.documentcloud.org/documents/23571805/intergenerational-income-mobility-in-australia.pdf">Treasury policy briefs</a>, reports by the <a href="https://www.google.com/search?q=https://www.aihw.gov.au/getmedia/37c2c8b7-328c-41e1-bace-87ed7a551777/australias-welfare-chapter-2-summary-18sept2019.pdf.aspx%23:~:text%3DThere%2520is%2520clear%2520evidence%2520that,most%2520notably%2520the%2520United%2520States%2529.">Australian Institute for Health and Welfare</a> and <a href="https://www.pc.gov.au/media-speeches/speeches/inequality-government-role">speeches by the head</a> of the Australian Government’s major economic think tank. Genetics does not get a mention. It is possible to dig up the <a href="https://insidestory.org.au/the-remarkable-persistence-of-power-and-privilege/">occasional left-of-centre politician</a> who realises genetics can affect social mobility (albeit that politician was an economics professor who published on social mobility). However, even they <a href="https://ministers.treasury.gov.au/ministers/andrew-leigh-2022/articles/opinion-piece-no-childs-future-should-be-pre-determined-their">are silent on genetics</a> when they move into political mode.</p>
<p>That said, it is hard for policymakers to engage with genetic questions when the research comes from longitudinal datasets without genetic data. Insightful papers examining the genetics of social mobility or other economic questions are rare. When faced with a particular policy question, it is unlikely that genetic analysis is available, especially one that matches relevant populations or precise policy measures.</p>
<p>That is why enriching our economic datasets is so important. A robust genetic data foundation is crucial for advancing our understanding of policy questions such as social mobility, inequality, skill development, and the diversity of our responses to government interventions. By enabling more studies that incorporate genetics, we can expose the limitations of research that ignores this critical factor. Only then can we answer vital questions and develop more effective policies.</p>


</section>
</section>

 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/economists-genetic-blindspot-the-data-were-not-collecting.html</guid>
  <pubDate>Tue, 27 May 2025 23:00:00 GMT</pubDate>
</item>
<item>
  <title>A critical behavioural economics and behavioural science reading list</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/a-critical-behavioural-economics-and-behavioural-science-reading-list.html</link>
  <description><![CDATA[ 




<p>This reading list is a balance to the one-dimensional view in many popular books, TED talks, conferences, academic press releases and consultancy sales pitches. For those who feel they have a good understanding of the literature after reading <a href="../posts/re-reading-kahnemans-thinking-fast-and-slow/">Thinking Fast and Slow</a>, <a href="../posts/arielys-predictably-irrational/">Predictably Irrational</a> and <a href="../posts/thaler-and-sunsteins-nudge/">Nudge</a>, this is for you. [In the time since I drafted the first version of this list in 2017, it’s fair to say that the balance has swung a bit.]</p>
<p>The purpose of this reading list is not to imply that all behavioural economics or behavioural science is bunk (it’s not). That said, I did not design the list to be balanced; you can combine this list with plenty of reading lists from elsewhere for that.</p>
<p>Please let me know if there are any other books or articles I should add, or if there are any particularly good replies to what I have listed. I am sure I have missed some good ones. I have set a mild quality bar on what I have included. I don’t agree with all the arguments, but everything on the list has at least one interesting idea.</p>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">1. Books</h2>
<p>Gerd Gigerenzer, Peter Todd and the ABC Research Group, <a href="../posts/simple-heuristics-that-make-us-smart/">Simple Heuristics That Make Us Smart</a>: Simple heuristics can be both fast and accurate, particularly when we assess real-life performance rather than conformity with the principles of rationality.</p>
<p>Doug Kenrick and Vlad Griskevicius, <a href="../posts/kenrick-and-griskeviciuss-the-rational-animal/">The Rational Animal: How Evolution Made Us Smarter Than We Think</a>: A good introduction to the idea that evolutionary psychology could add a lot of value to behavioural economics, but has the occasional straw man discussion of economics and a heavy reliance on priming research (and you will see below how that is panning out).</p>
<p>David Levine, <a href="../posts/levines-is-behavioural-economics-doomed/">Is Behavioural Economics Doomed?</a>: A good but slightly frustrating read. I agree with Levine’s central argument that rationality is underweighted, but the book is littered with straw man arguments.</p>
<p>Lionel Page, <em>Optimally irrational: The Good Reasons We Behave the Way We Do</em>: We should invest more in understanding <em>why</em> people behave the way they do.</p>
<p>Mario J. Rizzo and Glen Whitman, <em>Escaping Paternalism: Rationality, Behavioral Economics, and Public Policy</em>: An excellent critique of the traditional behavioural economists’ arguments for paternalism.</p>
<p>Phil Rosenzweig, <a href="../posts/rosenzweigs-left-brain-right-stuff-how-leaders-make-winning-decisions/">Left Brain, Right Stuff: How Leaders Make Winning Decisions</a>: An entertaining examination of how behavioural economics findings hold up for real world decision-making.</p>
<p>Gilles Saint-Paul, <a href="../posts/saint-pauls-the-tyranny-of-utility-behavioral-social-science-and-the-rise-of-paternalism/">The Tyranny of Utility: Behavioral Social Science and the Rise of Paternalism</a>: Sometimes hard to share Saint-Paul’s anger, but some important underlying points.</p>
<p>Hugo Mercier, <em>Not Born Yesterday: The Science of Who We Trust and What We Believe</em>: A strong argument that we are not gullible and easily manipulated, but rather skeptical and rational in the way we filter information.</p>
<p>Robert Sugden, <a href="../posts/robert-sugdens-the-community-of-advantage-a-behavioural-economists-defence-of-the-market/">The Community of Advantage: A Behavioural Economist’s Defence of the Market</a>: A well balanced critique from someone who has worked in the field for decades.</p>
<p>Mark D. White, <em>The Manipulation of Choice: Ethics, Libertarianism and Paternalism</em>: Some great chapters on what policy makers can know about people’s preferences, but for misses the mark is his critique on what behavioural economics can bundle under the “preferences” label.</p>
</section>
<section id="general-and-methodological-critiques" class="level2">
<h2 class="anchored" data-anchor-id="general-and-methodological-critiques">2. General and methodological critiques</h2>
<p><strong>Applied behavioural economics:</strong> In <a href="https://www.thebehavioralscientist.com/articles/the-death-of-behavioral-economics">The death of behavioral economics</a>, Jason Hreha argues that applied behavioural economics is on the way out. Scott Alexander <a href="https://astralcodexten.substack.com/p/on-hreha-on-behavioral-economics">responds</a>.</p>
<p><strong>Are we biased?:</strong> Gerd Gigerenzer debates Daniel Kahneman and Amos Tversky. <a href="https://doi.org/10.1080/14792779143000033">Gigerenzer tees off</a> (<a href="http://library.mpib-berlin.mpg.de/ft/gg/gg_how_1991.pdf">pdf</a>). <a href="http://doi.org/10.1037/0033-295X.103.3.582">Kahneman and Tversky respond</a> (<a href="http://matt.colorado.edu/teaching/highcog/fall8/kt96.pdf">pdf</a> - this pdf also includes a rejoinder to Gigerenzer’s later piece). <a href="http://doi.org/10.1037/0033-295X.103.3.592">Gigerenzer returns</a> (<a href="http://library.mpib-berlin.mpg.de/ft/gg/gg_on%20narrow_1996.pdf">pdf</a>). I’m a fan of a lot of Gigerenzer’s work, but his strength has never been the direct attack. Kahneman and Tversky get the better of this exchange. My post <a href="../posts/gigerenzer-versus-kahneman-and-tversky-the-1996-face-off/">here</a>.</p>
<p><strong>As-if models</strong>: Nathan Berg and Gerd Gigerenzer note that <a href="https://www.jstor.org/stable/23723790?seq=1#page_scan_tab_contents">behavioral economics is neoclassical economics in disguise</a> (<a href="https://mpra.ub.uni-muenchen.de/26586/1/MPRA_paper_26586.pdf">pdf of working paper</a>). They write that “‘As-if’ arguments are frequently put forward in behavioral economics to justify ‘psychological’ models that add new parameters to fit decision outcome data rather than specifying more realistic or empirically supported psychological processes that genuinely explain these data.” Includes a critique of prospect theory’s lack of realism as a decision-making process.</p>
<p><strong>Critiquing economics I:</strong> Ken Binmore <a href="https://doi.org/10.1017/S0140525X05230145">argues</a> <a href="http://else.econ.ucl.ac.uk/papers/uploaded/262.pdf">(pdf)</a> that the claim “economic man” is a failure can be both attacking a position not held by economics and ignoring the experimental evidence of people behaving like “economic man”.</p>
<p><strong>Critiquing economics II:</strong> Pete Lunn and Tim Harford <a href="https://www.prospectmagazine.co.uk/magazine/behaviouraleconomicsisitsuchabigdeal">debate</a> whether “the idea that the very foundations of economics are being undermined is absurd.”</p>
<p><strong>The effectiveness of nudging:</strong> Mertens et al <a href="https://doi.org/10.1073/pnas.2107346118">“found”</a> that choice architecture interventions promote behavior change with a small to medium effect size. Andrew Gelman <a href="https://statmodeling.stat.columbia.edu/2022/01/07/pnas-gigo-qrp-wtf-approaching-the-platonic-ideal-of-junk-science/">responds</a>. Three articles in reply argue that <a href="https://doi.org/10.1073/pnas.2203616119">most of the pooled effects in Mertens et al.&nbsp;are overestimated and hence unrepresentative</a>, <a href="https://doi.org/10.1073/pnas.2200300119">there is no evidence for nudging after correcting for publication bias</a>, and <a href="https://doi.org/10.1073/pnas.2200732119">there is no reason to expect large and consistent effects of nudge interventions</a>. Some of the garbage in the meta-analysis led to a <a href="https://doi.org/10.1073/pnas.2204059119">correction</a>, although the papers from Brian Wansink remained (more on Wansink below).</p>
<p><strong>Evolutionary theory I:</strong> Owen Jones <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2504776">proposes that</a> “… Behavioral Economics, and those who rely on it, are falling behind with respect to new developments in other disciplines that also bear directly on the very same mysteries of human decision-making.”</p>
<p><strong>Evolutionary theory II:</strong> Douglas Kenrick and colleagues <a href="https://doi.org/10.1521%2Fsoco.2009.27.5.764">argue</a> that many of our biases are in fact deeply rational. (<a href="../posts/deep-rationality-the-evolutionary-economics-of-decision-making/">My post</a>).</p>
<p><strong>Ergodicity:</strong> Ole Peters proposes <a href="https://doi.org/10.1038/s41567-019-0732-0">The ergodicity problem in economics</a>. “[B]y carefully addressing the question of ergodicity, many puzzles besetting the current economic formalism are resolved in a natural and empirically testable way.” See also David Meder and friends’ <a href="https://arxiv.org/abs/1906.04652">Ergodicity-breaking reveals time optimal economic behavior in humans</a>. My posts <a href="../posts/ergodicity-economics-a-primer/">here</a>, <a href="../posts/risk-and-loss-aversion-in-ergodicity-economics">here</a> and <a href="../posts/the-psychological-and-genes-eye-view-of-ergodicity-economics">here</a>.</p>
<p><strong>Humility</strong>: In <a href="../posts/arent-we-smart-fellow-behavioural-scientists/">Aren’t we smart, fellow behavioural scientists</a>, I suggest that “As applied behavioural scientists, we need to inject some humility into our assessment of other people’s decisions. … We need to stop making glib assumptions about what other people want and how they can best achieve their objectives.”</p>
<p><strong>Lab experiments 1:</strong> Ken Binmore and Avner Shaked <a href="https://doi.org/10.1016/j.jebo.2008.10.019">urge experimentalists</a> to “join the rest of the scientific community in adopting a more skeptical attitude when far-reaching claims about human behavior are extrapolated from very slender data”. Fehr and Schmidt <a href="https://doi.org/10.1016/j.jebo.2009.12.001">respond</a>, as do <a href="https://doi.org/10.1016/j.jebo.2009.03.026">Eckel and Gintis</a>. Binmore and Shaked <a href="https://discovery.ucl.ac.uk/id/eprint/14996/1/14996.pdf">wrote a rejoinder</a>.</p>
<p><strong>Lab experiments 2:</strong> Steven Levitt and John List note that, while economic models can benefit from incorporating insights from psychology, <a href="https://doi.org/10.1126/science.1153640">“behavior in the lab might be a poor guide to real-world behavior.”</a> (<a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=E8D3E1779C3E987FD26581542DF90122?doi=10.1.1.352.3885&amp;rep=rep1&amp;type=pdf">pdf</a>).</p>
<p><strong>Lab experiments 3:</strong> Steven Levitt and John List <a href="https://www.aeaweb.org/articles?id=10.1257/jep.21.2.153">suggest that caution is required</a> when attempting to generalise lab results out of sample.</p>
<p><strong>Many co-authors:</strong> Emerging from the Francesca Gino frauds (see below) was the <a href="https://manycoauthors.org/">Many Co-authors project</a>. For all studies in which Gino was involved, was Gino involved in data collection? The truly underwhelming element of this project is how rarely data has been made publicly available. Further, it once again highlights that shenanigans by people like Gino are only the tip of the iceberg. Here’s one outcome, a retraction of <a href="https://doi.org/10.1016/j.obhdp.2016.07.004">Don’t stop believing: Rituals improve performance by decreasing anxiety</a> for which Gino was a co-author but not involved in data collection for most of the studies. Missing data and questionable data management all round. It’s best to retain the <a href="../posts/a-default-of-disbelief">default of disbelief</a>.</p>
<p><strong>Megastudies:</strong> Do megastudies improve the impact of applied behavioural science? <a href="https://doi.org/10.1038/s41586-021-04128-4">Katherine Milkman and friends</a> argue so. <a href="../posts/megastudy-scepticism">My initial take</a> and a <a href="../posts/what-we-learn-when-we-test-everything">later reflection</a> suggest there are trade-offs and problems in execution.</p>
<p><strong>Preferences:</strong> Gerardo Infante, Guilhem Lecouteux and Robert Sugden argue that <a href="https://doi.org/10.1080/1350178X.2015.1070527">Behavioural welfare economics does not model human psychology as it really is, but rather as “faulty Econs”</a> (<a href="https://www.tandfonline.com/doi/pdf/10.1080/1350178X.2015.1070527?needAccess=true">pdf</a>). Daniel Hausman <a href="https://doi.org/10.1080/1350178X.2015.1070525">responds</a>. Infante and friends provide a <a href="https://doi.org/10.1080/1350178X.2015.1070526">rejoinder</a> (<a href="https://ueaeprints.uea.ac.uk/57631/1/reply_to_Hausman_final_1506_10.pdf">working paper pdf</a>).</p>
<p><strong>Pre-registration</strong>: <a href="https://doi.org/10.1038/s41562-023-01749-9">Protzko and friends argue</a> that rigour-enhancing practices such as confirmatory tests, large sample sizes, preregistration and methodological transparency increase replication rates. The problem: they didn’t preregister their own analysis. Jessica Hullman discusses <a href="https://statmodeling.stat.columbia.edu/2023/11/21/of-course-its-preregistered-just-give-me-a-sec/">here</a> and <a href="https://statmodeling.stat.columbia.edu/2024/03/27/the-feel-good-open-science-story-versus-the-preregistration-who-do-you-think-wins/">here</a>. My <a href="../posts/the-preregistration-halo">two cents</a>. Andrew Gelman <a href="https://statmodeling.stat.columbia.edu/2024/09/26/whats-the-story-behind-that-paper-by-the-center-for-open-science-team-that-just-got-retracted/">provides a nice summary</a> following the retraction.</p>
<p><strong>The need for theory I:</strong> David Levine and Jie Zheng <a href="http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195328325.001.0001/acprof-9780195328325-chapter-3">propose that</a> (<a href="http://jzheng.weebly.com/uploads/1/9/6/6/19665907/levine_and_zheng_%5B2015%5D.pdf">pdf</a>) Economic theory makes strong predictions about many situations and is generally quite accurate in predicting behavior in the laboratory. “In situations where the theory is thought to fail, the failure is in the application of theory rather than the theory failing to explain the evidence.”</p>
<p><strong>The need for theory II:</strong> Michael Muthukrishna and Joseph Henrich <a href="https://doi.org/10.1038/s41562-018-0522-1">argue that</a> the replication crisis in the psychological sciences is a problem of lack of theory.</p>
<p><strong>Replication:</strong> The Open Science Collaboration found that <a href="https://doi.org/10.1126/science.aac4716">Thirty-six percent of psychology replications had significant results</a> (<a href="http://www.psykologforbundet.se/Documents/Psykologtidningen/Aktuellt%20Pdf/Science%20aug%202015.pdf">pdf</a>). Effect sizes were halved in magnitude. Social psychology fares particularly poorly.</p>
<p><strong>Self criticism:</strong> Ariel Rubinstein <a href="http://arielrubinstein.tau.ac.il/papers/behavioral-economics.pdf">notes that</a> “[f]or Behavioral Economics to be a revolutionary program of research rather than a passing episode, it must become more open-minded and much more critical of itself.”</p>
<p><strong>Too many biases:</strong> <a href="https://worksinprogress.co/issue/biases-the-wrong-model/">I argue that</a> instead of building a messier and messier picture of human behavior, we need a new model.</p>
<p><strong>WEIRD people</strong>: Joseph Henrich, Steven Heine and Ara Norenzayan <a href="https://doi.org/10.1017/S0140525X0999152X">propose that</a> “we need to be less cavalier in addressing questions of <em>human</em> nature on the basis of data drawn from this particularly thin, and rather unusual, slice of humanity.” But see <a href="https://www.cremieux.xyz/p/weird-doesnt-work">Cremieux on weirdness</a> and two papers in response (<a href="https://doi.org/10.1177/25152459231225163">1</a>, <a href="https://doi.org/10.1038/s44271-024-00135-z">2</a>).</p>
</section>
<section id="counterpoints-to-famous-biases-effects-and-stories" class="level2">
<h2 class="anchored" data-anchor-id="counterpoints-to-famous-biases-effects-and-stories">3. Counterpoints to famous biases, effects and stories</h2>
<p><strong>The backfire effect:</strong> <a href="https://slate.com/health-and-science/2018/01/weve-been-told-were-living-in-a-post-truth-age-dont-believe-it.html">Daniel Engber reviews</a> the evidence. I first saw <a href="https://www.wnyc.org/story/walking-back-backfire-effect?tab=transcript">doubts about the effect on WNYC</a>.</p>
<p><strong>Choice overload</strong>: Mark Lepper and Sheena Iyengar’s <a href="https://doi.org/10.1037/0022-3514.79.6.995">famous jam study</a> (<a href="http://werbepsychologie-uamr.de/files/literatur/01_Iyengar_Lepper(2000)_Choice-Overload.pdf">pdf</a>). A <a href="http://jcr.oxfordjournals.org/content/37/3/409">meta-analysis</a> by Benjamin Scheibehenne and friends (<a href="http://scheibehenne.de/ScheibehenneGreifenederTodd2010.pdf">pdf</a>) - the mean effect size of changing the number of choices across the studies was virtually zero (although note the Brian Wansink studies in the meta-analysis!). Other studies point to conditions where it might occur, such as <a href="https://doi.org/10.1016/j.jcps.2014.08.002">Chernev and friends</a> who identify some factors that facilitate choice overload.</p>
<p><strong>Depletion of willpower:</strong> <a href="http://www.slate.com/articles/health_and_science/cover_story/2016/03/ego_depletion_an_influential_theory_in_psychology_may_have_just_been_debunked.html">Daniel Engber summarises</a> the state of affairs. The <a href="http://www.frontiersin.org/journal/10.3389/fpsyg.2014.00823/abstract">meta-analysis</a> referred to by Engber. And the <a href="http://www.psychologicalscience.org/publications/rrr-the-ego-depletion-paradigm">failed replication</a> that triggered the article.</p>
<p><strong>Disfluency:</strong> <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=2007-16657-003">The original N=40 paper</a> (<a href="https://pdfs.semanticscholar.org/526d/fb9f8715d48fa79d0f766caa5cd9151cf074.pdf">pdf</a>). <a href="http://psycnet.apa.org/journals/xge/144/2/e16/">The N=7000 replication</a> (<a href="http://digitalcommons.chapman.edu/cgi/viewcontent.cgi?article=1095&amp;context=esi_pubs">pdf</a>). <a href="http://www.terryburnham.com/2015/04/a-trick-for-higher-sat-scores.html">Terry Burnham tells the story</a>. (And interestingly, Adam Alter, author of the first paper, <a href="https://www.edge.org/response-detail/27024">suggests that the law of small numbers should be more widely known</a>).</p>
<p><strong>Dishonest bankers</strong>: <a href="https://doi.org/10.1038/nature13977">Cohn and colleagues</a> argue that “When their professional identity as bank employees is rendered salient, a significant proportion of them become dishonest”. But look at the data more closely, and primed bankers <a href="../posts/bankers-are-more-honest-than-the-rest-of-us">cheat no more than the student controls</a>. See also <a href="https://doi.org/10.1038/s41586-019-1741-y">Rahwan and friends</a> for a failed replication.</p>
<p><strong>The Florida effect:</strong> The poster child for the replication crisis. <a href="https://www.nationalgeographic.com/science/article/failed-replication-bargh-psychology-study-doyen">Ed Yong catalogues the story</a> nicely.</p>
<p><strong>Grit:</strong> <a href="http://www.slate.com/articles/health_and_science/cover_story/2016/05/angela_duckworth_says_grit_is_the_key_to_success_in_work_and_life_is_this.html">Daniel Engber reviews Angela Duckworth’s book</a>. <a href="../angela-duckworths-grit-the-power-of-passion-and-perseverance/">I review</a>. (I like the way Angela Duckworth deals with criticism. Also listen to this <a href="http://www.econtalk.org/archives/2016/07/angela_duckwort.html">Econtalk episode</a>.)</p>
<p><strong>Growth mindset:</strong> The <a href="https://en.wikipedia.org/wiki/Mindset#Fixed_mindset_and_growth_mindset">Wikipedia summary</a>. <a href="http://slatestarcodex.com/2015/04/08/no-clarity-around-growth-mindset-yet/">Scott Alexander’s initial exploration</a> and <a href="http://slatestarcodex.com/2015/04/10/i-will-never-have-the-ability-to-clearly-explain-my-beliefs-about-growth-mindset/">clarification</a>. A <a href="https://psyarxiv.com/md2qa">pre-registered study</a> and <a href="https://doi.org/10.1177%2F0956797617739704">meta-analysis</a> both showing a tiny but apparently real effect. A more <a href="https://doi.org/10.1037/bul0000352">recent meta-analysis</a> concludes that “Across all studies, we observed a small overall effect … which was nonsignificant after correcting for potential publication bias. … We conclude that apparent effects of growth mindset interventions on academic achievement are likely attributable to inadequate study design, reporting flaws, and bias.”</p>
<p><strong>The hot hand illusion</strong>: The original <a href="https://doi.org/10.1016/0010-0285(85)90010-6">Thomas Gilovich, Robert Vallone and Amos Tversky paper</a> arguing people are seeing a hot hand in basketball when none exists. <a href="https://doi.org/10.3982/ECTA14943">Work by Joshua Miller and Adam Sanjurjo</a> (<a href="https://arxiv.org/pdf/1902.01265.pdf">working paper pdf</a>) shows the original argument was based on a statistical mistake. The hot hand does exist in basketball. (Although I will say that there is plenty of evidence of people seeing patterns where they don’t exist.) <a href="http://www.espn.com.au/nba/story/_/page/presents-19573519/heating-fire-klay-thompson-truth-hot-hand-nba">ESPN explores</a>. My post <a href="../explaining-the-hot-hand-fallacy-fallacy/">here</a>.</p>
<p><strong>Hungry judges:</strong> <a href="https://doi.org/10.1073/pnas.1018033108">Shai Danziger and friends find</a> that favourable rulings by Israeli parole boards plunge in the lead up to meal breaks (from 65% to near 0). <a href="http://journal.sjdm.org/16/16823/jdm16823.html">Andreas Glockner suggests</a> this might be a statistical artefact. <a href="https://doi.org/10.1073/pnas.1110910108">Keren Weinshall-Margela and John Shapard point out</a> that the hearing order is not random (<a href="https://doi.org/10.1073/pnas.1112190108">Danziger and friends respond</a>). And <a href="http://daniellakens.blogspot.com.au/2017/07/impossibly-hungry-judges.html">Daniel Lakens suggests</a> we should dismiss the finding as simply being impossible. My post <a href="../posts/the-effect-is-too-large-heuristic/">here</a>. A similar analysis of <a href="https://doi.org/10.1038/s41562-023-01547-3">judges during Ramadan</a> (<a href="https://www.tse-fr.eu/sites/default/files/TSE/documents/doc/wp/2022/wp_tse_1393.pdf">working paper pdf</a>) finds the opposite effect - they are more lenient when hungry.</p>
<p><strong>Hyperbolic discounting:</strong> Ariel Rubinstein <a href="https://doi.org/10.1111/1468-2354.t01-1-00106">points out that</a> (<a href="http://arielrubinstein.tau.ac.il/papers/67.pdf">pdf</a>) “the same type of evidence, which rejects the standard constant discount utility functions, can just as easily reject hyperbolic discounting as well.”</p>
<p><strong>Illusion of control:</strong> Francesca Gino, Zachariah Sharek and Don Moore <a href="https://doi.org/10.1016/j.obhdp.2010.10.002">note that illusion of control experimental results can be statistical artefacts</a> (<a href="http://learnmoore.org/papers/Gino%20Sharek%20Moore%202011.pdf">pdf</a>). “[B]y focusing on situations marked by low control, prior research has created the illusion that people systematically overestimate their level of control.” My post <a href="../posts/the-illusion-of-the-illusion-of-control/">here</a>.</p>
<p><strong>Loss aversion I:</strong> David Gal and Derek Rucker <a href="https://doi.org/10.1002/jcpy.1047">claim that</a> (<a href="https://ssrn.com/abstract=3049660">working paper</a>) “current evidence does not support that losses, on balance, tend to be any more impactful than gains.” E. Tory Higgins and Nira Liberman <a href="https://doi.org/10.1002/jcpy.1045">respond</a>, as do <a href="https://doi.org/10.1002/jcpy.1046">Itamar Simonson and Ran Kivetz</a>. Gal and Rucker <a href="https://doi.org/10.1002/jcpy.1044">rejoinder</a> (<a href="https://ssrn.com/abstract=3127716">working paper pdf</a>). My post <a href="../posts/the-case-against-loss-aversion/">here</a>. Mrkva and friends also <a href="https://doi.org/10.1002/jcpy.1156">add to the debate</a>.</p>
<p><strong>Loss aversion II:</strong> Eldad Yechiam makes a related argument in <a href="https://doi.org/10.1007/s00426-018-1013-8">Acceptable losses: the debatable origins of loss aversion</a> (<a href="https://ie.technion.ac.il/~yeldad/Y2018.pdf">pdf</a>). My post <a href="../posts/kahneman-and-tverskys-debatable-loss-aversion-assumption/">here</a>. Also see <a href="https://astralcodexten.substack.com/p/on-hreha-on-behavioral-economics">Scott Alexander</a>.</p>
<p><strong>Money priming:</strong> Doug Rohrer, Harold Pashler and Christine Harris <a href="https://doi.org/10.1037/xge0000058">find that subtle reminders of money don’t change people’s political views</a> (<a href="http://uweb.cas.usf.edu/~drohrer/pdfs/Rohrer_et_al_2015JEPG.pdf">pdf</a>). Kathleen Vohs <a href="https://doi.org/10.1037/xge0000091">fights back</a> (<a href="https://pdfs.semanticscholar.org/f3d9/a2a0fd1c361d338d63d8e8306b38e7dea583.pdf">pdf</a>). Miguel Vadillo, Tom Hardwicke and David R. Shanks <a href="http://psycnet.apa.org/journals/xge/145/5/655.html">respond</a>. Analysis of the broader literature on money priming suggests, among other things, massive publication bias.</p>
<p><strong>Moral reminders:</strong> The original (N = 229) <a href="https://doi.org/10.1509/jmkr.45.6.633">paper co-authored by Nina Mazar, On Amir and Dan Ariely</a> (<a href="http://people.duke.edu/~dandan/webfiles/PapersPI/Dishonesty%20of%20Honest%20People.pdf">pdf</a>). The (N=5,786) <a href="https://doi.org/10.1177%2F2515245918781032">multi-lab replication by Verschuere and friends</a>: “This small effect was numerically in the opposite direction of the original study.” More recently, an investigation into the data provenance has led to an <a href="https://doi.org/10.1177/00222437241285882">Expression of Concern</a>. Relatedly, <a href="http://fraudbytes.blogspot.com/2021/08/top-honesty-researcher-dan-ariely-has.html">here</a> and <a href="http://fraudbytes.blogspot.com/2021/08/my-experience-with-arielys-modified.html">here</a> are posts analysing the “shredders” used in some of Ariely’s honesty experiments.</p>
<p><strong>Organ donation:</strong> Does Austria have a 99.94% organ donation rate because of the design of their driver’s licence application? <a href="../posts/charts-that-dont-seem-quite-right-organ-donation-edition/">No</a>.</p>
<p><strong>Overconfidence:</strong> Don Moore and Paul Healy <a href="https://doi.org/10.1037/0033-295X.115.2.502">address the many concepts tangled up in the word “overconfidence”</a>” (<a href="http://healy.econ.ohio-state.edu/papers/Moore_Healy-TroubleWithOverconfidence.pdf">pdf</a>). [My post]/overconfident-about-overconfidence/).</p>
<p><strong>Power pose:</strong> <a href="http://nymag.com/scienceofus/2016/09/power-poses-co-author-i-dont-think-power-poses-are-real.html">Jesse Singal on</a> Dana Carney’s shift from author of the <a href="https://www.ncbi.nlm.nih.gov/pubmed/20855902">classic power pose paper</a> (<a href="http://www.people.hbs.edu/acuddy/in%20press,%20carney,%20cuddy,%20&amp;%20yap,%20psych%20science.pdf">pdf</a>) to skeptic. Carney’s posted a document about her shift <a href="http://faculty.haas.berkeley.edu/dana_carney/pdf_My%20position%20on%20power%20poses.pdf">on her website</a>.</p>
<p><strong>Priming mating motives:</strong> Shanks and friends on <a href="https://doi.org/10.1037/xge0000116">Romance, risk, and replication: Can consumer choices and risk-taking be primed by mating motives?</a> (<a href="http://discovery.ucl.ac.uk/1472788/3/Shanks_Priming%20Mating%20Motives%20ms_FINAL_COMPLETE.pdf">pdf</a>): A failed replication, plus “a meta-analysis of this literature reveals strong evidence of either publication bias or p-hacking.” (I have cited some of these studies approvingly in published work - a mistake.)</p>
<p><strong>Prospect theory:</strong> The <a href="https://behaviouraleconomics.jasoncollins.blog/prospect-theory/prospect-theory">prospect theory model</a>, the centrepiece of behavioural economics, has us as loss averse and risk seeking when facing losses, and risk averse when considering gains. Ryan Oprea proposes that most of the evidence underlying theories of risk, such as prospect theory, actually reflect <a href="https://doi.org/10.1257/aer.20221227"><em>mistakes</em> under complexity</a>.</p>
<p><strong>Safety signs kill motorists</strong>: <a href="https://doi.org/10.1126/science.abm3427">Hall and Madsen proposed</a> that dynamic signs that reported Texas road fatalities - “1669 deaths this year on Texas roads” - caused more accidents and fatalities. I argue that we <a href="../posts/why-i-dont-believe-that-signs-with-fatality-numbers-cause-more-crashes/">shouldn’t take too much</a> from this single paper.</p>
<p><strong>Scarcity:</strong> <a href="../posts/scarcity-of-time-money-friends-and-bandwidth/">My review of the book</a>. <a href="https://doi.org/10.1126/science.1246680">Reanalysis</a> of the <a href="http://doi.org/10.1126/science.1238041">original scarcity paper</a> (<a href="https://scholar.harvard.edu/files/sendhil/files/976.full_.pdf">pdf</a>) without dichotomising income eliminated the effect. The original authors managed to <a href="https://doi.org/10.1126/science.1246799">resurrect the effect</a> (<a href="https://pdfs.semanticscholar.org/7fd6/f9c439607455381c40c9129f8e9773b083a1.pdf">pdf</a>) by combining the data from three experiments, but once you are at this point, you have well and truly entered the <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf">garden of forking paths</a>. Leandro Carvalho and friends <a href="https://doi.org/10.1257/aer.20140481">found that</a> “participants surveyed before and after payday performed similarly on a number of cognitive function tasks.” Then, in a <a href="https://doi.org/10.1073/pnas.2103313118">replication of scarcity papers</a> by O’Donnell and friends: “Of the 20 studies that were significant in the original, four of our replication efforts yielded significant results.”</p>
<p><strong>Signing at the top, part I:</strong> Lisa Shu and friends <a href="https://doi.org/10.1073/pnas.1209746109">report in PNAS</a> that “signing before—rather than after—the opportunity to cheat makes ethics salient when they are needed most and significantly reduces dishonesty.” Ariella Kristal, Ashley Whillans and the authors of the original paper <a href="https://doi.org/10.1073/pnas.1911695117">report a failed replication</a>. A <a href="https://blogs.scientificamerican.com/observations/when-were-wrong-its-our-responsibility-as-scientists-to-say-so/">discussion of what this means in Scientific American</a>. That, of course, is only the beginning of the story (see the fraud story below).</p>
</section>
<section id="fraud-and-misconduct" class="level2">
<h2 class="anchored" data-anchor-id="fraud-and-misconduct">4. Fraud and misconduct</h2>
<p><strong>The Cornell Food and Brand Lab’s catalogue of eating biases (led by Brian Wansink):</strong> <a href="http://nymag.com/scienceofus/2017/02/cornells-food-and-brand-lab-has-a-major-problem.html">Jesse Singal catalogues the events</a>. <a href="https://www.buzzfeed.com/stephaniemlee/brian-wansink-cornell-p-hacking?utm_term=.ve4mg8wPr#.djJEANbMe">Stephanie Lee’s reviews emails from the lab</a>. <a href="http://steamtraen.blogspot.com/2018/02/the-latest-cornell-food-and-brand-lab.html">Corrections</a> and <a href="http://retractiondatabase.org/RetractionSearch.aspx#?auth%3dWansink%252c%2bBrian">retractions</a> are flowing. It’s fair to say that we shouldn’t place any weight on results out of that lab. (Although somewhat amazingly, <a href="https://doi.org/10.1038/oby.2005.12">Wansink’s experiment</a> with a bottomless soup bowl <a href="https://doi.org/10.1037/xge0001503">replicated</a>! I didn’t believe the original experiment ever existed - and am still doubtful that it did.)</p>
<p><strong>Diederik Stapel:</strong> For a long-time, the most salient fraud in social science. The <a href="https://web.archive.org/web/20230830170016/http://www.nytimes.com/2013/04/28/magazine/diederik-stapels-audacious-academic-fraud.html">NYT tells the story</a>. My favourite (now retracted) study of his was on how <a href="https://doi.org/10.1126/science.1201068">trash-filled environments make people racist</a>. For a long time I thought of Stapel as an extreme but rare case of fraud. I now believe fraud is common, but most people don’t leave such a trail.</p>
<p><strong>Francesca Gino:</strong> In a series of four posts (<a href="https://datacolada.org/109">1</a>, <a href="https://datacolada.org/110">2</a>, <a href="https://datacolada.org/111">3</a>, <a href="https://datacolada.org/112">4</a>), the Data Colada team document a series of frauds in Francesca Gino’s work. Failing to recall <a href="https://en.wikipedia.org/wiki/Streisand_effect">Barbara Streisand’s experience</a>, Gino <a href="https://www.vox.com/future-perfect/23841742/francesca-gino-data-colada-lawsuit-gofundme-science-culture-transparency-academic-fraud-dishonesty">sued the Data Colada team</a>. The lawsuit was <a href="https://doi.org/10.1126/science.zciy6ft">later dismissed</a> (although as at the time of writing, Gino’s claim against Harvard remains ongoing). Fortunately, the <a href="https://datacolada.org/wp-content/uploads/Harvard-Report-on-Gino.pdf">Harvard investigation</a> was made public as a result of the court proceedings, allowing even more <a href="https://datacolada.org/118">analysis by the Data Colada team</a> into how the fraud was perpetrated.</p>
<p><strong>Signing at the top, part II:</strong> The field trial data from the signing at the top study (noted above) <a href="https://datacolada.org/98">was completely made up</a>. This led to the paper being <a href="https://doi.org/10.1073/pnas.2115397118">retracted</a> and an investigation into Ariely (that ultimately reached <a href="https://danariely.com/wp-content/uploads/2024/04/ArielyEndofIStatment.pdf">no adverse findings</a>). That, of course, was only one of two frauds in this paper. The other, also <a href="https://datacolada.org/109">uncovered by the Data Colada team</a>, was that the data in experiment 1 had been manipulated. Absent the manipulation, there was no effect.</p>
</section>
<section id="applications-of-behavioural-economics-and-nudging" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-behavioural-economics-and-nudging">5. Applications of behavioural economics (and nudging)</h2>
<p><strong>Government failure I:</strong> In <a href="http://johnhcochrane.blogspot.com.au/2015/05/homo-economicus-or-homo-paleas.html">Homo economicus or homo paleas?</a>, John Cochrane states that “The case for the free market is not that each individual’s choices are perfect. The case for the free market is long and sorry experience that government bureaucracies are pretty awful at making choices for people.” Noah Smith <a href="http://www.bloombergview.com/articles/2015-06-01/a-dose-of-psychology-does-economics-field-some-good">responds</a>.</p>
<p><strong>Government failure II:</strong> Ted Gayer <a href="https://www.brookings.edu/on-the-record/energy-efficiency-risk-and-uncertainty-and-behavioral-public-choice/">writes that</a> “the main failure of rationality is not with the energy-using consumers and firms, but instead the main failure of rationality is with the regulators themselves.” Two related papers by Gayer and W. Kip Viscusi are <a href="https://www.mercatus.org/publication/overriding-consumer-preferences-energy-regulations">Overriding Consumer Preferences With Energy Regulations</a> (<a href="https://www.mercatus.org/system/files/Energy_regulations_GayerViscusi_WP1221_1.pdf">pdf</a>) and <a href="https://www.brookings.edu/articles/behavioral-public-choice-the-behavioral-paradox-of-government-policy/">Behavioral Public Choice: The Behavioral Paradox of Government Policy</a> (<a href="http://harvardjlpp.wpengine.com/wp-content/uploads/2010/01/ViscusiGayer_4.pdf">pdf</a>)</p>
<p><strong>Implementation:</strong> <a href="https://doi.org/10.1086/729447">DellaVigna, Kim and Linos find</a> that a nudge trial with a negative result is almost as likely to be implemented as a positive result.</p>
<p><strong>A manifesto for applying behavioural science:</strong> Michael Hallsworth writes a <a href="https://doi.org/10.1038/s41562-023-01555-3">manifesto for applying behavioural science</a> (longer and ungated BIT version <a href="https://www.bi.team/publications/a-manifesto-for-applying-behavioral-science/">here</a>). A few <a href="../posts/a-comment-on-the-manifesto-for-behavioural-science">observations from me</a>.</p>
<p><strong>More than nudging I:</strong> Reuben Finighan <a href="http://melbourneinstitute.unimelb.edu.au/__data/assets/pdf_file/0005/2168195/pb2015n04.pdf">looks beyond nudging</a> (pdf), stating that “Policymakers often mistakenly see behavioural policy as synonymous with”nudging”. Yet nudges are only one part of the value of the behavioural revolution—and not even the lion’s share”</p>
<p><strong>More than nudging II:</strong> George Loewenstein and Nick Chater <a href="https://doi.org/10.1017/bpp.2016.7">put nudges in perspective</a>, writing that “This paper aims to remind policy-makers that behavioural economics can influence policy in a variety of ways, of which nudges are the most prominent but not necessarily the most powerful.” <a href="https://bppblog.com/2017/06/02/much-ado-about-nudging/">Richard Thaler responds</a>. Chater and Loewenstein later <a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/iframe-and-the-sframe-how-focusing-on-individuallevel-solutions-has-led-behavioral-public-policy-astray/A799C9C57F388A712BE5A8D34D5229A1#">took this critique further</a>, arguing that the belief that society’s problems can be addressed cheaply and effectively at the level of the individual, without modifying the system in which the individual operates, is a mistake.</p>
<p><strong>Paternalism:</strong> Robert Sugden <a href="https://doi.org/10.1080/0020174X.2013.806139">writes that</a> (<a href="https://www.tandfonline.com/doi/pdf/10.1080/0020174X.2013.806139?casa_token=Vohf6wMlldMAAAAA:LFQmXYGKKEadyXBC1aq2NulpsT9f_PGuc3DfvRMF7nuyZCbkjkXkD4cZiTqu3AqWrExIGX8ooHhsNtM">pdf</a>) “The claim that the paternalist is merely implementing what the individual would have chosen for herself under ideal conditions is a common theme in paternalistic arguments, but should always be viewed with scepticism.” Also see Sugden’s <a href="https://doi.org/10.1007/s12232-016-0264-1">Do people really want to be nudged towards healthy lifestyles?</a>, Sunstein’s <a href="https://doi.org/10.1007/s12232-017-0280-9">response</a> (<a href="https://poseidon01.ssrn.com/delivery.php?ID=084013121017005091028095106125026109118032061048043044009117119089082113106094066092005049039026020056054098116089088118100077108057014069082023066084005073071102065045091091083011024002086098077116079085090067099118020002071086020031118067065069066&amp;EXT=pdf">pdf</a>) and Sugden’s <a href="https://link.springer.com/article/10.1007/s12232-017-0281-8">rejoinder</a>.</p>
<p><strong>Policy failure I:</strong> Philip Booth <a href="https://iea.org.uk/behavioural-economics-a-critique-of-its-policy-conclusions/">notes that</a> “We seem to have gone … to a situation where we have regulators who use economics 101 supplemented with behavioural economics to try to bring perfection to markets that simply cannot be perfected and perhaps cannot be improved.”</p>
<p><strong>Policy failure II:</strong> Tim Harford <a href="https://www.ft.com/content/9d7d31a4-aea8-11e3-aaa6-00144feab7de?mhq5j=e1">writes that</a> “The appeal of a behavioural approach is not that it is more effective but that it is less unpopular.” (Google the article and go through that link if you hit the paywall.)</p>
<p><strong>Policy failure III:</strong> George Loewenstein and Peter Ubel <a href="http://www.nytimes.com/2010/07/15/opinion/15loewenstein.html?hp">argue that</a> “behavioral economics is being used as a political expedient, allowing policymakers to avoid painful but more effective solutions rooted in traditional economics.”</p>
<p><strong>Policy failure IV:</strong> In a Behavioural and Brain Sciences target article, George Loewenstein and Nick Chater <a href="https://doi.org/10.1017/S0140525X23002091">argue</a> that focussing on interventions at the individual level is inadvertently preventing systemic change. There are many <a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/where-next-for-behavioral-public-policy/C1122FBA28BAC79981D42F2875E2B5F5#related-commentaries">responses</a>, but I’ll highlight those by <a href="https://doi.org/10.1017/S0140525X23000924">Michael Hallsworth</a>, <a href="https://doi.org/10.1017/S0140525X23000912">David Gal and Derek Rucker</a>, <a href="https://doi.org/10.1017/S0140525X23001097">Cass Sunstein</a>, <a href="https://doi.org/10.1017/S0140525X23000973">Richard Thaler</a> and <a href="https://doi.org/10.1017/S0140525X23000936">Ralph Hertwig</a>.</p>
</section>
<section id="if-you-want-some-background" class="level2">
<h2 class="anchored" data-anchor-id="if-you-want-some-background">6. If you want some background</h2>
<p>I know this list is of critiques, but here are a few books I would recommend if you want a basic background.</p>
<p>Daniel Kahneman’s <a href="../posts/kahnemans-thinking-fast-and-slow/">Thinking, Fast and Slow</a> is still the best popular overview of behavioural science. However, it is <a href="../posts/re-reading-kahnemans-thinking-fast-and-slow/">not standing the test of time particularly well</a>. Here is a fantastic <a href="https://replicationindex.wordpress.com/2017/02/02/reconstruction-of-a-train-wreck-how-priming-research-went-of-the-rails/">analysis of the priming chapter</a>, and <a href="https://replicationindex.wordpress.com/2017/02/02/reconstruction-of-a-train-wreck-how-priming-research-went-of-the-rails/#comment-1454">Kahneman’s response</a> to that review in the comments. <a href="https://replicationindex.com/2020/12/30/a-meta-scientific-perspective-on-thinking-fast-and-slow/">A review of the estimated replicability</a> of all the chapters is similarly damming. It’s unfortunate that something better hasn’t yet emerged. Just pair it with this reading list!</p>
<p>Erik Angner’s <em>A Course in Behavioral Economics</em> is a good and readable academic presentation of the core principles of behavioural economics.</p>
<p>Cass Sunstein and Richard Thaler’s <em>Nudge: The Final Edition</em> is not my favourite book, but it’s a useful to understand the mindset of many nudge proponents.</p>
<p>Richard Thaler’s <em>Misbehaving</em> is a pretty good (although very US-centric) history of behavioural economics.</p>
<p>Michael Lewis’s <a href="../posts/michael-lewiss-the-undoing-project-a-friendship-that-changed-the-world/">The Undoing Project</a> is an accessible overview of Kahneman and Tversky’s work.</p>
<p>Michael Hallsworth and Elspeth Kirkman’s <a href="https://mitpress.mit.edu/9780262539401/behavioral-insights/">Behavioral Insights</a> is a solid book on translating behavioural science into applied public policy.</p>


</section>

 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/a-critical-behavioural-economics-and-behavioural-science-reading-list.html</guid>
  <pubDate>Wed, 19 Feb 2025 02:00:00 GMT</pubDate>
</item>
<item>
  <title>Books I read in 2024</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/books-i-read-in-2024.html</link>
  <description><![CDATA[ 




<p>The books I enjoyed the most in 2024, although all were published in different years:</p>
<ul>
<li>Ashlee Vance, <em>When the Heavens Went on Sale</em>: For all the grumbling about how progress in software isn’t matched in the physical world, Vance tells some amazing stories. The tale about how Planet Labs got going using smartphone technology to make shoebox size satellites was fantastic.</li>
<li>Julia Galef, <em>The Scout Mindset: Why Some People See Things Clearly and Others Don’t</em>: Wonderfully practical. I enter almost every psychology or behavioural science related book dreading the shaky scientific studies I will be dragged through. But Galef did a great job of knowing when to pull out a study (not often) and when to build a more practical case.</li>
<li>William Poundstone, <em>Fortune’s Formula: The Untold Story of the Scientific Betting System That Beat the Casinos and Wall Street</em>: A good balance of technicality and colour.</li>
<li>Kurt Vonnnegut, <em>Player Piano</em>: Simply a great story.</li>
</ul>
<p>Below is the list of books I read in 2024 (with a star if I have read them before). My volume of my reading of books cover-to-cover has increased from 2023, with 49 total (26 non-fiction, 23 fiction).</p>
<p><em>Non-Fiction</em></p>
<ul>
<li>Kathryn Astbury and Robert Plomin, <em>G is for Genes: The Impact of Genetics on Education and Achievement</em></li>
<li>Eric Berger, <em>Liftoff: Elon Musk and the Desperate Early Days that Launched SpaceX</em></li>
<li>Eric Berger, <em>Reentry: SpaceX, Elon Musk, and the Reusable Rockets that Launched a Second Space Age</em></li>
<li>Dalton Conley and Jason Fletcher, <em>The Genome Factor: What the Social Genomics Revolution Reveals about Ourselves, Our History, and the Future</em></li>
<li>Tyler Cowen and Daniel Gross, <em>Talent: How to Identify Energizers, Creatives and Winners Around the World</em></li>
<li>Kate Crawford, <em>Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence</em></li>
<li>Nir Eyal, <em>Indistractable: How to Control Your Attention and Choose Your Life</em></li>
<li>Bent Flyvbjerg and Dan Gardner, <em>How Big Things Get Done</em></li>
<li>Martin Ford, <em>Architects of Intelligence</em></li>
<li>Julia Galef, <em>The Scout Mindset: Why Some People See Things Clearly and Others Don’t</em></li>
<li>Michael Greger, <em>How Not to Age</em></li>
<li>Saul Griffith, <em>Electrify: An Optimist’s Playbook for Our Clean Energy Future</em></li>
<li>Kathryn Paige Harden, <em>The Genetic Lottery: Why DNA Matters for Social Equality</em> *</li>
<li>Michel Lewis, <em>Going Infinite: The Rise and Fall of a New Tycoon</em></li>
<li>Ethan Mollick, <em>Co-Intelligence: Living and Working with AI</em></li>
<li>Charles Murray, <em>Human Diversity: The Biology of Gender, Race and Class</em></li>
<li>Cal Newport, <em>Slow Productivity</em></li>
<li>Toby Ord, “The Precipice: Existential Risk and the Future of Humanity”</li>
<li>Robert Plomin, <em>Blueprint: How DNA makes us who we are</em></li>
<li>William Poundstone, <em>Fortune’s Formula: The Untold Story of the Scientific Betting System That Beat the Casinos and Wall Street</em></li>
<li>Nichola Raihani, <em>The Social Instinct</em></li>
<li>Rebecca Reider, <em>Dreaming the Biosphere</em></li>
<li>Edward O Thorpe, <em>A Man for All Markets: Beating the Odds from Las Vegas to Wall Street</em></li>
<li>Ashlee Vance, <em>When the Heavens Went on Sale</em></li>
<li>Walter Willett, <em>Eat, Drink and Be Healthy</em></li>
<li>Scott H Young, <em>Get Better at Anything</em></li>
</ul>
<p><em>Fiction</em></p>
<ul>
<li>Edward Abbey, <em>The Brave Cowboy</em></li>
<li>Isaac Asimov, <em>I, Robot</em></li>
<li>Isaac Asimov, <em>The Caves of Steel</em></li>
<li>Isaac Asimov, <em>The Naked Sun</em></li>
<li>Isaac Asimov, <em>The Robots of Dawn</em></li>
<li>Isaac Asimov, <em>The Complete Robot</em></li>
<li>Isaac Asimov, <em>Robots and Empire</em></li>
<li>Margaret Atwood, <em>The Handmaid’s Tale</em> *</li>
<li>Orson Scott Card, <em>Ender’s Game</em></li>
<li>Orson Scott Card, <em>Speaker for the Dead</em></li>
<li>Ernest Cline, <em>Ready Player One</em></li>
<li>Philip K Dick, <em>Do Androids Dream of Electric Sheep</em></li>
<li>Robert Heinlein, <em>Starship Troopers</em></li>
<li>Daniel Keyes, <em>Flowers for Algernon</em></li>
<li>Madeleine L’Engle, <em>A Wrinkle in Time</em></li>
<li>Madeleine L’Engle, <em>A Wind in the Door</em></li>
<li>Madeleine L’Engle, <em>A Swiftly Tilting Planet</em></li>
<li>John le Carrè, <em>A Perfect Spy</em> *</li>
<li>Cormac McCarthy, <em>Stella Maris</em></li>
<li>Cormac McCarthy, <em>The Passenger</em></li>
<li>Richard Matheson, <em>I Am Legend</em></li>
<li>Walter Tevis, <em>The Queen’s Gambit</em> *</li>
<li>Kurt Vonnnegut, <em>Player Piano</em></li>
</ul>
<p>Previous annual book lists: <a href="../posts/top-10-books-in-2010.html">2010</a>, <a href="../posts/best-books-i-read-in-2011.html">2011</a>, <a href="../posts/the-best-books-i-read-in-2012.html">2012</a>, <a href="../posts/best-books-i-read-in-2013.html">2013</a>, <a href="../posts/best-books-i-read-in-2014.html">2014</a>, <a href="../posts/best-books-i-read-in-2015.html">2015</a>, <a href="../posts/best-books-i-read-in-2016.html">2016</a>, <a href="../posts/best-books-i-read-in-2017.html">2017</a>, <a href="../posts/books-i-read-in-2018.html">2018</a>, <a href="../posts/best-books-i-read-in-2019.html">2019</a>, <a href="../posts/best-books-i-read-in-2020.html">2020</a>, <a href="../posts/best-books-i-read-in-2021.html">2021</a>, <a href="../posts/books-i-read-in-2022.html">2022</a>, <a href="../posts/books-i-read-in-2023.html">2023</a></p>



 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/books-i-read-in-2024.html</guid>
  <pubDate>Fri, 17 Jan 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Human-AI collaboration: is it better when the human is asleep at the wheel?</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/human-ai-collaboration-is-it-better-when-the-human-is-asleep-at-the-wheel.html</link>
  <description><![CDATA[ 




<p>In his book Co-Intelligence: Living and Working with AI, <a href="https://www.oneusefulthing.org/">Ethan Mollick</a> describes an experiment by Fabrizio Dell’Acqua:</p>
<blockquote class="blockquote">
<p>In a different paper, Fabrizio Dell’Acqua shows why relying too much on AI can backfire. He found that recruiters who used high-quality AI became lazy, careless, and less skilled in their own judgment. They missed out on some brilliant applicants and made worse decisions than recruiters who used low-quality AI or no AI at all.</p>
<p>He hired 181 professional recruiters and gave them a tricky task: to evaluate 44 job applications based on their math ability. The data came from an international test of adult skills, so the math scores were not obvious from the résumés. Recruiters were given different levels of AI assistance: some had good or bad AI support, and some had none. He measured how accurate, how fast, how hardworking, and how confident they were.</p>
<p>Recruiters with higher-quality AI were worse than recruiters with lower-quality AI. They spent less time and effort on each résumé, and blindly followed the AI recommendations. They also did not improve over time. On the other hand, recruiters with lower-quality AI were more alert, more critical, and more independent. They improved their interaction with the AI and their own skills. Dell’Acqua developed a mathematical model to explain the trade-off between AI quality and human effort. When the AI is very good, humans have no reason to work hard and pay attention. They let the AI take over instead of using it as a tool, which can hurt human learning, skill development, and productivity. He called this “falling asleep at the wheel.”</p>
</blockquote>
<p>What are the costs of falling asleep at the wheel? We can get a better sense from the as yet <a href="https://www.dropbox.com/scl/fi/c5jdi146erky69csa8gha/Falling_Asleep_at_the_Wheel.pdf?rlkey=ss4vh6bsgzf52xiba8ffx0onc&amp;e=1&amp;st=s0ppis9g&amp;dl=0">unpublished working paper</a>. (I expect it will be published somewhere reasonably prestigious before too long.)</p>
<p>The “bad AI” had an accuracy of 75%. The “good AI” had an accuracy of 85%. What was the accuracy of the recruiters? My reading of Table 4 of the paper is that, without any AI support, the recruiters had 72.3% accuracy. With the bad AI that was 75.4%, and with good AI was 74.4%. So on the raw outcome, about the same across all three treatments. (I’ve based these calculations on the assumption that the results come from a linear regression for columns (1) and (2). The author could have used a logistic regression given the binary dependent variable, but the magnitude of the coefficients suggests that isn’t the case.)</p>
<p>But think about what we could achieve if we just eliminated the recruiters. The recruiters with the bad AI add nothing. Their deviations from the AI recommendations are a wash. The recruiters with the good AI intervene enough to degrade the performance from 85% to 74%. If anything, the recruiters with the bad AI aren’t asleep enough! If they didn’t do a thing, they’d get 85% accuracy. Instead of thinking about getting recruiters to pay attention, we should remove them from simple prediction tasks like this.</p>
<p>The underperformance of human-AI combinations is a common theme across the literature on statistical versus human prediction. Combine a human with a good algorithm and you will improve the human’s performance. However, their performance will still be below the level of the algorithm alone. (I’ve written in <a href="https://behavioralscientist.org/dont-touch-computer/">Behavioural Scientist</a> on this previously.)</p>
<p>Before moving on, I should point out that the measure of decision quality highlighted in the preregistration was not the decision to interview the candidate, but rather a measure of confidence. (I can’t check this as the pre-registration is embargoed.) For each decision, recruiters were asked to rate their confidence on a 1 to 5 scale. Using this confidence measure, the recruiters with the bad AI performed significantly better than those with the good AI (scraping under the 0.05 threshold once some additional controls are added). I can’t confirm from the paper whether the good AI model would outperform on this measure - or even whether it generates measures of confidence - but I’d be very surprised if a model wouldn’t outperform.</p>
<section id="understanding-ai-quality" class="level2">
<h2 class="anchored" data-anchor-id="understanding-ai-quality">Understanding AI quality</h2>
<p>Having said the above, it’s unclear what is driving the headline result and whether it would replicate. The recruiters were given one of the following descriptions. For the good AI:</p>
<blockquote class="blockquote">
<p>The AI tool that will support you has been performing very well in prior analysis and we have been very pleased with the candidates selected. However, it made a few mistakes for candidates that were close calls.</p>
<p>We reviewed the algorithm’s recommendations using performance data, and we found that the vast majority of AI’s recommendations about whether to interview a candidate or not were correct (about 85% of cases).</p>
</blockquote>
<p>Those who were given the bad AI read:</p>
<blockquote class="blockquote">
<p>The AI tool that will support you has been performing well in prior analysis and we have been pleased with the candidates selected. However, it made some mistakes for candidates that were close calls.</p>
<p>We reviewed the algorithm’s recommendations using performance data, and we found that the large majority of AI’s recommendations about whether to interview a candidate or not were correct (about 75% of cases).</p>
</blockquote>
<p>The differences are performed “very well” versus “well”, “very pleased” versus “pleased”, making “a few” versus “some” mistakes, “vast majority” versus “large majority”, and “85%” versus “75%”.</p>
<p>Which change or changes are driving the effect? We can’t tell. I lean toward the accuracy numbers having no effect. People tend not to react differently to numbers in those ranges. The words might be doing something, but which ones? The framing of the mistakes? How pleased the developers are?</p>
<p>Further, is the problem identified in the experiment giving people a good AI or if it is describing it poorly? We could easily have used the bad AI description for the good AI (except the number, which I predict has no effect). Would we see an effect if we gave the bad AI description (except for the number) for the good AI? If not, we’ve solved the asleep at the wheel problem!</p>
<p>I’d love to see a replication of this experiment, mixing the combinations of words to understand better what people are hooking into. My hunch is that the differences in accuracy wouldn’t replicate. This paper has some of the classic signs: a weak treatment and a p-value scraping under 0.05. (I’m more optimistic about time and effort.)</p>


</section>

 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/human-ai-collaboration-is-it-better-when-the-human-is-asleep-at-the-wheel.html</guid>
  <pubDate>Thu, 05 Dec 2024 00:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/asleep-at-the-wheel.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>What we learn when we test everything</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/what-we-learn-when-we-test-everything.html</link>
  <description><![CDATA[ 




<p>The below are my speaking notes for a presentation in the Innovative methodologies in behavioural science session at <a href="https://behaviouraleconomics.pmc.gov.au/bi-connect-2024">BI Connect 2024</a>, hosted by the Behavioural Economics Team of the Australian Government (BETA) in the Department of Prime Minister and Cabinet.</p>
<p>The notes reflect many of the themes discussed in more detail in a <a href="../megastudy-scepticism">previous post on megastudies</a>.</p>
<p>When BETA posts the video of the session, I will link here.</p>
<hr>
<p>I’m going to start with a story about a <a href="https://web.archive.org/web/20061106031902/http://www.netflixprize.com/index">competition held by Netflix</a>.</p>
<p>They offered $1 million to the team that could develop an algorithm that could predict film ratings with 10% better accuracy than Netflix’s own model. The competition began in October 2006, and by June 2007 over 20 000 teams had registered for the competition and 2000 teams had submitted predictions. The prize was <a href="https://web.archive.org/web/20090926213457/http://www.netflixprize.com/leaderboard">claimed in 2009</a>, albeit the prize algorithm was never implemented by Netflix.</p>
<p>Competitions of this nature now underpin much progress in artificial intelligence. Many date the genesis of the current AI boom to the success of the deep convolutional neural net called AlexNet in the <a href="https://www.image-net.org/challenges/LSVRC/2012/results.html">2012 edition</a> of the <a href="https://www.image-net.org/challenges/LSVRC/index.php">ImageNet Large Scale Visual Recognition Challenge</a>.</p>
<p><a href="https://www.kaggle.com/">Kaggle</a> has industrialised the running of these competitions for private and government entities. The organisation submits a problem and data, and competitors compete to develop the best algorithm. This <a href="https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2">Math Olympiad competition</a> is running now. You can see that 1754 submissions had already been made by participants at the time I took this snapshot.</p>
<p><a href="img/what-we-learn-when-we-test-everything/kaggle-math-olympiad.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://www.jasoncollins.blog/posts/img/what-we-learn-when-we-test-everything/kaggle-math-olympiad.png" class="img-fluid" style="width:80.0%"></a></p>
<p>We have also seen informal competitions emerge, such as the measuring of generative AI against standardised benchmarks. When a new version of Claude, ChatGPT, Gemini or Llama is released, they often release measures of their performance against these benchmarks, such as <a href="https://www.anthropic.com/news/3-5-models-and-computer-use">in this screenshot</a>.</p>
<p><a href="img/what-we-learn-when-we-test-everything/claude-benchmarking.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://www.jasoncollins.blog/posts/img/what-we-learn-when-we-test-everything/claude-benchmarking.png" class="img-fluid" style="width:60.0%"></a></p>
<p>The approach that underpins these competitions and comparisons is known as the common task framework. Researchers compete to solve the a problem using the same dataset, with each measured against the same scale.</p>
<p>There are many benefits to the common task framework. We have objective measures of performance. We can see what is the state of the art. We can compare apples with apples.</p>
<p>There are also some downsides to the common task framework that I will come to later.</p>
<section id="megastudies" class="level2">
<h2 class="anchored" data-anchor-id="megastudies">Megastudies</h2>
<p>Is there a behavioural science version of the common task framework?</p>
<p>According to some behavioural scientists, the answer is yes - the megastudy. First labelled megastudy in 2021, the idea behind the megastudy is to test many interventions in a single massive experiment. Don’t test one intervention against a control. Test 50. Put these interventions in direct competition with each other.</p>
<p>This idea of testing many interventions in this way has been around since before the behavioural scientists put on their marketing hat, called it the megastudy and published it in Nature. But the megastudy has certainly increased in frequency over the last couple of years.</p>
<p>There is a fairly simple case for the megastudy. We have many studies showing the effects of idiosyncratic behavioural interventions. We have social norms. Loss framing. Scarcity. Incentives. And so on. Which is more effective in achieving the behaviour change you want? We often can’t answer this as the various interventions aren’t directly compared against each other in the academic literature. The typical academic paper compares one intervention or class of similar interventions against a control.</p>
<p>A megastudy enables us to make that comparison.</p>
</section>
<section id="increasing-gym-attendance" class="level2">
<h2 class="anchored" data-anchor-id="increasing-gym-attendance">Increasing gym attendance</h2>
<p>To illustrate, let me walk through the highest-profile megastudy, which as I hinted was published in Nature.</p>
<p>Katherine Milkman and friends <span class="citation" data-cites="milkman2021">(2021)</span> tested 54 interventions to increase the gym visits of 61,000 experimental participants.</p>
<p>Members of a national gym chain were asked if they wished to enrol in a “habit-building science-based workout program”. Those who signed up formed the subject pool and were randomly assigned to the experimental conditions, including a control under which they received no further contact.</p>
<p><a href="img/what-we-learn-when-we-test-everything/milkman_et_al_2021_signup.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://www.jasoncollins.blog/posts/img/what-we-learn-when-we-test-everything/milkman_et_al_2021_signup.png" class="img-fluid" style="width:60.0%"></a></p>
<p>Over the following 28-days participants were subject to interventions involving varying mixes of incentives and messages. For example, those in the “Social norm (high and increasing)” treatment group received six text message reminders, with content such as:</p>
<blockquote class="blockquote">
<p>Trivia time! What percent of Americans exercised at least 3 times per week in 2016? Reply 1 for 61%, 2 for 64%, 3 for 70% or 4 for 73%.</p>
</blockquote>
<p>If they respond 1, 2 or 3, they receive a message back stating:</p>
<blockquote class="blockquote">
<p>It’s actually 73%. And this is up from 71% in 2015.</p>
</blockquote>
<p>They also received emails with similar facts.</p>
<p>Those in the “Social norm (low)” group received messages with a less rosy situation:</p>
<blockquote class="blockquote">
<p>Trivia time! What percent of Americans exercised at least 3 times per week in 2016? Reply 1 for 35%, 2 for 38%, 3 for 41% or 4 for 44%</p>
</blockquote>
<p>As an aside, there don’t seem to be any qualms about using deception here.</p>
<p>Some interventions involved incentives. For example, the “Rigidity Rewarded” intervention paid 500 Amazon points worth $1.79 each time they attended a planned gym visit, and 250 Amazon points worth $0.90 if they attended the gym at another time.</p>
<p>The headline results of all the interventions are in this figure, with the effect sizes and their 95% confidence intervals represented by the blue lines. The intervention with the largest effect size involved incentives for returning to the gym after a missed workout.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Milkman et al.&nbsp;(2021a) Figure 1</figcaption>
<p><a href="img/what-we-learn-when-we-test-everything/milkman_et_al_2021_figure_1.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Milkman et al.&nbsp;(2021a) Figure 1"><img src="https://www.jasoncollins.blog/posts/img/what-we-learn-when-we-test-everything/milkman_et_al_2021_figure_1.jpeg" class="img-fluid figure-img" style="width:90.0%" alt="Milkman et al.&nbsp;(2021a) Figure 1"></a></p>
</figure>
</div>
<p>Twenty-four of the 53 interventions were found to have a statistically significant effect over the control of no messages, increasing visits by between 9% and 27%. That equates to 0.14 to 0.40 extra weekly gym visits over the control average of 1.48 visits per week.</p>
<p>This figure also contains predictions made by behavioural practitioners, public health academics and lay people - those orange bars on the right indicate the overestimation of effect and lack of any relationship between the predictions and the results. I’ll briefly touch on these predictions later.</p>
</section>
<section id="increasing-vaccination-rates" class="level2">
<h2 class="anchored" data-anchor-id="increasing-vaccination-rates">Increasing vaccination rates</h2>
<p>Another megastudy by most of the same authors released that same year <span class="citation" data-cites="milkman2021a">(2021)</span> looked at a series of messages to encourage vaccination. For example:</p>
<blockquote class="blockquote">
<p>John, this is a reminder that a flu vaccine has been reserved for your appt with Dr.&nbsp;Smith. Please ask your doctor for the shot to make sure you receive it.</p>
</blockquote>
<p>Again, a bit deceptive as there was no reserved vaccine, but as you can see in this chart, that particular message of a highlighted flu dose was the most effective.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Milkman et al.&nbsp;(2021) Figure 1</figcaption>
<p><a href="img/what-we-learn-when-we-test-everything/milkman_et_al_2021a_fig_1.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Milkman et al.&nbsp;(2021) Figure 1"><img src="https://www.jasoncollins.blog/posts/img/what-we-learn-when-we-test-everything/milkman_et_al_2021a_fig_1.jpg" class="img-fluid figure-img" style="width:75.0%" alt="Milkman et al.&nbsp;(2021) Figure 1"></a></p>
</figure>
</div>
<p>Beyond giving us direct comparability, there are some other nice features about megastudies. There are economies to scale: while an individual megastudy is a large exercise, the cost can be lower on a per-intervention basis.</p>
<p>Megastudies also have built-in publication of null findings. We get to see both the successful interventions and the duds.</p>
</section>
<section id="generalising" class="level2">
<h2 class="anchored" data-anchor-id="generalising">Generalising</h2>
<p>But what can you as a practitioner or behavioural scientist do with the output of a megastudy?</p>
<p>If you are that particular gym chain or vaccination provider for which the megastudy was conducted, you might scale the most successful messaging.</p>
<p>But what if you are operating in a different context? What if you are a different gym chain with different customer demographics? A yoga studio? A chess club? A university encouraging student attendance? A preventative health provider?</p>
<p>As the authors of these papers argue, the fundamental problem that the megastudy is designed to address is the lack of comparability of interventions tested in different contexts. The context of two different experiments may be sufficiently different that it is not reasonable to ask which intervention is more effective.</p>
<p>But if we cannot easily compare across experiments in different contexts, what confidence can you have that the ordering or magnitude of intervention effect sizes in the megastudy will be reflected in a different context?</p>
<p>We are in a Catch-22 situation. The bigger the comparability problem that the megastudy is seeking to solve, the less useful the megastudy results are for application in other contexts.</p>
<p>Ultimately, this is why good policy or business advice should typically be to run your own experiment.</p>
<p>There is also the question of translating the particular interventions into the new contexts. There are so many degrees of freedom in developing a message, from the visual design, to the precise wording, to the choice of medium, to the timing. The result is that your translated intervention may not capture what drove the success of the previous intervention. The copy may not convey the concept. The wording may be confusing. And so on.</p>
<p>This message from the first megastudy on vaccinations was the worst performing:</p>
<blockquote class="blockquote">
<p>It’s flu season &amp; getting a flu shot at your appt is an easy thing you can do to be healthy!</p>
</blockquote>
<p>Who were their copywriters?! I would argue that the poor performance of this message gives little information about the effectiveness of health messaging.</p>
<p>This implementation problem again points to the advice: test in your own domain. A megastudy isn’t going to save you from doing that.</p>
</section>
<section id="power" class="level2">
<h2 class="anchored" data-anchor-id="power">Power</h2>
<p>And this brings me to possibly the biggest challenge with megastudies.</p>
<p>On its face, megastudies have the benefit of getting a large sample. A total of 61,293 participants for the gym megastudy sounds solid.</p>
<p>But it doesn’t take much thought to realise that across 54 interventions (including the control) there is an average of not much more than 1000 participants per intervention. And that relatively small number of participants means that we have low power - that is, a low ability to detect any effects that exist and to differentiate between interventions.</p>
<p>For instance, while the largest effect size in the gym megastudy involved a bonus for returning after a missed workout, this effect size was indistinguishable from around half the other interventions.</p>
<p>The megastudy on vaccinations has the same problem. The 19 interventions across 47 000 participants boosted vaccinations by an average of 2.1 percentage points, but the authors noted that they could not reject the null hypothesis that all 19 effects have the same true value. A megastudy where we can’t tell which message works.</p>
<p>Not all megastudies have this problem, but they highlight an issue that we always grapple with as experimentalists. Increasing the number of interventions reduces power unless we can commensurately increase sample size. There’s a tradeoff, and sometimes you’re better off with fewer interventions.</p>
</section>
<section id="building-theory" class="level2">
<h2 class="anchored" data-anchor-id="building-theory">Building theory</h2>
<p>Beyond the applied nature of these megastudies, another question worth asking is what they offer to science. The flagship megastudy paper was published in Nature after all.</p>
<p>To address this, let me first describe an experiment by Google.</p>
<p>When you visit Google online, they really want you to click on advertising links. What colour link is most likely to induce a click?</p>
<p>Google doesn’t mess around in answering questions such as this. In one experiment, they <a href="https://www.theguardian.com/technology/2014/feb/05/why-google-engineers-designers">tested 41 shades of blue</a>. While this experiment was ridiculed by outsiders as the “50 shades of blue” episode, it yielded an additional $200 million dollars a year in revenue.</p>
<p>Where do megastudies sit between this Google experiment - a valuable optimisation exercise with limited scientific value - and a study designed to teach us something about how the world works.</p>
<p>To date, I’d argue that megastudies are closer to the Google end of the spectrum. They’re valuable for the task being optimised, but provide limited feedback into our theoretical understanding of human behaviour.</p>
<p>Each intervention tested in the megastudy is derived from empirical regularities observed in past experiments. But instead of taking on the challenge of giving this mass of empirical evidence some theoretical backbone, megastudies have become domain specific horse races. As a policy maker or business owner, you might reap the benefits. But for science, there is less gain.</p>
<p>I admit I’m asking a lot. I want to see behavioural science build theoretical understanding as to what is going on. These studies are designed to test how to increase gym attendance or vaccination rates. We can’t always have everything.</p>
<p>However, this lack of theory is not without costs. For instance, as I’ve already noted, when asked to predict the ordering of effect sizes for the gym and vaccination megastudies, the practitioners had no idea - predictions for the gym megastudy are represented by the orange bars. We don’t have a theoretical framework that can outperform common sense or guide us as to what interventions are most likely to work. You’re stuck throwing as many interventions as you can find against a wall to see which will stick. If we had better theory, we might be able to winnow down options for a higher powered study. Megastudies are in part a symptom of this failure.</p>
<p>So, where to from here. What’s the future role of megastudies?</p>
</section>
<section id="building-on-the-common-task-approach" class="level2">
<h2 class="anchored" data-anchor-id="building-on-the-common-task-approach">Building on the common task approach</h2>
<p>I believe there is more to the common task approach. Common task exercises have catalysed some key moments in machine learning and artificial intelligence. The iterative increases in performance have provided tangible evidence of progress.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption><a href="https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024_Chapter2.pdf">AI Index 2024</a></figcaption>
<p><a href="img/what-we-learn-when-we-test-everything/ai-index-2024.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="AI Index 2024"><img src="https://www.jasoncollins.blog/posts/img/what-we-learn-when-we-test-everything/ai-index-2024.png" class="img-fluid figure-img" alt="AI Index 2024"></a></p>
</figure>
</div>
<p>Can we bring the megastudy even closer to the common task approach? Common task tournaments typically create an open playing field by making the dataset generally available. Anyone can enter. People can have multiple cracks.</p>
<p>Contrast that with the published megastudies to date from a relatively narrow set of behavioural science teams. I don’t see any evidence that behavioural science teams have skill in developing messages beyond marketers - they couldn’t predict which were more effective after all - so how could we open up and democratise who provides interventions? I saw earlier this year an open call for intervention submissions to a happiness megastudy, which is a great step, although I’m not sure it ended up on the desks of any marketing agencies. I hope they recruited some weirdos.</p>
<p>Most common task frameworks also allow iterative exploration and progress. Teams can access the data outside of tournaments. People get to repeatedly return to the problem. In contrast, with the megastudies we’ve got a one-shot game.</p>
<p>So why don’t we run this experiment with a gym chain or vaccination provider every year? Solicit open entries, with a process to whittle them down to the required number of interventions. Include a range of the best interventions from previous years.</p>
<p>If we took these extra steps, however, a limitation to the common task framework will become of increasing importance to the megastudy: overfitting. If you run a contest to increase gym attendance again and again there’s a higher probability that one of the interventions will capitalise on an idiosyncratic feature of that gym and its members. Great results, poor generalisation.</p>
<p>There are also decreasing marginal gains. The winner of the Netflix prize was never implemented as other cheaper combinations of models delivered most of the same benefits. Performance against many machine learning benchmarks plateaued or maxed out, requiring the development of new benchmarks.</p>
<p>But there is something to be said for a process where we learn and build on what we have learnt, rather than simply trial (hopefully scale) and publish. And by taking the inspiration for the megastudies - the common task framework more seriously - megastudies could contribute to this.</p>
<p>These performance curves on your screen are quite amazing. In the space of a decade, many tasks went from impossible for machines to machines being vastly superior to humans, despite predictions that these advances were decades away. A similar curve in understanding the drivers of human behaviour would be an amazing thing.</p>
<p>And that’s where I’ll wind up for today.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-milkman2021" class="csl-entry">
Milkman, K. L., Gromet, D., Ho, H., Kay, J. S., Lee, T. W., … Duckworth, A. L. (2021). Megastudies improve the impact of applied behavioural science. <em>Nature</em>, <em>600</em>(7889), 478–483. <a href="https://doi.org/10.1038/s41586-021-04128-4">https://doi.org/10.1038/s41586-021-04128-4</a>
</div>
<div id="ref-milkman2021a" class="csl-entry">
Milkman, K. L., Patel, M. S., Gandhi, L., Graci, H. N., Gromet, D. M., … Duckworth, A. L. (2021). A megastudy of text-based nudges encouraging patients to get vaccinated at an upcoming doctor<span>’</span>s appointment. <em>Proceedings of the National Academy of Sciences</em>, <em>118</em>(20), e2101165118. <a href="https://doi.org/10.1073/pnas.2101165118">https://doi.org/10.1073/pnas.2101165118</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/what-we-learn-when-we-test-everything.html</guid>
  <pubDate>Wed, 13 Nov 2024 06:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/what-we-learn-when-we-test-everything/milkman_et_al_2021_figure_1.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The human benchmark is typically unimpressive</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/the-human-benchmark-is-typically-unimpressive.html</link>
  <description><![CDATA[ 




<p>If you ever read a claim of an AI outperforming a human, dig into the performance data to check out the human benchmark. The mediocrity of the human is often more salient than the competence of the AI. The AI has an easy job.</p>
<p>Here’s an example from a paper by Ayers and friends <span class="citation" data-cites="ayers2023">(2023)</span>. They sampled 195 question and response exchanges on Reddit’s <a href="https://www.reddit.com/r/AskDocs">r/AskDocs</a> and entered those same questions into ChatGPT 3.5. Responses by the Reddit physicians and ChatGPT were then independently rated for quality and empathy.</p>
<p>ChatGPT responses were rated as higher quality, with 78% of ChatGPT responses rated as good or very good quality. 22% of physician responses had that rating. Similarly, 45% of ChatGPT responses were rated empathetic or very empathetic, compared to 5% for the physicians.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Distribution of Average Quality and Empathy Ratings for Chatbot and Physician Responses to Patient Questions</figcaption>
<p><a href="img/ayers-et-al-2023-figure.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Distribution of Average Quality and Empathy Ratings for Chatbot and Physician Responses to Patient Questions"><img src="https://www.jasoncollins.blog/posts/img/ayers-et-al-2023-figure.png" class="img-fluid figure-img" alt="Distribution of Average Quality and Empathy Ratings for Chatbot and Physician Responses to Patient Questions"></a></p>
</figure>
</div>
<p>I <a href="https://doi.org/10.7910/DVN/BZARC3">downloaded the csv file</a> of the responses. The most striking feature was the brevity and curtness of the humans (52 words average compared to 211 for ChatGPT). Here are a few of the human responses.</p>
<p>A friend’s uninsured mother needs a liver transplant. What should she do?</p>
<blockquote class="blockquote">
<p>Its not just a work around the insurance, she will need lifelong expensive meds after surgery as well. Why does she not have insurance?</p>
</blockquote>
<p>Should they be worried about arm pain when they sneeze?</p>
<blockquote class="blockquote">
<p>The answer simply is no..</p>
</blockquote>
<p>Are they crazy for thinking they have pancreatic or some other cancer given a list of symptoms?</p>
<blockquote class="blockquote">
<p>Why do you think you have pancreatic cancer?</p>
</blockquote>
<p>Where can someone from a family of anti-vaxers get information on vaccines?</p>
<blockquote class="blockquote">
<p>See your general practitioner. They’ll understand and will sort you out bro.</p>
</blockquote>
<p>Does smelly poop and less frequent bowel movements indicate cancer?</p>
<blockquote class="blockquote">
<p>This does not sound like cancer. I would advise stop googling.</p>
</blockquote>
<p>In contrast, ChatGPT gave long, involved answers that inevitably began with a statement of concern for the medical condition. “I’m sorry to hear about your friend’s mom.” Funnily enough, that verbosity annoys me the most in using LLMs. One person’s verbosity is another’s empathy.</p>
<p>I don’t mean the above to be read as a criticism of AI performance. (This is ChatGPT 3.5 after all!) But there’s an interesting contrast between performance benchmarking and discussions of the role of AI. In benchmarking exercises, we use actual human performance as the standard. But when discussing whether AI should replace or augment human decisions, we often compare AI to an idealised human. We have a mental image of a high-quality physician with excellent bedside manner, not the distribution of skills and empathy we actually have. Scrutinising the performance data for some of these benchmarking exercises is a good reminder that AI doesn’t always have to be great to be better.</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-ayers2023" class="csl-entry">
Ayers, J. W., Poliak, A., Dredze, M., Leas, E. C., Zhu, Z., … Smith, D. M. (2023). Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. <em>JAMA Internal Medicine</em>, <em>183</em>(6), 589–596. <a href="https://doi.org/10.1001/jamainternmed.2023.1838">https://doi.org/10.1001/jamainternmed.2023.1838</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/the-human-benchmark-is-typically-unimpressive.html</guid>
  <pubDate>Sun, 27 Oct 2024 23:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/ayers-et-al-2023-figure.png" medium="image" type="image/png" height="61" width="144"/>
</item>
<item>
  <title>A comment on the manifesto for behavioural science</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/a-comment-on-the-manifesto-for-behavioural-science.html</link>
  <description><![CDATA[ 




<p>I wrote this post based on notes for a proposed “lunch and learn” session. Illness got in the way, so rather than let those notes sit on the shelf, I’ve cleaned them up to share here. Many points were intended to be (provocative) conversation prompts rather than statements, so a few parts are light on evidence or end with a question.</p>
<hr>
<p>In the first half of 2023, <a href="https://doi.org/10.1038/s41562-023-01555-3">A manifesto for applying behavioural science</a> was published in Nature Human Behaviour. Written by the head of the North American arm of the Behavioural Insights Team, Michael Hallsworth, the manifesto “looks at the challenges facing the field and sets out ten proposals to address them.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption>Hallsworth (2023) Figure 1</figcaption>
<p><a href="img/manifesto-figure-1.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Hallsworth (2023) Figure 1"><img src="https://www.jasoncollins.blog/posts/img/manifesto-figure-1.webp" class="img-fluid figure-img" style="width:80.0%" alt="Hallsworth (2023) Figure 1"></a></p>
</figure>
</div>
<p>The Behavioural Insights Team also published a <a href="https://www.bi.team/wp-content/uploads/2023/04/BIT_Manifesto.pdf">longer version</a> of the manifesto, plus a <a href="https://www.bi.team/wp-content/uploads/2023/03/Manifesto-Summary.pdf">summary document</a>. Hallsworth gave me the opportunity to comment on a draft of the long-form manifesto, so I have a small insight into its development.</p>
<p>Rather than address the document as a whole - I must admit I am sceptical of manifestos for direction from up high - I am going to discuss three of Hallsworth’s proposals:</p>
<ul>
<li>See the system</li>
<li>No view from nowhere</li>
<li>Data science for equity</li>
</ul>
<section id="see-the-system" class="level2">
<h2 class="anchored" data-anchor-id="see-the-system">See the system</h2>
<p>The summary table in the Nature Human Behaviour article describes the “See the system” proposal as follows:</p>
<blockquote class="blockquote">
<p>Use aspects of complexity thinking to improve behavioural science so that it can exploit leverage points, model the collective implications of heuristics, alter specific features of systems to create wider changes, and understand the longer-term impact on a system of a collection of policies with varying goals.</p>
</blockquote>
<p>Putting this section into my words, much of the public policy territory in which we work is a complex adaptive system. That is, there is a dynamic network of many interacting agents, each with their own strategies. They are constantly acting and reacting and adapting to the environment they find themselves in. Changes are not linear. Small changes can cascade into large consequences. Major efforts can produce little change. “Emergent” behaviour can arise from these interactions, with the system as a whole producing something more than the sum of its parts. If we examine public policy issues with this lens, we might be able to identify leverage points, model the collective implications of people’s decision making strategies, make system-level changes, and understand the impact of multiple policies.</p>
<p>Hallsworth illustrates this proposal with the UK tax on sugared drinks. This tax was implemented in tiers, with drinks with higher sugar content hit with higher taxes. While this might be seen as a way of changing consumer behaviour via higher prices for the sugary drinks, this approach primarily affected sugar consumption in soft drinks by altering the incentives presented to manufacturers. They could reduce the price of their product by reducing the sugar content. Price signals via a tax reduced the sugar content of the drinks on the shelf.</p>
<p>Before digging into the proposal and example, I want to describe two related concepts, chaos and complexity. Both involve the study of non-linear dynamics.</p>
<p>Chaos concerns the study of dynamic systems that are sensitive to the initial starting conditions.</p>
<p>A famous example is Edward Lorenz’s replication of results of his weather simulations. He took the numbers from a previous weather simulation, re-entered them and started the simulation. He found that these new simulations diverged wildly from the previous runs. When he examined the results, he realised he was taking numbers from the prior simulations to six decimal places. Beyond six decimal places, there was variation. These very slight changes in initial conditions led to large divergences over time. This idea is typically referred to as the butterfly effect; a butterfly flapping its wings in the Amazon causing a tornado in Florida.</p>
<p>Chaos suggests there is an inherent limit in our ability to predict weather and other chaotic systems. Seemingly insignificant short-term variations from the model will cascade into larger differences.</p>
<p>Chaos can emerge in very simple systems. Lorenz’s weather simulation was based on just 12 equations. Robert May <span class="citation" data-cites="may1976">(1976)</span> famously showed that by adjusting a single parameter ‘a’ in a deterministic equation, he was able to generate anything from a stable equilibrium to multiple equilibria to what looks like random noise.</p>
<p>Complexity also relates to non-linear systems, in which order can emerge at a higher level that’s not easily seen as the sum of the lower parts. Complexity theory is the study of these systems. Complex <em>adaptive</em> systems are a type of complex system with agents who learn and adapt in the changing environment, adding an additional complication to the study of the dynamical system.</p>
<p>What does embracing this complexity mean for applied behavioural science?</p>
<p>I see two possibilities.</p>
<p>The first, suggested in the manifesto, is that we can identify leverage points to trigger a large change. Imagine you could control the parameter ‘a’ in May’s equations. The sugar tax is one example, manipulating the price of sugar. Similarly, if trying to regulate carbon emissions, instead of identifying all the different sources and setting specific regulations around them, you could simply set a carbon price.</p>
<p>The second possibility from taking complexity (and chaos) seriously is that some features of the policy environment will be inherently unpredictable.</p>
<p>To discuss this, let’s dig into that example of the sugar tax more deeply. A tax on sugar content of soft drinks led to organisations to reformulate their products (sidestepping the question of whether this is complexity or just second order effects). However, obesity in the UK has continued to go up. The pandemic didn’t help, but it was going up before that. The best we have are desperate data mining studies that, after enough slices and dices, claim a benefit for year 6 girls (but fatter year 6 boys) <span class="citation" data-cites="rogers2023">(Rogers et al., 2023)</span>.</p>
<p>So, despite the second order effect of reformulation of soft drinks, for the measure of interest, there was no measurable reduction on obesity. (To be fair, it’s questionable whether you’d expect it to be detectable.) And what of other measures? <a href="https://www.gov.uk/government/statistics/soft-drinks-industry-levy-statistics/soft-drinks-industry-levy-statistics-commentary-2021">Over 300 million pounds a year out of people’s pockets</a> during a supposed <a href="https://www.bi.team/blogs/supporting-households-through-the-cost-of-living-crisis/">cost of living crisis</a>. What of the distribution of that cost? I expect a relatively regressive distribution. And drinks that taste worse.</p>
<p>As another example, one of the Behavioural Insights Team’s early projects involved offering loft cleaning services in conjunction with insulation installation, removing a hassle that was standing in the way of energy efficiency improvements. (After reading the original report on this work, this topic is deserving of another post.) Yet, in line with previous research, gas use rebounds to original levels within two years of loft insulation installation <span class="citation" data-cites="peñasco2023">(Peñasco and Anadón, 2023)</span>. Again, this might just be thought about as second-order effects rather than complexity, but here we have seemingly simple interventions failing to achieve the desired objective.</p>
<p>Taking complexity seriously and seeing the system also requires thinking about ourselves. What is the process by which our work results in change? Even this is not simple. Stefan Della Vigna and Elizabeth Linos analysed the many pre-registered trials conducted by the Behavioural Insights Team in North America (full credit for transparency). In a paper published in Econometrica <span class="citation" data-cites="dellavigna2022">(DellaVigna and Linos, 2022)</span> they demonstrated that although the effects of ‘nudges’ in the field were smaller than those in academic publications, they were real and would in many cases pass a cost-benefit test. A second paper in the Journal of Political Economy <span class="citation" data-cites="dellavigna2024">(DellaVigna et al., 2024)</span>, however, is somewhat depressing. There was no link between the evidence from the trial and implementation. We have what seems a simple lever - identify those interventions that work - and yet we don’t see this down the line in the outcomes that matter.</p>
<p>And here’s one further dimension of complexity that should be considered. We’re working on a lot of objectives. Look at the bodies of work focused on gender equity, retirement savings, education, and the like. Achieving these objectives have second order effects. How do they affect each other? Does encouraging female participation in STEM increase the gender wage gap? Does encouraging paternity leave affect productivity or family income? Does encouraging university attendance among low-socioeconomic status increase inequality (when they drop out or end up in a lower paying job than a trade)? Some of these might be easy to measure. But some of the interactions are likely beyond us.</p>
<p>So, the question I have is, should we take a message of greater humility from “seeing the system”? (Humility is one of the principles in the manifesto - but this comes from a different foundation.)</p>
</section>
<section id="no-view-from-nowhere" class="level2">
<h2 class="anchored" data-anchor-id="no-view-from-nowhere">No view from nowhere</h2>
<p>As an outsider reading the manifesto, the question I kept asking was “what is the objective?”. (I asked that in my comments on the draft manifesto too!)</p>
<p>If the recipe in the manifesto is followed, what would be the measure of success? The manifesto contains some general statements about applied behavioural science fulfilling its potential. I have no idea what fulfilled potential looks like. The ten proposals are largely quiet about what the manifesto is trying to achieve, outside of the explicit “Data Science for Equity”. I”ll come to that proposal later.</p>
<p>Similarly, what are we trying to achieve as behavioural science practitioners? This is a big question, but it’s fair to ask it of a “manifesto”. What are the consequences for the subjects of our work - citizens, customers, employees - from our interventions as applied behavioural practitioners, and how might the manifesto shape these outcomes if the manifesto’s proposals are implemented?</p>
<p>The point of the manifesto where the question of objective stood out most to me was in the “No view from nowhere” proposal. The summary of this proposal states:</p>
<blockquote class="blockquote">
<p>Cultivate self-scrutiny, find new ways for the subjects of research to judge researchers, and take actions to increase diversity among behavioural scientists and their teams, such as building professional networks between the Global North and Global South.</p>
</blockquote>
<p>Again, let me give my summary of that principle from the broader text. We don’t come to work with a blank slate. We bring assumptions. We bring values. Gender, race and sexuality influence our viewpoints. And so on. Because of this, we cannot view a situation from nowhere. These assumptions and values are always there. This problem is relevant as behavioural science practitioners are homogeneous. Few teams come from the “Global South”. Our research subjects have traditionally represented only a small fraction of the global population. As a result, we should give more scrutiny to our starting points and build diversity among data scientists and their teams. The call to increase diversity notes that we need to increase diversity “of several kinds”. Directly mentioned is increasing collaboration with the Global South and increasing ethnic and racial diversity.</p>
<p>Every time I see a call for diversity, I wonder what kind of diversity. And there is one specific type that isn’t questioned in the manifesto.</p>
<p>Suppose I was to ask a set of behavioural science practitioners the following questions (excuse their Australian flavour - I’m sure you can come up with versions for whatever country you wish):</p>
<ul>
<li>Who voted “No” in the referendum to amend the constitution to give a <a href="https://en.wikipedia.org/wiki/2023_Australian_Indigenous_Voice_referendum">“Voice” to Indigenous Australians</a>? (At one stage, the presentation was scheduled for the weekend before this referendum. And despite 60% of the Australian voting population rejecting the proposal, I am still to meet even one person in my professional world or town where I live who has openly stated that they voted no.)</li>
<li>Relatedly, should we have an indigenous land acknowledgement at the start of every meeting?</li>
<li>Who voted Liberal at the last Federal election? (The Australian conservative party.)</li>
<li>Who believes there are only two sexes?</li>
<li>Should there be a sugar tax in Australia?</li>
</ul>
<p>I am not asking for a show of hands, but I suspect a skew in a specific direction. And that is largely reflected in the types of projects that applied behavioural practitioners work on. Equity. Diversity. Climate. The sins of the lower classes.</p>
<p>We work on sugar taxes in soft drinks when a large flat white has more calories than a can of Coke. (Products with more than 75% milk are excluded from the UK sugar tax.) I can’t find a serious mention of the effect of the sugar tax on taste. We work on net zero rather than energy abundance. We work on how can we get more men to take paternity leave to close the gender wage gap rather than ‘What is the optimal level of paternity leave and how can we support it’? (Given the most credible evidence on the gender gap points to a motherhood penalty from time out of the workforce <span class="citation" data-cites="goldin2014">(Goldin, 2014)</span>, are we trying to convert the motherhood penalty into a family penalty?) There’s hardly any questioning of whether this is even a policy issue where income is shared within a household.</p>
<p>The omissions also stand out. We rarely work on projects to boost productivity or economic growth. For all the talk of “libertarian paternalism”, I’m not aware of a single example of a behavioural team working hard to remove regulation and replace it with good behavioural design? Where is the push to move to a voluntary superannuation system in Australia, where we let people have their superannuation if they want it, with a behaviourally designed system to support their savings? Applied behavioural science is simply paternalism.</p>
<p>Here’s a final example. Many Australian women fail to meet their fertility intentions (for example, see <span class="citation" data-cites="wilkins2021">Wilkins et al. (2021)</span> and a summary of the report in <a href="https://theconversation.com/half-of-women-over-35-who-want-a-child-dont-end-up-having-one-or-have-fewer-than-they-planned-173151">the Conversation</a>). This is not just an Australian phenomenon (e.g. <span class="citation" data-cites="guzzo2023">Guzzo and Hayford (2023)</span>). There is also considerable evidence that people don’t understand how early in life fertility starts to decline (e.g. <span class="citation" data-cites="hammarberg2013">Hammarberg et al. (2013)</span>). Is there a project to help people to overcome this shortcoming? Contrast this to the volume of work on retirement savings.</p>
<p>Putting these examples together, there is a lack of intellectual diversity in the behavioural science world, and this is reflected in the work that we do. Further, there seems to be little interest in rectifying this. We’re only calling for the types of diversity that don’t challenge our world view.</p>
</section>
<section id="data-science-for-equity" class="level2">
<h2 class="anchored" data-anchor-id="data-science-for-equity">Data Science for Equity</h2>
<p>The third proposal I will briefly discuss, “Data Science for Equity”, is a view from somewhere very specific. The summary in the Nature Human Behaviour paper reads:</p>
<blockquote class="blockquote">
<p>Use data science to identify the ways in which an intervention or situation appears to increase inequalities and introduce features to reduce them. For example, groups that are particularly likely to miss a filing requirement could be offered pre-emptive help.</p>
</blockquote>
<p>I take the choice of the word “equity” as deliberate and coming with a meaning different to equality. Equity is about outcomes, not equality of opportunity. On my previous point about diversity, I’m not sure a more intellectually diverse team would have chosen that word. Think of all the things behavioural science could be achieving: productivity, happiness, financial wellbeing, economic growth, sustainability. Why single out equity?</p>
<p>That this proposal is “data science” and not “behavioural science” for equity is also interesting. It seems somewhat narrow to highlight one particular tool.</p>
<p>But the question I want to flag concerns trade-offs. When you choose a specific objective, what are you are willing to trade-off to achieve it? Absent trade-offs, the objective has no teeth. How does it guide choice of problem (including what problems you won’t work on)? What does it imply for choice of intervention and measurement of success?</p>
<p>The example offered in the above summary doesn’t provide much guidance. Helping people who might miss a filing requirement is innocuous. Assuming a small cost of a reminder or prompt, there’s no real trade-off here.</p>
<p>So let’s pull out a cartoon example. You discover that abolishing advanced math classes reduces the gap between indigenous and non-indigenous students, largely by reducing the performance of the top cohort. Is this the equity you want to achieve?</p>
<p>Maybe not, but it’s not clear from the proposal. And if it’s not, where would we draw the line? Do we want to prioritise problems that lift the bottom but harm no-one else? (Is it now data science for Pareto improvement?)</p>
<p>And this brings me back to my previous question about objectives. Should our goal be equity? Or should it be to bring out the best in us in our own way?</p>
<p>I don’t expect Hallsworth to have the complete answer in his manifesto, but I’m not sure I get any useful guidance from this objective of equity.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-dellavigna2024" class="csl-entry">
DellaVigna, S., Kim, W., and Linos, E. (2024). Bottlenecks for evidence adoption. <em>Journal of Political Economy</em>, 000–000. <a href="https://doi.org/10.1086/729447">https://doi.org/10.1086/729447</a>
</div>
<div id="ref-dellavigna2022" class="csl-entry">
DellaVigna, S., and Linos, E. (2022). RCTs to Scale: Comprehensive Evidence From Two Nudge Units. <em>Econometrica</em>, <em>90</em>(1), 81–116. <a href="https://doi.org/10.3982/ECTA18709">https://doi.org/10.3982/ECTA18709</a>
</div>
<div id="ref-goldin2014" class="csl-entry">
Goldin, C. (2014). A Grand Gender Convergence: Its Last Chapter. <em>American Economic Review</em>, <em>104</em>(4), 1091–1119. <a href="https://doi.org/10.1257/aer.104.4.1091">https://doi.org/10.1257/aer.104.4.1091</a>
</div>
<div id="ref-guzzo2023" class="csl-entry">
Guzzo, K. B., and Hayford, S. R. (2023). Evolving Fertility Goals and Behaviors in Current U.S. Childbearing Cohorts. <em>Population and Development Review</em>, <em>49</em>(1), 7–42. <a href="https://doi.org/10.1111/padr.12535">https://doi.org/10.1111/padr.12535</a>
</div>
<div id="ref-hammarberg2013" class="csl-entry">
Hammarberg, K., Setter, T., Norman, R. J., Holden, C. A., Michelmore, J., …. (2013). Knowledge about factors that influence fertility among australians of reproductive age: A population-based survey. <em>Fertility and Sterility</em>, <em>99</em>(2), 502–507. <a href="https://doi.org/10.1016/j.fertnstert.2012.10.031">https://doi.org/10.1016/j.fertnstert.2012.10.031</a>
</div>
<div id="ref-may1976" class="csl-entry">
May, R. M. (1976). Simple mathematical models with very complicated dynamics. <em>Nature</em>, <em>261</em>(5560), 459–467. <a href="https://doi.org/10.1038/261459a0">https://doi.org/10.1038/261459a0</a>
</div>
<div id="ref-peñasco2023" class="csl-entry">
Peñasco, C., and Anadón, L. D. (2023). Assessing the effectiveness of energy efficiency measures in the residential sector gas consumption through dynamic treatment effects: Evidence from england and wales. <em>Energy Economics</em>, <em>117</em>, 106435. <a href="https://doi.org/10.1016/j.eneco.2022.106435">https://doi.org/10.1016/j.eneco.2022.106435</a>
</div>
<div id="ref-rogers2023" class="csl-entry">
Rogers, N. T., Cummins, S., Forde, H., Jones, C. P., Mytton, O., … Adams, J. (2023). Associations between trajectories of obesity prevalence in English primary school children and the UK soft drinks industry levy: An interrupted time series analysis of surveillance data. <em>PLOS Medicine</em>, <em>20</em>(1), e1004160. <a href="https://doi.org/10.1371/journal.pmed.1004160">https://doi.org/10.1371/journal.pmed.1004160</a>
</div>
<div id="ref-wilkins2021" class="csl-entry">
Wilkins, R., Vera-Toscano, E., Botha, F., and Dahmann, S. C. (2021). <em>The Household, Income and Labour Dynamics in Australia Survey: Selected Findings from Waves 1 to 19</em>. <a href="https://melbourneinstitute.unimelb.edu.au/__data/assets/pdf_file/0009/3963249/HILDA-Statistical-Report-2021.pdf">https://melbourneinstitute.unimelb.edu.au/__data/assets/pdf_file/0009/3963249/HILDA-Statistical-Report-2021.pdf</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/a-comment-on-the-manifesto-for-behavioural-science.html</guid>
  <pubDate>Thu, 24 Oct 2024 23:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/manifesto-figure-1.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Subject notes on behavioural economics</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/subject-notes-on-behavioural-economics.html</link>
  <description><![CDATA[ 




<p>Each year I teach an undergraduate subject in behavioural economics.</p>
<p>I have pulled together the notes for the subject into a website, which you can find <a href="https://behaviouraleconomics.jasoncollins.blog">here</a>. The notes include the subject content, plus “exercises” that form the basis for the tutorials. If you work through the content, you’re effectively getting the same content as my students, minus the interactive seminars with me, tutorials with the teaching assistants, and the assessments.</p>
<p>I have also developed a set of videos to accompany the notes, which can be found <a href="https://www.youtube.com/@jasonacollins">here</a>. The videos are effectively voice versions of the notes (or you can think of the notes as transcripts for the videos), so whether you watch or read, you will get the same content. The videos are largely voiced by me, although the more recent videos tend to have an AI voice, as I discuss <a href="https://www.jasoncollins.blog/posts/using-generative-AI-as-academic-july-2024-edition">here</a>.</p>
<p>I take a traditional approach in these notes, starting with the typical economic approaches to decision making (expected utility theory, exponential discounting, game theory) and then adding the behavioural twists (prospect theory, hyperbolic discounting, bounded rationality). Partly, I took this approach because I iterated toward this content over a couple of years from the version of the subject taught by previous lecturers. As a result, I’ve retained much of the past structure (although the content is new). But, there’s also some benefit in building a solid foundation in how behavioural economists traditionally approach the subject before expanding into new territory.</p>
<p>I’m developing a new set of notes that take a more “Jason” approach, applying a critical lens to the research, pulling in interdisciplinary content, and framing humans as good decision makers given our computational constraints. I’ll post those notes when they are ready.</p>
<p>Please feel free to take these notes and use them for your own purposes; the notes are <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>. The site is generated using <a href="https://quarto.org">quarto</a>, so you can also clone the <a href="https://github.com/jasonacollins/behaviouraleconomics">repository</a> and make your own version of the notes, or simply take the text files underlying the website.</p>
<p>Finally, I have several other sets of subject notes, including material on financial and corporate decision making. This more applied content is linked <a href="https://jasoncollins.blog/teaching/">here</a>.</p>



 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/subject-notes-on-behavioural-economics.html</guid>
  <pubDate>Thu, 08 Aug 2024 06:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/notes-in-be.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>The illusion of evidence-based nudges</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/the-illusion-of-evidence-based-nudges.html</link>
  <description><![CDATA[ 




<p>From a recent Journal of Political Economy paper by Stefano DellaVigna, Woojin Kim and Elizabeth Linos <span class="citation" data-cites="dellavigna2024">(2024)</span>:</p>
<blockquote class="blockquote">
<p>We study 30 US cities that ran 73 RCTs with a national nudge unit. Cities adopt a nudge treatment into their communications in 27% of the cases. We find that the strength of the evidence and key city features do not strongly predict adoption; instead, the largest predictor is whether the RCT was implemented using preexisting communication, as opposed to new communication.</p>
</blockquote>
<p>A nudge with a negative result is almost as likely to be implemented as a positive result.</p>
<blockquote class="blockquote">
<p>There is no difference in adoption for results with negative point estimates (25% adoption), results with positive but not statistically significant estimates (25%), and estimates that are positive and statistically significant (30%). The likelihood of adoption increases with effect size (measured in percentage points), from 17% in the bottom third to 38% in the top third, though this difference is not statistically significant at conventional levels.</p>
</blockquote>
<p>My cynical take is that running trials with nudge units is cool. Despite more than a decade of nudge unit stories, behavioural insights is still a “shiny new thing” and are a way to say “we’re doing science” The hard work of implementing or scaling an intervention simply isn’t as sexy.</p>
<p><a href="img/dellavigna-et-al-2024-fig-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://www.jasoncollins.blog/posts/img/dellavigna-et-al-2024-fig-3.png" class="img-fluid"></a></p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-dellavigna2024" class="csl-entry">
DellaVigna, S., Kim, W., and Linos, E. (2024). Bottlenecks for evidence adoption. <em>Journal of Political Economy</em>, 000–000. <a href="https://doi.org/10.1086/729447">https://doi.org/10.1086/729447</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/the-illusion-of-evidence-based-nudges.html</guid>
  <pubDate>Thu, 01 Aug 2024 09:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/dellavigna-et-al-2024-fig-3.png" medium="image" type="image/png" height="123" width="144"/>
</item>
<item>
  <title>Humans 1, Chimps 0: Correcting the Record</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/humans-1-chimps-0-correcting-the-record.html</link>
  <description><![CDATA[ 




<p>In 2012, I wrote a post titled <a href="https://www.jasoncollins.blog/posts/chimps-1-humans-0">Chimps 1, Humans 0</a> after seeing videos of a chimp named Ayumu. Ayumu could recall the location of numbers, in order, flashed briefly on a screen. Ayumu’s performance far exceeded my feeble attempts. See the below videos to get a sense of the task.</p>
<p><strong>The human</strong></p>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/RnJTwKMCvqM" width="600" height="450" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><strong>Ayumu</strong></p>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/iT0abyAIyY8" width="600" height="450" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>This performance, documented by <span class="citation" data-cites="inoue2007">Inoue and Matsuzawa (2007)</span> in Current Biology, was used to assert that chimps have superior working memory to humans. The claim has spread widely, as a brief search on Twitter and Google shows.</p>
<p>When I wrote that post, I didn’t know that this conclusion was already without basis. Here’s Peter Cook and Margaret Wilson <span class="citation" data-cites="cook2010">(2010a)</span> in Science:</p>
<blockquote class="blockquote">
<p>Ayumu received extensive practice on the task; the humans to whom he was compared received none. At least one subsequent study (2) shows that, with even very moderate practice, humans can match Ayumu’s performance.</p>
<p>In spite of this basic methodological error, the claim of superior spatial working memory in chimpanzees has been widely and uncritically repeated in the popular and scientific media. Propagation of this incorrect idea distracts from more fruitful explorations of chimpanzee memory and undermines ongoing research into human and primate evolution.</p>
</blockquote>
<p>The paper referenced at (2) was by <span class="citation" data-cites="silberberg2009">Silberberg and Kearns (2009)</span>, who found that trained people could match Ayumu’s performance. <span class="citation" data-cites="cook2010a">Cook and Wilson (2010b)</span> subsequently trained two university students to a level superior to the chimpanzee. A more recent literature review by <span class="citation" data-cites="read2022">Read et al. (2022)</span> suggested that chimp working memory matches that of 4 to 5-year-old humans. However, at around two digits (plus or minus one), chimp working memory falls short of adult human performance. (Read et al.&nbsp;also question whether this task is even a test of working memory.)</p>
<p>Putting it together, the initial claim of superior working memory doesn’t hold up. Ayumu’s performance is impressive at first sight, but that’s about it.</p>
<p>*Someone brought this to my attention back in November (that’s the date on my note to blog this), but I can’t remember who!</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-cook2010" class="csl-entry">
Cook, P., and Wilson, M. (2010a). In practice, chimp memory study flawed. <em>Science</em>, <em>328</em>(5983), 1228–1228. <a href="https://doi.org/10.1126/science.328.5983.1228-c">https://doi.org/10.1126/science.328.5983.1228-c</a>
</div>
<div id="ref-cook2010a" class="csl-entry">
Cook, P., and Wilson, M. (2010b). Do young chimpanzees have extraordinary working memory? <em>Psychonomic Bulletin &amp; Review</em>, <em>17</em>(4), 599–600. <a href="https://doi.org/10.3758/pbr.17.4.599">https://doi.org/10.3758/pbr.17.4.599</a>
</div>
<div id="ref-inoue2007" class="csl-entry">
Inoue, S., and Matsuzawa, T. (2007). Working memory of numerals in chimpanzees. <em>Current Biology</em>, <em>17</em>(23), R1004–R1005. <a href="https://doi.org/10.1016/j.cub.2007.10.027">https://doi.org/10.1016/j.cub.2007.10.027</a>
</div>
<div id="ref-read2022" class="csl-entry">
Read, D. W., Manrique, H. M., and Walker, M. J. (2022). On the working memory of humans and great apes: Strikingly similar or remarkably different? <em>Neuroscience &amp; Biobehavioral Reviews</em>, <em>134</em>, 104496. <a href="https://doi.org/10.1016/j.neubiorev.2021.12.019">https://doi.org/10.1016/j.neubiorev.2021.12.019</a>
</div>
<div id="ref-silberberg2009" class="csl-entry">
Silberberg, A., and Kearns, D. (2009). Memory for the order of briefly presented numerals in humans as a function of practice. <em>Animal Cognition</em>, <em>12</em>(2), 405–407. <a href="https://doi.org/10.1007/s10071-008-0206-8">https://doi.org/10.1007/s10071-008-0206-8</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/humans-1-chimps-0-correcting-the-record.html</guid>
  <pubDate>Wed, 24 Jul 2024 22:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/ayumu.png" medium="image" type="image/png" height="98" width="144"/>
</item>
<item>
  <title>Using generative AI as an academic - July 2024 edition</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/using-generative-AI-as-academic-july-2024-edition.html</link>
  <description><![CDATA[ 




<p>I first wrote <a href="https://www.jasoncollins.blog/posts/using-large-language-models-as-academic">a version of this post in April 2023</a>. A lot has changed since then in both the tools and how I use them.</p>
<p>As was the case then, if you want a sense of the frontier, others such as <a href="https://www.oneusefulthing.org/">Ethan Mollick</a> will give you a better flavour. But if you’re after some practical examples, you might find this useful.</p>
<section id="my-toolkit" class="level2">
<h2 class="anchored" data-anchor-id="my-toolkit">My toolkit</h2>
<p>I use multiple tools, switching between them depending on the task and comparing the responses. I want to gain a sense of the frontier.</p>
<p>As an academic, I gain free access to <a href="https://github.com/features/copilot">Github Copilot</a>. (Students can also get free access.) CoPilot provides code suggestions in coding environments. But while badged this way, CoPilot also provides text suggestions more broadly. To access CoPilot, I write markdown documents in <a href="https://code.visualstudio.com">Visual Studio Code</a> or <a href="https://posit.co/download/rstudio-desktop/">RStudio</a>. (For those who want more specific guidance on how to set this up, I’ve added that at the bottom of this post.) If you use CoPilot in Visual Studio Code you also gain access to <a href="https://docs.github.com/en/copilot/using-github-copilot/asking-github-copilot-questions-in-your-ide">Copilot Chat</a>.</p>
<p>I also work with <a href="https://chat.openai.com/">ChatGPT Plus</a> and <a href="https://www.anthropic.com/claude">Claude Pro</a> open in a browser. I subscribe to the Pro/Plus version of both: it is worth it for the superior tools. As you’ll see from the below, I use them all the time, although more recently I lean toward Claude.</p>
<p>I run some other large language models locally on my computer using <a href="https://ollama.com/">Ollama</a>. I do this more to get a feel for them than for current utility. Most of my recent experimentation has been with <a href="https://ollama.com/library/llama3">Llama 3</a>. I use these models via the command line or the <a href="https://github.com/logancyang/obsidian-copilot">CoPilot plugin</a> in <a href="https://obsidian.md/">Obsidian</a>.</p>
<p>I also subscribe to <a href="https://elevenlabs.io/">ElevenLabs</a> for its voice-generation capabilities. More on that below.</p>
<p>I’ve experimented with other tools, but they haven’t yet formed a large part of my workflow. I don’t use Bing much, except for images if ChatGPT isn’t giving me what I want. I like that it gives four images for every prompt. I experimented with Google Gemini but haven’t found a reason for it to supplant the Claude plus ChatGPT combination. I revisit it every month or two to see whether I should add it to the mix.</p>
</section>
<section id="thinking" class="level2">
<h2 class="anchored" data-anchor-id="thinking">Thinking</h2>
<ul>
<li>Efficiency gain: uncertain</li>
</ul>
<p>I am increasingly using Claude and ChatGPT as interactive <a href="https://en.wikipedia.org/wiki/Rubber_duck_debugging">rubber ducks</a>. When thinking through something new, I’ll often state my thoughts and ask for comments. I’ll often ask them to explain a concept to me, then I will ask follow-up questions. Sometimes I’ll do this in ChatGPT with voice mode when I am walking. I know that I’m not getting 100% accurate information, but I wouldn’t talking to a friend either.</p>
<p>Similarly, after reading an article and forming my own views on its message, strengths and weaknesses, I’ll ask Claude or ChatGPT their views. I find this can be hit and miss, but on net worth doing. Sometimes the description is spot on, and the critiques hit points I haven’t thought of.</p>
<p>Finally, if I have a technical question, I’ll ask before googling. It’s faster and, I would say, more accurate than the top Google hits.</p>
</section>
<section id="coding-and-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="coding-and-data-analysis">Coding and data analysis</h2>
<ul>
<li>Efficiency gain: 10x</li>
<li>Quality gain: 50%</li>
</ul>
<p>Despite spending a lot of time in R, I am a crap coder. As a result, my typical approach is to write a comment and let CoPilot do the first cut of the code. I will then tweak the code until it is in shape. That tweaking isn’t manual tweaking either. If there is an error or problem that I can’t resolve, I’ll use CoPilot Chat to get a solution. Chat will usually provide code solving the problem.</p>
<p>CoPilot is also great in helping me understand someone else’s code. I’ll highlight sections and ask CoPilot Chat to explain what it does. Often, I’ll paste poorly documented code into Claude or ChatGPT and ask it to write comments. Further, If the code looks overly complicated, a request to simplify often yields good results. (I’ve been asking ChatGPT to review some of my old code recently. I’m a bit embarrassed at how much more efficiently I could have written it.)</p>
<p>One large benefit has come from cross-language translation. Last year I wanted to reproduce the results in Berkeley Dietvorst’s <a href="https://doi.org/10.1037/xge0000033">Algorithm aversion: People erroneously avoid algorithms after seeing them err</a>. Data and the code for analysis were <a href="https://researchbox.org/379&amp;PEER_REVIEW_passcode=MOQTEQ">available on ResearchBox</a>. The problem was that the code was in Stata, and I have no desire to learn Stata.</p>
<p>I pasted the Stata code into ChatGPT and asked for a conversion to R. What I received was 90% of the way there. Initially, there was an error, but pasting the error into ChatGPT gave me the solution first shot. I then tweaked a couple of the variable manipulations and specified that some of the t-tests were paired t-tests. That was it. In less than 10 minutes I had code that reproduced exactly the results from Study 1. I’ve now done this translation dozens of times when examining and reproducing studies by others.</p>
<p>I’m increasingly asking ChatGPT and Claude to provide me with working programs. For example, I am building a website with an underlying database and model for predicting AFL games. (I wanted to experiment with how far I could go with these tools.) I obtained a web interface and underlying code from Claude to access the database. I used ChatGPT for the first version of the predictive model. I’m now playing with the details, but the core is there. I wouldn’t even attempt it without these tools.</p>
<section id="data-exploration" class="level3">
<h3 class="anchored" data-anchor-id="data-exploration">Data exploration</h3>
<ul>
<li>Efficiency gain: 2x</li>
</ul>
<p>Any time I am about to work with new data, confidentiality permitting, I’ll give the data to ChatGPT and ask about it. I’ll start generally: “tell me about this file”. Then I’ll work down to the details and ask for basic visualisations and analysis. Finally, I’ll export the Python code (or ask for an R version of the code).</p>
<p>Ever since the <a href="https://datacolada.org/98">Dan Ariely car insurance data fraud</a>, which is obvious from a simple plot, I’ve made it a habit of looking at the data before jumping into analysis (which I didn’t do as often as I should have in the past). It’s surprising how often I find that something is not quite right or as expected. Having ChatGPT on hand makes this first step quick and easy.</p>
</section>
<section id="extracting-pdf-data" class="level3">
<h3 class="anchored" data-anchor-id="extracting-pdf-data">Extracting pdf data</h3>
<ul>
<li>Efficiency gain: 10x</li>
</ul>
<p>This is a small one in that I don’t need to do that often, but it’s a massive time saver. If there is a large table in a PDF, I ask ChatGPT to output it as a CSV. Recently, I had data spread across half a dozen PDFs in poorly formatted tables. I used ChatGPT to combine and arrange the data. I check the accuracy as I don’t fully trust ChatGPT, but the accuracy is typically great, saving me a lot of time.</p>
</section>
</section>
<section id="writing" class="level2">
<h2 class="anchored" data-anchor-id="writing">Writing</h2>
<ul>
<li>Efficiency gain: 20%</li>
<li>Quality gain: 10%</li>
</ul>
<p>When I first started using GitHub CoPilot, I would have it on whenever I was writing. I would receive suggestions as I typed. Today, I generally turn it off when writing a first draft. The distraction in filtering suggestions was too costly, and I was worried about getting dragged in random directions.</p>
<p>However, I use Claude and ChatGPT a lot to improve my writing. When I’m having trouble getting a sentence or paragraph right, I’ll often hand it over and ask for 10 possible rewrites. Similarly, I will ask for simpler, shorter or more conversational text. I’ll rarely take a rewrite as provided, but it often gives me a word or turn of phrase that does the job.</p>
<section id="lecture-notes" class="level3">
<h3 class="anchored" data-anchor-id="lecture-notes">Lecture notes</h3>
<p>For more mechanical lecture notes, there are some clear gains. The notes for my undergraduate behavioural economics subject (which you can access <a href="https://behaviouraleconomics.jasoncollins.blog">here</a>) were produced with CoPilot assistance.</p>
<p>Here are a few instances where CoPilot has been useful.</p>
<p>Often the notes include a statement of a concept followed by a step-by-step example or illustration. The gain comes when you’re writing those steps.</p>
<p>For example, in a section about decision making under risk, I might write:</p>
<blockquote class="blockquote">
<p>Bill is a risk-averse agent with utility function <img src="https://latex.codecogs.com/png.latex?u(x)=%5Ctext%7Bln%7D(x)"> and wealth of $100. He is offered a 50:50 bet to win $100, lose $50.</p>
<p>Will Bill accept the bet?</p>
</blockquote>
<p>If I write the first couple of words of the answer “First, we calculate…”, CoPilot is away.</p>
<blockquote class="blockquote">
<p>First, we calculate the expected utility of each option. The expected utility of the bet is:</p>
</blockquote>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{=tex}</span></span>
<span id="cb1-2"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\begin{aligned}</span></span>
<span id="cb1-3"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">EU(\text{bet}) &amp;= 0.5 \times u(100) + 0.5 \times u(-50) \\</span></span>
<span id="cb1-4"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;= 0.5 \times \text{ln}(100) + 0.5 \times \text{ln}(50) \\</span></span>
<span id="cb1-5"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;= 4.259</span></span>
<span id="cb1-6"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\end{aligned}</span></span>
<span id="cb1-7"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<blockquote class="blockquote">
<p>The expected utility of not taking the bet is:</p>
</blockquote>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"></span>
<span id="cb2-2"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{=tex}</span></span>
<span id="cb2-3"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\begin{aligned}</span></span>
<span id="cb2-4"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">EU(\text{no bet}) &amp;= U(100) \\</span></span>
<span id="cb2-5"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;= \text{ln}(100) \\</span></span>
<span id="cb2-6"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;= 4.605</span></span>
<span id="cb2-7"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\end{aligned}</span></span>
<span id="cb2-8"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<blockquote class="blockquote">
<p>As the expected utility of the bet is less than the expected utility of not taking the bet, Bill will not accept the bet.</p>
</blockquote>
<p>Not bad for a few seconds of work. For those unfamiliar with the mathematical notation, this is <img src="https://latex.codecogs.com/png.latex?%5CLaTeX">, which renders into nice equations like this.</p>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%0AEU(%5Ctext%7Bbet%7D)%20&amp;=%200.5%20%5Ctimes%20u(100)%20+%200.5%20%5Ctimes%20u(-50)%20%5C%5C%0A&amp;=%200.5%20%5Ctimes%20%5Ctext%7Bln%7D(100)%20+%200.5%20%5Ctimes%20%5Ctext%7Bln%7D(50)%20%5C%5C%0A&amp;=%204.259%0A%5Cend%7Baligned%7D">
<p>I might beef this up with a better explanation, or paste the question into ChatGPT directly, where I tend to get more detailed answers. CoPilot has done OK with the math here - the logs are correct!</p>
<p>CoPilot is also great when I’m doing repetitive tasks such as describing the elements of an equation or diagram. Start describing the first element and it might give you the rest. And if you write a point followed by “Conversely, …”, CoPilot is often on the money.</p>
<p>I also use CoPilot with <a href="https://ggplot2.tidyverse.org">ggplot</a> to produce graphs for the notes. When I wanted to generate a chart showing a <a href="https://behaviouraleconomics.jasoncollins.blog/prospect-theory/probability-weighting">probability weighting function</a> from prospect theory, I created an R code block and typed a comment:</p>
<blockquote class="blockquote">
<p>#Plot of probability weighting function using ggplot2</p>
</blockquote>
<p>Here’s the result that ChatGPT produced with the diagram rendered below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Plot of probability weighting function using ggplot2</span></span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Define probability weighting function</span></span>
<span id="cb3-5">prob_weight <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(p, alpha){</span>
<span id="cb3-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">exp</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">log</span>(p))<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span>alpha)</span>
<span id="cb3-7">}</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Create data frame of probabilities and weights</span></span>
<span id="cb3-10">prob <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>)</span>
<span id="cb3-11">prob_df <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">prob =</span> prob, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">weight =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prob_weight</span>(prob, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>))</span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Plot</span></span>
<span id="cb3-14"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(prob_df, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> prob, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> weight)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-15">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-16"></span>
<span id="cb3-17">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Add labels</span></span>
<span id="cb3-18">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Probability"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Weight"</span>)</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="using-generative-AI-as-academic-july-2024-edition_files/figure-html/unnamed-chunk-1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://www.jasoncollins.blog/posts/using-generative-AI-as-academic-july-2024-edition_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>Exactly what I wanted. When I implemented this in the notes, I only tweaked the style and added a 45-degree line.</p>
<p>CoPilot’s offering uses Prelec’s <span class="citation" data-cites="prelec1998">(1998)</span> probability weighting function. Whether it picked that up from earlier text in my notes or just gave the most common function for probability weighting, I don’t know, but it’s what I would have used if doing it manually. However, in writing this post I wasn’t able to replicate what I did when writing the lecture notes. I got better results in the lecture notes themselves. A few paragraphs about probability weighting before I ask for the code generated better results than asking for the chart straight up.</p>
<p>CoPilot didn’t offer this full chunk of code at once. Each comment was offered, then the piece of code after it, one after the other. But the only work I did was writing the first comment and pressing tab several times as each succeeding comment or chunk of code was suggested. (CoPilot has certainly increased the level of comments in my code too.)</p>
</section>
<section id="writing-organisational-fluff" class="level3">
<h3 class="anchored" data-anchor-id="writing-organisational-fluff">Writing organisational fluff</h3>
<p>Work in any decent-sized modern organisation and you will have to write some level of fluff to satisfy the higher-ups, clients, government requirements and the like. I am hopeless at those tasks. I have to invest heavily to make fluff sound decent.</p>
<p>My approach to these exercises depends on the degree of pointlessness.</p>
<p>If the task relates to a process that will have zero impact on what anyone will do, I simply give the task to ChatGPT, let it do the first cut and then tweak as required. One or two sentences of guidance often get you 80% of the way there.</p>
<p>If I think there is a positive benefit to the task, or it’s for public consumption, I’ll be more proactive first up. I will write a rough draft, not caring much about the writing but making sure the concepts I want to include are there. It might be in dot points. Then I’ll ask ChatGPT for a version that is “clearer”, “simpler” or “better written” or “for a ten-year-old”.</p>
<p>Recently, I needed to describe how a program met a set of quality criteria. I uploaded some documents describing the program and a pdf that contained the criteria (in a table). I then asked Claude to provide me with short paragraphs describing how the program met the criteria. Some mild tweaking and I was there.</p>
</section>
<section id="generating-quiz-questions" class="level3">
<h3 class="anchored" data-anchor-id="generating-quiz-questions">Generating quiz questions</h3>
<ul>
<li>Efficiency gain: 3x</li>
</ul>
<p>One of the best ways to learn is to be tested. As a result, I offer students in my undergraduate subject a series of practice quizzes that they can work through.</p>
<p>It’s hard work to generate questions in bulk, and I struggle to generate plausible-sounding but incorrect answers to multiple-choice questions. I now ask ChatGPT to generate them. I upload my subject notes and ask that they be used as the basis of the questions. In the prompts, I vary in the specificity of the questions. “Give me 20 multiple choice questions testing the concept of loss aversion.” “Give me 20 multiple choice questions testing prospect theory.” Out of each batch, only a few will be suitable. But by tweaking my instruction by, say, describing the level of the students (undergraduate) or more explicitly defining the concept, it doesn’t take long to get 10 or so good questions.</p>
<p>I have also used ChatGPT to generate question ideas for assessable quizzes and exams. That exam is a closed-book AI-invigilated exam, so is less vulnerable to someone simply feeding the questions back to ChatGPT. One helpful approach was to upload some previous exams plus my subject notes and ask for new exam questions at the same level of difficulty or on the same concepts.</p>
</section>
</section>
<section id="ai-voiced-lectures" class="level2">
<h2 class="anchored" data-anchor-id="ai-voiced-lectures">AI-voiced lectures</h2>
<ul>
<li>Efficiency gain: 10%</li>
<li>Quality gain: 50%</li>
</ul>
<p>Last year I decided to base my undergraduate behavioural economics subject around <a href="https://www.youtube.com/@jasonacollins">short pre-recorded videos</a>, interactive online seminars and tutorials. To produce the videos I wrote scripts, which also form the <a href="https://behaviouraleconomics.jasoncollins.blog">subject notes</a>. I read the notes accompanied by slides.</p>
<p>There are three pain points in this exercise. First, I speak too fast (even when I think I’m speaking slow) and I enunciate many words poorly. Second, recording takes a lot of time. I rarely get a two to five-minute video in a single take that I’m happy with. Third, if I want to tweak the recording, I need to either re-record solid chunks of text or fiddle around with video edits.</p>
<p>So, why not get an artificial voice to do the speaking? When I wrote my last post, AI-voiced lectures were the future. It’s now a core part of my subject delivery.</p>
<p>I experimented with <a href="https://murf.ai">Murf.ai</a>, <a href="https://speechify.com">Speechify</a>, <a href="https://play.ht/">play.ht</a> and <a href="https://beta.elevenlabs.io">ElevenLabs</a>. Initially I used Murf.ai to make some videos, as it allowed me to pair slides and text easily. I could also integrate with Google Slides. However, the voices sound a bit robotic, so I currently use ElevenLabs, even though all I get is an audio file. ElevenLabs has fantastic voices. Even a hint of AI voicing gets a negative reaction from students, so voice quality needs to be my primary criterion. If the Murf.ai voices improve and Eleven doesn’t develop video integration, I may shift back.</p>
<p>The production process is easy. I paste the text into an ElevenLabs project chapter and render the voice. Typically, the pacing won’t be quite right, so I’ll add some commas and dashes to create some pauses. I then export the voice file and combine it with images in Final Cut Pro. I can normally create a five to 10 minute video from text and slides in less than a hour.</p>
<p>The fantastic part is that if I want to update a section or change a sentence, I update the script in ElevenLabs, re-render the relevant sentences, load a new voice file into the Final Cut Pro project and tweak the slide timings (if the voice edits require it). It’s fast, simple and gives me a consistently high-quality video.</p>
<p>ElevenLabs can “clone” your voice. I tried a quick clone on play.ht, but it gave me an American accent. On ElevenLabs, you can get a professional clone of a voice by uploading three or more hours of audio. I did that, and it sounds just like me, even with the Australian accent. Unfortunately, it comes with my faults, particularly speaking too fast. ElevenLabs doesn’t have an option to slow down the speaking outside of putting a mountain of dashes through the text. It also reflects the quality of my home recording setup and sounds a bit echoey. So, for now, I’m using one of their off-the-shelf Australian voices.</p>
<p>Here are two samples of the above paragraph, an off-the-shelf Australian voice and my “cloned” voice.</p>
<audio controls="" src="img/ElevenLabs_2024-07-15T09_03_10_Charlie_pre_s50_sb75_m1.mp3">
</audio>
<audio controls="" src="img/ElevenLabs_JC.mp3">
</audio>
<p>I’ve also started looking at options to create an AI avatar based on videos or photos of me for some parts of the videos. I’m leaving that one for the moment but can see myself revisiting it in the next year.</p>
</section>
<section id="accessing-github-copilot" class="level2">
<h2 class="anchored" data-anchor-id="accessing-github-copilot">Accessing GitHub CoPilot</h2>
<p>The below gives the basic steps to access GitHub CoPilot.</p>
<p>If you are an academic, you can sign up for (free) academic access to CoPilot at <a href="https://education.github.com/discount_requests/application">this link</a>. If you’re not an academic or student, sign up for a free trial as described <a href="https://docs.github.com/en/billing/managing-billing-for-github-copilot/managing-your-github-copilot-subscription-for-your-personal-account">here</a>. You’ll need a Github account to do this. The $10 a month is worth it.</p>
<p>Visual Studio Code is available <a href="https://code.visualstudio.com">here</a>. (I use the Mac version.) Download and install.</p>
<p>Install the Github CoPilot extension into Visual Studio Code. Instructions on installing the extension are <a href="https://docs.github.com/en/copilot/quickstart#installing-the-github-copilot-extension-for-visual-studio-code">here</a>. On installation you’ll be prompted to login to GitHub to gain access to authorise CoPilot.</p>
<p>Once you have done that, using CoPilot is easy. You simply type. As you type, you will be given suggestions.</p>
<p>The setup in RStudio is even easier. Download RStudio from <a href="https://posit.co/download/rstudio-desktop/">here</a>. Under Tools/Global Options is a CoPilot menu item. Enable CoPilot there. You will be asked to enter your GitHub login details to get it running.</p>
<p>I write in markdown (and at the moment, a flavour of markdown called <a href="https://quarto.org">Quarto</a>). It allows me to include <img src="https://latex.codecogs.com/png.latex?%5CLaTeX"> math and R computations within any document (as I have in this post). If you’re an academic stuck in the <img src="https://latex.codecogs.com/png.latex?%5CLaTeX"> ecosystem, you can also write in Visual Studio Code wholly in <img src="https://latex.codecogs.com/png.latex?%5CLaTeX">. You can also just get CoPilot in Word. I’m looking forward to my university moving beyond the experimental stage and giving us access. (I took a one-month free trial of Microsoft CoPilot on the home computer, but didn’t find the time to give it a proper go.)</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-prelec1998" class="csl-entry">
Prelec, D. (1998). The probability weighting function. <em>Econometrica</em>, <em>66</em>(3), 497–527. <a href="https://doi.org/10.2307/2998573">https://doi.org/10.2307/2998573</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/using-generative-AI-as-academic-july-2024-edition.html</guid>
  <pubDate>Mon, 15 Jul 2024 09:00:00 GMT</pubDate>
  <media:content url="https://www.jasoncollins.blog/posts/img/gen-AI.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>The psychological and genes’ eye view of ergodicity economics</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics.html</link>
  <description><![CDATA[ 




<p>This post was my plan for a presentation at the <a href="https://www.furconference.org/fur-2024/">Foundation of Utility and Risk Conference</a>. I drew on my previous posts laying out the <a href="https://www.jasoncollins.blog/posts/ergodicity-economics-a-primer">foundations of ergodicity economics</a> and examining <a href="https://www.jasoncollins.blog/posts/risk-and-loss-aversion-in-ergodicity-economics">what ergodicity economics states about risk preferences</a>. This varied somewhat from delivery (I’m easily waylaid and skipped a couple of sections). Given it’s to a technical audience, there are a few moments that might lose the lay reader.</p>
<p>–</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This presentation started with a blog post. Around five years ago when I was ensconced in the corporate world, I wrote a couple of posts on an idea called ergodicity economics. A random physicist, <a href="https://x.com/ole_b_peters">Ole Peters</a>, was riling people up on twitter about how economists were doing it wrong, how expected utility theory was fatally flawed, how you don’t need to introduce psychology to explain human decisions under risk, and how all the anomalies in behavioural economics could be reconciled with his new theory.</p>
<p>There were plenty of people countering the stronger statements, but I thought that by writing a post or two I could understand the idea better myself. So I ignored the hyperbole and tried to give a fair hearing to the underlying idea. Since I had some background in evolutionary biology, I also tried to view it from an evolutionary lens.</p>
<p>In the spirit of those original posts, I am going to avoid today’s presentation from becoming an exercise in attacking the most outlandish statements. There are a couple of published critiques of ergodicity economics, one by Jason Doctor et al <span class="citation" data-cites="doctor2020">(2020)</span> in Nature Physics and one more recent by Matthew Ford and John Kay <span class="citation" data-cites="ford2023">(2023)</span> in Econ Journal Watch that do a good job of addressing the claims about economics and expected utility theory. Instead, I’m going to give a flat description of ergodicity economics, before laying out some psychological and evolutionary observations.</p>
<section id="the-bet" class="level3">
<h3 class="anchored" data-anchor-id="the-bet">The bet</h3>
<p>So let me start with the classic example used to illustrate what ergodicity economics is about. You may have seen this before.</p>
<blockquote class="blockquote">
<p>Suppose you are offered a series of 100 bets on the flip of a coin. You win 50% of your wealth on heads. You lose 40% of your wealth on tails. Do you take the bet?</p>
</blockquote>
<p>The expected value of the bet is 5% of your wealth each flip. Continue playing for many rounds and your expected wealth is very large.</p>
<p>However, what is the most probable outcome over many repeats of this bet?</p>
<p>This plot is the result of a simulation of 10,000 people, each starting with $100, experiencing the 100 flips. The black line is the average wealth of the population. The red lines are paths of the first 20 people in the simulation.</p>
<div class="cell">
<details class="code-fold">
<summary>Setup code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the required packages</span></span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(scales) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#use the percent scale later</span></span>
<span id="cb1-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(dplyr) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#use the filter function later</span></span></code></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code for bet function</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a function for running of the bets.</span></span>
<span id="cb2-2"></span>
<span id="cb2-3">bet <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(p, n, t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">start=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, gain, loss, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ergodic=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">absorbing=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>){</span>
<span id="cb2-4"></span>
<span id="cb2-5">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#p is probability of a gain</span></span>
<span id="cb2-6">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#n is how many people in the simulation</span></span>
<span id="cb2-7">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#t is the number of coin flips simulated for each person</span></span>
<span id="cb2-8">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#start is the number of dollars each person starts with</span></span>
<span id="cb2-9">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#if ergodic=FALSE, gain and loss are the multipliers</span></span>
<span id="cb2-10">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#if ergodic=TRUE, gain and loss are the dollar amounts</span></span>
<span id="cb2-11">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#if absorbing=TRUE, zero wealth ends the series of flips for that person</span></span>
<span id="cb2-12"></span>
<span id="cb2-13">  params <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.data.frame</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(p, n, t, start, gain, loss, ergodic, absorbing))</span>
<span id="cb2-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rownames</span>(params) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"p"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"n"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"t"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"start"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gain"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"loss"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ergodic"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"absorbing"</span>)</span>
<span id="cb2-15">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(params) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span></span>
<span id="cb2-16"></span>
<span id="cb2-17">  sim <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> n)</span>
<span id="cb2-18"></span>
<span id="cb2-19">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span>(ergodic<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>){</span>
<span id="cb2-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (j <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n) {</span>
<span id="cb2-21">      x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> start</span>
<span id="cb2-22">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>t) {</span>
<span id="cb2-23">      outcome <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbinom</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">prob=</span>p)</span>
<span id="cb2-24">      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(outcome<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>loss, x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>gain)</span>
<span id="cb2-25">      sim[i,j] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x</span>
<span id="cb2-26">      }</span>
<span id="cb2-27">    }</span>
<span id="cb2-28">  }</span>
<span id="cb2-29"></span>
<span id="cb2-30"> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span>(ergodic<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>){</span>
<span id="cb2-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (j <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n) {</span>
<span id="cb2-32">      x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> start </span>
<span id="cb2-33">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>t) {</span>
<span id="cb2-34">      outcome <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbinom</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">prob=</span>p)</span>
<span id="cb2-35">      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(outcome<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>loss, x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>gain)</span>
<span id="cb2-36">      sim[i,j] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x</span>
<span id="cb2-37">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span>(absorbing<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>){</span>
<span id="cb2-38">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span>(x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>){</span>
<span id="cb2-39">          sim[i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>t,j] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb2-40">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">break</span></span>
<span id="cb2-41">        }</span>
<span id="cb2-42">        }</span>
<span id="cb2-43">      }</span>
<span id="cb2-44">    }</span>
<span id="cb2-45">  }</span>
<span id="cb2-46"></span>
<span id="cb2-47">  sim <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbind</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rep</span>(start,n), sim) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#placing the starting sum in the first row</span></span>
<span id="cb2-48">  sim <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,t), sim) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#number each period</span></span>
<span id="cb2-49">  sim <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(sim)</span>
<span id="cb2-50">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colnames</span>(sim) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"period"</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste0</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"p"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n))</span>
<span id="cb2-51">  sim <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">params=</span>params, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>sim)</span>
<span id="cb2-52">  sim</span>
<span id="cb2-53">}</span></code></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code to run simulation</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulate 10,000 people who accept a series of 1000 50:50 bets to win \$50 or lose \$40 from a starting wealth of \$100.</span></span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20240705</span>)</span>
<span id="cb3-4">nonErgodic <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bet</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">p=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">gain=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">loss=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ergodic=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code for plot</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to plot individual paths and average wealth over a set number of periods.</span></span>
<span id="cb4-2">plotWealth <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(sim, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">people =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>) {</span>
<span id="cb4-3">  basePlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(t<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),], <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> period)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb4-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Wealth ($)"</span>)</span>
<span id="cb4-5"></span>
<span id="cb4-6">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add lines for individual paths if specified</span></span>
<span id="cb4-7">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">is.null</span>(people)) {</span>
<span id="cb4-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>people) {</span>
<span id="cb4-9">      basePlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> basePlot <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb4-10">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!!</span>sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(t<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red"</span>)</span>
<span id="cb4-11">    }</span>
<span id="cb4-12">  }</span>
<span id="cb4-13"></span>
<span id="cb4-14">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add line for average wealth</span></span>
<span id="cb4-15">  basePlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> basePlot <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb4-16">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rowMeans</span>(sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(t<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)])), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"black"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linewidth =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-17">  </span>
<span id="cb4-18">  basePlot</span>
<span id="cb4-19">}</span>
<span id="cb4-20"></span>
<span id="cb4-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate the plot with individual paths and average wealth</span></span>
<span id="cb4-22">nonErgodicPlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plotWealth</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim =</span> nonErgodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">people =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb4-23">nonErgodicPlot</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Plot of first 20 people against average wealth
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Plot of first 20 people against average wealth"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-1-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<p>The sudden drop in mean wealth toward the end of the sequence is an interesting feature that I will ignore for the moment. But look at the red lines. At the end of 100 periods, all are below the mean wealth, and only one of the 20 agents has enough wealth at the end that you can discern the line from the x-axis.</p>
<p>Let us now use a log scale to enable us to see the pattern more clearly.</p>
<div class="cell">
<details class="code-fold">
<summary>Code for log plot</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot both the average outcome and first twenty people on the same plot.</span></span>
<span id="cb5-2"></span>
<span id="cb5-3">logNonErgodicPlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plotWealth</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>nonErgodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">people=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb5-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_log10</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0001</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100000</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">labels =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.0001"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100000"</span>))</span>
<span id="cb5-5">logNonErgodicPlot</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Plot of first 20 people against average wealth (log scale)
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Plot of first 20 people against average wealth (log scale)"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-2-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<p>All 20 of these people are below the mean wealth. Only one is ahead of where they started.</p>
<div class="cell">
<details class="code-fold">
<summary>Code to create function to generate summary statistics</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a function to generate summary statistics.</span></span>
<span id="cb6-2">summaryStats <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(sim, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>) {</span>
<span id="cb6-3">  </span>
<span id="cb6-4">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the wealth data for the specified time</span></span>
<span id="cb6-5">  wealth_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.matrix</span>(sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[(t <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, ] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)])</span>
<span id="cb6-6">  </span>
<span id="cb6-7">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate mean wealth</span></span>
<span id="cb6-8">  mean_wealth <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(wealth_data)</span>
<span id="cb6-9">  </span>
<span id="cb6-10">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate median wealth</span></span>
<span id="cb6-11">  median_wealth <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">median</span>(wealth_data)</span>
<span id="cb6-12">  </span>
<span id="cb6-13">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number and percentage who lost more than 99% of their wealth</span></span>
<span id="cb6-14">  num_lost_99 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(wealth_data <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> (sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, ] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>))</span>
<span id="cb6-15">  perc_lost_99 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> (num_lost_99 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, ]) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb6-16">  </span>
<span id="cb6-17">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number and percentage who gained wealth</span></span>
<span id="cb6-18">  num_gain <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(wealth_data <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, ])</span>
<span id="cb6-19">  perc_gain <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> (num_gain <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, ]) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb6-20">  </span>
<span id="cb6-21">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number who increased their wealth more than 100-fold</span></span>
<span id="cb6-22">  num_increased_100 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(wealth_data <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> (sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, ] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>))</span>
<span id="cb6-23">  </span>
<span id="cb6-24">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Wealth and wealth share of the wealthiest person</span></span>
<span id="cb6-25">  max_wealth <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(wealth_data)</span>
<span id="cb6-26">  perc_max_wealth_share <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> max_wealth <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(wealth_data) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb6-27">  </span>
<span id="cb6-28">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Combine all statistics into a data frame</span></span>
<span id="cb6-29">  stats <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb6-30">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mean_wealth =</span> mean_wealth,</span>
<span id="cb6-31">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">median_wealth =</span> median_wealth,</span>
<span id="cb6-32">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">num_lost_99 =</span> num_lost_99,</span>
<span id="cb6-33">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">perc_lost_99 =</span> perc_lost_99,</span>
<span id="cb6-34">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">num_gain =</span> num_gain,</span>
<span id="cb6-35">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">perc_gain =</span> perc_gain,</span>
<span id="cb6-36">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">num_increased_100 =</span> num_increased_100,</span>
<span id="cb6-37">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">max_wealth =</span> max_wealth,</span>
<span id="cb6-38">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">perc_max_wealth_share =</span> perc_max_wealth_share</span>
<span id="cb6-39">  )</span>
<span id="cb6-40">  </span>
<span id="cb6-41">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">return</span>(stats)</span>
<span id="cb6-42">}</span>
<span id="cb6-43"></span>
<span id="cb6-44"></span>
<span id="cb6-45">nonErgodicStats <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summaryStats</span>(nonErgodic, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span></code></pre></div>
</details>
</div>
<p>These 20 people are representative of the broader population. Across the 10,000 agents in this simulation, 86 per cent lost money. The mean wealth was $22303, but the median wealth was $0.52.</p>
<p>What is the intuition behind this?</p>
<p>The black line reflects the expected gain of 5% per flip.</p>
<p>But for the red lines, over the long term, an individual will tend to get around half heads and half tails. As the number of flips goes to infinite, the proportion of heads or tails “<a href="https://en.wikipedia.org/wiki/Almost_surely">almost surely</a>” converges to 0.5. This means that each person will tend to get a 50% increase half the time (or 1.5 times the initial wealth), and a 40% decrease half the time (60% of the initial wealth). The time average growth in wealth for an individual is <img src="https://latex.codecogs.com/png.latex?(1.5%5Ctimes%200.6)%5E%7B0.5%7D%20%5Csim%200.95">, or approximately a 5% decline in wealth each period. Every individual’s wealth will tend to decay at that rate. The black line is held up by a very lucky few.</p>
<p>A system where the time average converges to the ensemble average (our population mean) is known as an ergodic system. The sequence of gambles I have just shown you is non-ergodic as the time average and the ensemble average diverge. (I’ll ignore the finer debates about whether this problem even involves ergodicity to the side.)</p>
<p>This leads to the following claim: as we cannot individually experience the ensemble average, the ensemble average is not what humans consider in their decision making. Instead, people maximise the time average growth rate of wealth. For this bet, as the time average growth rate is negative, an ergodicity economics agent would reject the bet.</p>
<p>Contrast this with the expected utility approach, where the utility of each outcome is weighted by its probability and summed to give the expected utility. Expected utility theory would be consistent with both accepting and rejecting the bet depending on the particular utility function.</p>
<p>There is, however, an incidental alignment between ergodicity economics and expected utility theory. If a person has log utility - that is, they maximise the probability-weighted logarithm of the possible outcomes - they will maximise the time average growth rate.</p>
</section>
<section id="additive-versus-multiplicative" class="level3">
<h3 class="anchored" data-anchor-id="additive-versus-multiplicative">Additive versus multiplicative</h3>
<p>One important feature of the bet I have just shown is that the outcomes are multiplicative. A win on one flip leads to a larger stake flip on the next bet. The size of the bet scales up or down with wealth.</p>
<p>What if I offered you the following bet instead?</p>
<blockquote class="blockquote">
<p>You have $100 and are offered a gamble involving a series of 100 coin flips. For each flip, heads will increase your wealth by $50. Tails will decrease it by $40. Do you take the bet?</p>
</blockquote>
<p>You can see the tweak from the original bet, with dollar sums rather than percentages. For someone with $100 in wealth, the first flip is effectively identical, but future bets will be additive on that result and always involve the same shift of $50 up or $40 down.</p>
<p>This second series of flips is ergodic. The expected value of each flip is $5 (<img src="https://latex.codecogs.com/png.latex?0.5%5Ctimes%20%5C$50-0.5%5Ctimes%20%5C$40=%5C$5">). The time-average growth rate is also $5.</p>
<p>Let’s simulate as we did for multiplicative bets, with 10,000 people starting with $100 and flipping the coin 100 times. This plot shows the average wealth of the population, together with the paths of the first 20 of the 10,000 people (in red).</p>
<div class="cell">
<details class="code-fold">
<summary>Code to simulate ergodic environment</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulate 10,000 people who accept a series of 1000 50:50 bets to win \$50 or lose \$40 from a starting wealth of \$100.</span></span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20240705</span>)</span>
<span id="cb7-4">ergodic <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bet</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">p=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">gain=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">loss=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ergodic=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">absorbing=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code to plot ergodic simulation</summary>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot both the average outcome and first twenty people on the same plot.</span></span>
<span id="cb8-2"></span>
<span id="cb8-3">ergodicPlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plotWealth</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>ergodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">people=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb8-4">ergodicPlot</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Average wealth of population and path of first 20 people
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-3-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Average wealth of population and path of first 20 people"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-3-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code to generate ergodic summary statistics</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate summary statistics for the population and wealthiest person after 100 and 1000 flips}</span></span>
<span id="cb9-2"></span>
<span id="cb9-3">summaryErgodic100 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summaryStats</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>ergodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span></code></pre></div>
</details>
</div>
<p>The individual growth paths cluster on either side of the population average. After 100 flips, the mean wealth is $602 and the median $600. 87% of the population has gained in wealth. This alignment between the mean and median wealth, and the relatively equal distribution of wealth, are characteristic of an ergodic system.</p>
<div class="cell">
<details class="code-fold">
<summary>Code to calculate number with zero wealth</summary>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Determine how many people (in the first people out of n) experienced zero wealth or less during the simulation.</span></span>
<span id="cb10-2"></span>
<span id="cb10-3">numZero <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(sim, t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subset=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>){</span>
<span id="cb10-4"></span>
<span id="cb10-5">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#subset</span></span>
<span id="cb10-6">  data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span>(subset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> subset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,]){</span>
<span id="cb10-7">    sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>t,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>params[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)]</span>
<span id="cb10-8">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> {</span>
<span id="cb10-9">    sim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>t,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(subset<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)]</span>
<span id="cb10-10">  }</span>
<span id="cb10-11">  </span>
<span id="cb10-12">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># number of people who experienced zero wealth or less</span></span>
<span id="cb10-13">  numZero <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(data) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sapply</span>(data, <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(x) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">all</span>(x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)))</span>
<span id="cb10-14">  numZero</span>
<span id="cb10-15">  </span>
<span id="cb10-16">}</span>
<span id="cb10-17"></span>
<span id="cb10-18">numZeroTwenty100 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">numZero</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>ergodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subset=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb10-19">numZeroTwenty1000 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">numZero</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>ergodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subset=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb10-20">numZero100 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">numZero</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>ergodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb10-21">numZero1000 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">numZero</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>ergodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span></code></pre></div>
</details>
</div>
<p>Now for a wrinkle, which we can see in the plotted figure. Of those first 20 people plotted on the chart, 11(!) had their wealth go into the negative over those 100 periods. We see the same phenomenon across the broader population, with 5433 dropping below zero in those first 100 periods.</p>
<p>To the extent zero wealth is ruinous when it occurs, that event is severe. If the player only incurs the consequences of their final position, the bet is unlikely to result in ruin but still presents a non-zero threat of catastrophe.</p>
<p>What would an expected utility maximiser do here? For a person with log utility, any probability of ruin during the flips would lead them to reject the gamble. The log of zero is negative infinite, which outweighs all other possible outcomes, whatever their magnitude or probability.</p>
<p>The growth-rate maximiser would accept the bet if they didn’t fear ruin. The time-average growth of $5 per flip would pull them in. If ruin was feared and consequential, then they might also reject.</p>
</section>
<section id="the-ergodicity-economics-hypothesis" class="level3">
<h3 class="anchored" data-anchor-id="the-ergodicity-economics-hypothesis">The ergodicity economics hypothesis</h3>
<p>This brings us to the core hypotheses in ergodicity economics.</p>
<p>First, people act to maximise the time-average growth rate of their wealth.</p>
<p>Second, the optimal action to maximise the time-average growth rate varies between multiplicative and additive environments. In multiplicative environments, people have log utility. In additive environments, they are risk neutral.</p>
</section>
<section id="what-are-the-implications-of-this-finding" class="level3">
<h3 class="anchored" data-anchor-id="what-are-the-implications-of-this-finding">What are the implications of this finding?</h3>
<p>The advocates of ergodicity economics have applied this claim to a range of economics problems.</p>
<p><span class="citation" data-cites="peters2023">Peters (2023)</span> argues that we can think of insurance as a tool to make wealth grow faster rather than as protection for the risk averse. This plot shows the outcomes for agents facing a 5% probability of a loss of 95% of their wealth each period. Uninsured agents experience ruinous path over time, losing far more than would be implied by the expected value. Those who insure at a cost experience a slower decline.</p>
<p>As an aside, I do find these numbers quite comical: 2500 periods with a 5% probability of loss, leading to an expected value of around <img src="https://latex.codecogs.com/png.latex?10%5E%7B-70%7D"> times the initial wealth even under the insured scenario. The expected-value optimisers, even if they stated with every atom in the universe, would be left with a fraction of an atom by the end.</p>
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/peters-2023-figure-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/peters-2023-figure-3.png" class="img-fluid" style="width:60.0%"></a></p>
<p><span class="citation" data-cites="peters2022">Peters and Adamou (2022)</span> similarly propose a desire to maximise the growth rate as the origin of cooperative behaviour. Here, the green trajectories are the selfish agents, the blue line the cooperators. In some ways, this is just the insurance problem reframed.</p>
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/peters-and-adamou-2022-figure-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/peters-and-adamou-2022-figure-2.png" class="img-fluid" style="width:60.0%"></a></p>
<p>One of the more interesting examples concerns time preference. <span class="citation" data-cites="adamou2021">Adamou et al. (2021)</span> use growth rate maximisation as an explanation for exponential discounting, hyperbolic discounting and preference reversals, depending on the particular wealth dynamic.</p>
<p>I won’t cover all the scenarios, but this image captures a situation where an agent in an additive world has a choice between a smaller sooner and a larger later pay-off. This agent seeks to maximise the growth rate of their wealth. From the perspective of <img src="https://latex.codecogs.com/png.latex?t_0"> the larger later pay-off provides a higher growth rate, which is equal to the slope of the line extended to the top of that pay-off. By the third frame, as the agent moves closer to the smaller, sooner pay-off, the higher growth rate now comes from that early pay-off. They have reversed their preference.</p>
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/adamou-et-al-2021-figure-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/adamou-et-al-2021-figure-3.png" class="img-fluid"></a></p>
<p>It is when seeing ideas such as this that the suggestion that ergodicity economics is a “psychology free” seem slightly ridiculous. The agent must be myopic to be unable to see their upcoming preference reversal, or to realise the foregone larger opportunity on the other side of that smaller sooner payment.</p>
</section>
</section>
<section id="the-experiment" class="level2">
<h2 class="anchored" data-anchor-id="the-experiment">The experiment</h2>
<p>But rather than going down that rabbit-hole, I want to present an experimental result. In 2019, a working paper was released examining whether shifting between an additive and multiplicative environment would change risk preferences. One of my blog posts was on that working paper. The paper was ultimately published in 2021 in PLOS Computational Biology <span class="citation" data-cites="meder2021">(Meder et al., 2021)</span>.</p>
<p>That first experiment was subject to many criticisms, including by me, so <span class="citation" data-cites="skjold">Skjold et al. (2024)</span> designed a new experiment. A pre-print describing the results from this experiment was released at the end of May. Some of the criticisms have been addressed in this new experiment, and the result is interesting.</p>
<p>Experimental participants were randomised to an additive or multiplicative environment where they were asked to make a series of bets. After making the bets in one environment, they were crossed over to the other.</p>
<p>At the beginning of the additive and multiplicative session, participants were trained on a set of fractal images, each of which had a specific effect on their endowment: multiplication by some fraction in the multiplicative session, or addition or subtraction of some sum in the additive session. Participants were then tested on whether they had learnt the ordering of the fractals, with the subset of participants with low learning excluded from the analysis. This image shows the training procedure, which essentially comprises exposure to the fractal and then an update to their wealth.</p>
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/skjold-et-al-2024-figure-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/skjold-et-al-2024-figure-1.png" class="img-fluid"></a></p>
<p>This use of fractals instead of numbers is one of the confounding factors that could influence the results: we have introduced ambiguity into the subsequent decisions. It was one of my critiques of the original experiment, but I clearly wasn’t very persuasive. Anyhow, let’s ignore that for now.</p>
<p>Participants then proceeded to their decision task, where they had to choose between gambles, each of which is represented by two of the fractal images. Over a sequence of 160 decisions, they would be shown the gambles, make their choice, be shown the outcome of the gamble, then see the effect of the outcome on their wealth.</p>
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/skjold-et-al-2024-figure-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/skjold-et-al-2024-figure-4.png" class="img-fluid"></a></p>
<p>You can watch a video of the training and decision task below. (I didn’t show this video in the presentation.)</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/uLGA4Ym-OYA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Participants were incentivised by being paid their relative proportion of points compared to a rolling window of 10 participants. Another exhibit of “why do we make experimental incentives so complicated” and another confound to the experimental result. By rewarding on proportional access to a pool, they have introduced diminishing gains and a cap on winnings. But again, I’ll ignore that for today.</p>
<p>So, to the result. The research team modelled participants as having an isoelastic utility function (a reasonably strong assumption), with the parameter <img src="https://latex.codecogs.com/png.latex?%5Ceta"> calculated by Bayesian cognitive modelling.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_%7B%5Ceta%7D(x)=%5Cbegin%7Bcases%7D%0A%5Cfrac%7Bx%5E%7B1-%5Ceta%7D%20-%201%7D%7B1-%5Ceta%7D%20&amp;%20%5Ctext%7Bif%20%7D%20%5Ceta%20%5Cneq%201%20%5C%5C%5B6pt%5D%0A%5Cln(x)%20&amp;%20%5Ctext%7Bif%20%7D%20%5Ceta%20=%201%0A%5Cend%7Bcases%7D%0A"></p>
<p>What would we predict the value of <img src="https://latex.codecogs.com/png.latex?%5Ceta"> to be in this experiment? Expected utility theory is quiet on the precise value. The ergodicity economics approach, however, gives us a prediction. First, <img src="https://latex.codecogs.com/png.latex?%5Ceta"> will be one in the multiplicative condition, as log utility maximises the growth rate. Second, <img src="https://latex.codecogs.com/png.latex?%5Ceta"> will be zero in the additive condition. The growth rate is maximised in an additive environment by risk neutral behaviour.</p>
<p>This chart shows the result. Thin lines represent individual participants. The thick lines represent the aggregate. For the additive scenario, participants were close to risk neutral: the aggregate estimate of <img src="https://latex.codecogs.com/png.latex?%5Ceta"> was 0.1. For the multiplicative condition, although there was a wider distribution of values, the central estimate of <img src="https://latex.codecogs.com/png.latex?%5Ceta"> was one.</p>
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/skjold-et-al-2024-figure-7c.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/skjold-et-al-2024-figure-7c.png" class="img-fluid"></a></p>
<p>Despite the elements of this experiment that I would do differently - I have only hinted at a couple - this is a strong result.</p>
<p>If the ergodocity economics hypotheis is correct, it is worth thinking about what this means psychologically.</p>
<p>When modelling the utility function, the researchers took the value of <img src="https://latex.codecogs.com/png.latex?x"> to be the participant’s experimental wealth at the time the participant makes their decision. It is the initial endowment, plus or minus the results of the previous bets. <img src="https://latex.codecogs.com/png.latex?x"> does not include outside wealth.</p>
<p>But if this use of <img src="https://latex.codecogs.com/png.latex?x"> is an accurate characterisation of the decision making process of the agents, it suggests a form of narrow bracketing or a degree of myopia. Agents are maximising the growth rate <em>within</em> the experiment, not more generally. We need to introduce some psychology to explain this. (This phenomenon is common across lab experiments involving risky decisions.)</p>
<p>Similarly, this experiment is part of a broader environment with either multiplicative or additive characteristics. Experimental participants can take their payment from the experiment and invest it. Maximising the growth rate in the additive condition by maximising expected value may not maximise the total growth rate if the world outside the experiment is multiplicative.</p>
</section>
<section id="an-evolutionary-analysis" class="level2">
<h2 class="anchored" data-anchor-id="an-evolutionary-analysis">An evolutionary analysis</h2>
<p>Now, via a rather long and winding path, I want to turn to a couple of evolutionary observations about ergodicity economics. There is a large literature in the evolution of preferences, not to mention in the evolutionary biology literature itself, that is relevant to an analysis of growth rate maximisation. Since the concepts are already there, I’m going to lean on them and turn them to my own purpose.</p>
<p>The first evolutionary angle concerns what happens when we take a gene’s eye view. And to assist me in making this point, let me show a quote from a Nature Physics paper in which Ole Peters <span class="citation" data-cites="peters2019">(2019)</span> summarises his work:</p>
<blockquote class="blockquote">
<p>[I]n maximizing the expectation value - an ensemble average over all possible outcomes of the gamble - expected utility theory implicitly assumes that individuals can interact with copies of themselves, effectively in parallel universes (the other members of the ensemble). An expectation value of a non-ergodic observable physically corresponds to pooling and sharing among many entities. That may reflect what happens in a specially designed large collective, but it doesn’t reflect the situation of an individual decision-maker.</p>
</blockquote>
<p>Ignoring the fact that Peters mis-characterises expected utility theory, this idea of interacting with copies of themselves is what happens at the level of genes. By the presence of multiple copies of a gene across individuals, the gene can experience the ensemble average. The following toy model and simulation illustrates.</p>
<section id="a-toy-model" class="level3">
<h3 class="anchored" data-anchor-id="a-toy-model">A toy model</h3>
<p>Suppose two types of agents lived in a non-ergodic world.</p>
<p>One type of agent seeks to maximise the time-average growth rate of its number of descendants. This desire to maximise the time-average growth rate is a function of its genotype, and is transmitted to its children.</p>
<p>The other type of agent seeks to maximise the expected number of offspring. Similarly, this agent’s preferences are set genetically.</p>
<p>In the environment in which these agents live, they have a choice of strategy. One strategy is to have a single offspring asexually with certainty before they die. The other strategy is a 50:50 bet of having either 0.6 or 1.5 offspring. Part offspring sounds weird, but with a large population of agents, you can think of this as the average number of offspring. The simulation works out largely the same if I make the number of children probabilistic in accord with those numbers. You can see I have effectively mimicked the classic ergodicity economics bet.</p>
<p>One final feature in this environment will be that each individual experiences its own flip. You might think of this environment as involving idiosyncratic risk. This is an important assumption that I will return to.</p>
<p>Given this setup, the type that maximises the expected number of offspring always accepts the bet. The time-average growth maximiser always rejects it. Which would come to dominate the population?</p>
<p>The time-average growth rate maximiser population stays constant. One offspring to each asexual parent.</p>
<p>This is a chart of the population of the accepting type for a simulation of 100 generations, starting with a population of 10,000.</p>
<div class="cell">
<details class="code-fold">
<summary>Code for evolutionary simulation</summary>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20240705</span>)</span>
<span id="cb11-2"></span>
<span id="cb11-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># create function to round probabilistically - important when small numbers involved</span></span>
<span id="cb11-4">probabilistic_round <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(x) {</span>
<span id="cb11-5">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> x <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">floor</span>(x)) {</span>
<span id="cb11-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ceiling</span>(x)</span>
<span id="cb11-7">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> {</span>
<span id="cb11-8">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">floor</span>(x)</span>
<span id="cb11-9">  }</span>
<span id="cb11-10">}</span>
<span id="cb11-11"></span>
<span id="cb11-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to simulate evolution betting</span></span>
<span id="cb11-13">evolutionBet <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(p, n, t, gain, loss) {</span>
<span id="cb11-14">  </span>
<span id="cb11-15">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#p is probability of a gain</span></span>
<span id="cb11-16">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#region  is how many people in the simulation</span></span>
<span id="cb11-17">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#t is the number of generations simulated</span></span>
<span id="cb11-18">  </span>
<span id="cb11-19">  params <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">value =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(p, n, t, gain, loss))</span>
<span id="cb11-20">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rownames</span>(params) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"p"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"n"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"t"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gain"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"loss"</span>)</span>
<span id="cb11-21"></span>
<span id="cb11-22">  sim <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">numeric</span>(t <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb11-23">  sim[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> n <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Start population</span></span>
<span id="cb11-24"></span>
<span id="cb11-25">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>t) {</span>
<span id="cb11-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (j <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(n)) {</span>
<span id="cb11-27">      outcome <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbinom</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, p)</span>
<span id="cb11-28">      n <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> n <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(outcome <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, gain, loss) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb11-29">    }</span>
<span id="cb11-30">    n <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">probabilistic_round</span>(n)</span>
<span id="cb11-31">    sim[i <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> n</span>
<span id="cb11-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (n <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">break</span></span>
<span id="cb11-33">  }</span>
<span id="cb11-34"></span>
<span id="cb11-35">  sim <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">period =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>t, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n =</span> sim)</span>
<span id="cb11-36">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">params =</span> params, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim =</span> sim)</span>
<span id="cb11-37">}</span>
<span id="cb11-38"></span>
<span id="cb11-39">evolution <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">evolutionBet</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">p=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">gain=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">loss=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#more than 100 periods can take a very long time, simulation slows markedly as population grows</span></span></code></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code for evolutionary plot</summary>
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the population growth for the evolutionary scenario (Figure 8).</span></span>
<span id="cb12-2"></span>
<span id="cb12-3">basePlotEvo <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(evolution<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">101</span>),], <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>period))</span>
<span id="cb12-4"></span>
<span id="cb12-5">expectationPlotEvo <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> basePlotEvo <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb12-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y=</span>n), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linewidth=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb12-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Population"</span>)</span>
<span id="cb12-8"></span>
<span id="cb12-9">expectationPlotEvo</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-8" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Population of accepting types
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-8-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;4: Population of accepting types"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-8-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<p>You can see that they have a population growth rate of close to 5%.</p>
<p>Why don’t they experience the decline we saw in earlier simulations of this bet? Because their copies experience the full ensemble of outcomes.</p>
<p>So here we have a toy model that shows that time-average growth rate maximisation may not be the optimal strategy in a multiplicative environment. The constant population of time-average growth rate maximisers is swamped by the spreading population of the expected value maximisers.</p>
<p>This behaviour could also emerge where it did not previously exist. The simulation I just showed you had 10,000 agents with expected value maximising behaviour to start. What if we had a population of time-average growth rate optimisers, and a single expected value maximiser emerged?</p>
<p>I simulated 10,000 instances of a single individual developing the mutation. This plot shows the population of the first ten mutants. For five of them, the mutation appears and disappears. For the other five, however, they grow into a substantial population.It only takes a few agents with this mutation to effectively diversify the results.</p>
<div class="cell">
<details class="code-fold">
<summary>Code for evolutionary simulation</summary>
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># run 9 simulations with 1 accepting type to start</span></span>
<span id="cb13-2"></span>
<span id="cb13-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20240705</span>)</span>
<span id="cb13-4"></span>
<span id="cb13-5">mutations <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span></span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>mutations) {</span>
<span id="cb13-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">assign</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste0</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"evolution_"</span>, i), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">evolutionBet</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">p=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">gain=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">loss=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>))</span>
<span id="cb13-9">}</span>
<span id="cb13-10"></span>
<span id="cb13-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a data frame for each simulation and store in a list</span></span>
<span id="cb13-12">data_frames <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>()</span>
<span id="cb13-13"></span>
<span id="cb13-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> (i <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>mutations) {</span>
<span id="cb13-15">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dynamically retrieve the variable and select the first 101 rows of $sim</span></span>
<span id="cb13-16">  current_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste0</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"evolution_"</span>, i))<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>sim[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">101</span>, ]</span>
<span id="cb13-17">  </span>
<span id="cb13-18">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a column for 'i' to use as color in plotting</span></span>
<span id="cb13-19">  current_data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>i <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> i</span>
<span id="cb13-20">  </span>
<span id="cb13-21">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Append to the list</span></span>
<span id="cb13-22">  data_frames[[i]] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> current_data</span>
<span id="cb13-23">}</span>
<span id="cb13-24"></span>
<span id="cb13-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Combine all data frames into one</span></span>
<span id="cb13-26">combined_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">do.call</span>(rbind, data_frames)</span></code></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code to count mutation spread</summary>
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Count the number of simulations where the mutation spread (where n &gt; 1 when i = 100)</span></span>
<span id="cb14-2">mutation_count <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(combined_data[combined_data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>period <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>n <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">na.rm =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code for evolutionary plot with mutation</summary>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot first 10 lines</span></span>
<span id="cb15-2">mutationPlotEvo <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(combined_data[combined_data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>i <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> combined_data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>i <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,], <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>period, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y=</span>n, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">factor</span>(i))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Population"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-5">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#remove legend</span></span>
<span id="cb15-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">legend.position =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"none"</span>)</span>
<span id="cb15-7"></span>
<span id="cb15-8"></span>
<span id="cb15-9">mutationPlotEvo</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-9" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Population of accepting types with mutation
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-9-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;5: Population of accepting types with mutation"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-9-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<p>If we zoom into the first 35 periods, you can see the dynamic for those where the mutation did not spread.</p>
<div class="cell">
<details class="code-fold">
<summary>Code for evolutionary plot with mutation (first 30 periods)</summary>
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot first 35 periods only</span></span>
<span id="cb16-2">mutationPlotEvo30 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(combined_data[combined_data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>i <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> combined_data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>i <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,], <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>period, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y=</span>n, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">factor</span>(i))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb16-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb16-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Population"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb16-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">xlim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb16-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ylim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb16-7">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#remove legend</span></span>
<span id="cb16-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">legend.position =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"none"</span>)</span>
<span id="cb16-9"></span>
<span id="cb16-10">mutationPlotEvo30</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-10" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Population of accepting types with mutation (first 30 periods for first 10 agents)
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-10-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;6: Population of accepting types with mutation (first 30 periods for first 10 agents)"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-10-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<p>This is a slightly rosier picture than occurs across the full 10,000 simulations, where the mutation did not spread 70% of the time.</p>
<p>These illustrations suggest that time-average growth optimisation may not be the optimal strategy, but it hinges on one critical assumption: that risk is idiosyncratic. Diversification enables the gene to experience the ensemble average. What if such diversification is not possible?</p>
<p>In that case, we are effectively back to the world that I showed you at the beginning. You could consider each line to represent an individual and their children, with their children all bound to the same bet. In almost all cases, this leads to a decline in frequency. An extraordinarily lucky few might boom through many rolls of the dice, but that is a rare chance.</p>
<p>Further, recall decline toward the end of the 100 periods. This occurred as a small number of genetic lines comprise most of the population - in fact, one single line of the original 10,000 comprises 53% of the population at the end of 100 periods - and they cannot diversify their risk. A few unlucky coin flips and they are gone.</p>
<p>The result is that, over a long enough time horizon, <em>everyone</em> is wiped out. There is no longer a lucky few. Here’s the same simulation plotted through 1000 iterations, over evolutionary time, in both linear and log scales.</p>
<div class="cell">
<details class="code-fold">
<summary>Code for evolutionary plot over 1000 periods</summary>
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1">nonErgodicPlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plotWealth</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sim=</span>nonErgodic, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">t=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">people=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb17-2">nonErgodicPlot</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-11" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Population of accepting types over 1000 periods
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-11-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Figure&nbsp;7: Population of accepting types over 1000 periods"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-11-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code for evolutionary plot over 1000 periods (log scale)</summary>
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1">logNonErgodicPlot <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> nonErgodicPlot<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb18-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_log10</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0001</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100000</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">labels =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.0001"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100000"</span>))</span>
<span id="cb18-3">logNonErgodicPlot</span></code></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-ergodicity-presentation-12" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-ergodicity-presentation-12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Population of accepting types over 1000 periods (log scale)
</figcaption>
<div aria-describedby="fig-ergodicity-presentation-12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-12-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure&nbsp;8: Population of accepting types over 1000 periods (log scale)"><img src="https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics_files/figure-html/fig-ergodicity-presentation-12-1.png" class="img-fluid figure-img" width="672"></a>
</div>
</figure>
</div>
</div>
</div>
<p>The result is that with aggregate risk, time-average growth rate maximisation can be the optimal strategy.</p>
</section>
<section id="probability-matching" class="level3">
<h3 class="anchored" data-anchor-id="probability-matching">Probability matching</h3>
<p>To explore this in more detail, I’m going to turn to another example that has a rich history in the biology literature.</p>
<p>The particular example I am going to pick is a bit cartoonish, and comes from Andrew Lo’s <a href="ADD_LINK">Adaptive Markets</a>. This in turn draws on a more technical paper by Thomas Brennan and Lo <span class="citation" data-cites="brennan2011">(2011)</span> published in The Quarterly Journal of Finance to explain the evolution of probability matching. You can find other earlier examples in the literature, such as by <span class="citation" data-cites="cooper1982">Cooper and Kaplan (1982)</span> in The Journal of Theoretical Biology.</p>
<p>The example concerns an animal called the tribble. For amusement, I chucked an earlier draft of this presentation into ChatGPT and asked it to illustrate it. Most of what it produced was unusable, but I’ve kept a couple of images for which I thought it did a good job.</p>
<p>Tribbles live in a region comprising valleys and plateaus. Tribbles reproduce once in their life (producing three offspring asexually) and must choose whether to reproduce in the valley or on the plateau. This is a risky decision, however, as the valleys are affected by floods and the plateaus by drought.</p>
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/tribbles.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/tribbles.webp" class="img-fluid" width="512"></a></p>
<p>Each generation there is a 75 per cent probability of sun. In such a case, the tribbles born on the plateau perish. The other 25 per cent of the time, it rains, leading to flood in the valleys and the death of those tribbles breeding there.</p>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/flood.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/flood.webp" class="img-fluid"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><a href="img/the-psychological-and-genes-eye-view-of-ergodicity-economics/drought.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="https://www.jasoncollins.blog/posts/img/the-psychological-and-genes-eye-view-of-ergodicity-economics/drought.webp" class="img-fluid"></a></p>
</div>
</div>
</div>
<p>What, then, is the growth maximising breeding strategy?</p>
<p>Let’s set <img src="https://latex.codecogs.com/png.latex?q"> as the proportion of tribbles that breed in the valley. If we maximise the expected number of offspring, tribbles would breed in the valley 100 per cent of the time. That is, <img src="https://latex.codecogs.com/png.latex?q=1">, leading to an an expected <img src="https://latex.codecogs.com/png.latex?0.75%5Ctimes%203=2.25"> offspring.</p>
<p>However, in the long run, if all tribbles make this choice, the tribbles will be wiped out. Over the long term, the tribbles will experience droughts 75 per cent of the time and floods 25 per cent of the time. Putting this into the language of ergodicity economics, the time average growth rate is zero.</p>
<p>To find the <img src="https://latex.codecogs.com/png.latex?q"> that maximises the growth rate, we take the log of G and calculate the derivative. The solution is to breed in the valley 75 per cent of the time and on the plateau 25 per cent of the time.</p>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AG&amp;=3%5Ctimes%20q%5E%7B0.75%7D(1-q)%5E%7B0.25%7D%5C%5C%5B6pt%5D%0A%5C%5C%0A%5Clog(G)&amp;=%5Clog(3)+0.75%5Clog(q)+0.25%5Clog(1-q)%5C%5C%5B6pt%5D%0A%5C%5C%0A%5Cfrac%7Bd%7D%7Bdq%7D%5Clog(G)&amp;=%5Cfrac%7B0.75%7D%7Bq%7D-%5Cfrac%7B0.25%7D%7B1-q%7D=0%5C%5C%5B6pt%5D%0A%5C%5C%0Aq&amp;=0.75%0A%5Cend%7Balign*%7D">
<p>Probability matching in this world maximises the time-average growth rate.</p>
<p>This result is the same if we approach this from the perspective of log utility. If we maximise log utility as a function of number of offspring, we get the same value of <img src="https://latex.codecogs.com/png.latex?q">.</p>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AU(n)&amp;=0.75%5Ctimes%20%5Clog(3q)+0.25%5Ctimes%20log(3-3q))%5C%5C%5B6pt%5D%0A%5C%5C%0A%5Cfrac%7Bd%7D%7Bdq%7DU(n)&amp;=0.75%5Ctimes%20%5Cfrac%7B3%7D%7B3q%7D-0.25%5Ctimes%20%5Cfrac%7B3%7D%7B3-3q%7D=0%5C%5C%5B6pt%5D%0A%5C%5C%0Aq&amp;=0.75%0A%5Cend%7Balign*%7D">
<p>Here we have a world where maximising the time-average growth rate is the optimal solution. In this case, it is achieved via probability matching.</p>
<p>There is one feature of this scenario that might seem off. Probability matching maximises the growth rate for the species. But which individuals are heading off to the plateau where 75% of the time they are going to be fried? If this an altruistic act for the benefit of the species? Why not head down to the cool valley where they, as an individual, is more likely to survive?</p>
<p>The answer was provided by <span class="citation" data-cites="grafen1999">Grafen (1999)</span>. Suppose we have a large population of size <img src="https://latex.codecogs.com/png.latex?N">. If an agent heads to the valley, the expected fraction of the population comprising their offspring (<img src="https://latex.codecogs.com/png.latex?%5Cpi">) will be:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cpi(%5Ctext%7Bvalley%7D)%5Capprox%5Cfrac%7B0.75%7D%7BqN%7D=%5Cfrac%7B1%7D%7BN%7D%0A"></p>
<p>If they stay to fry on the plateau, their offspring will comprise a similar fraction of the smaller remaining population:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cpi(%5Ctext%7Bplateau%7D)%5Capprox%5Cfrac%7B0.25%7D%7B(1-q)N%7D=%5Cfrac%7B1%7D%7BN%7D%0A"></p>
<p>Fitness is a relative measure. At equilibrium <img src="https://latex.codecogs.com/png.latex?q">, each option delivers the same fitness.</p>
</section>
<section id="idiosyncratic-versus-aggregate-risk" class="level3">
<h3 class="anchored" data-anchor-id="idiosyncratic-versus-aggregate-risk">Idiosyncratic versus aggregate risk</h3>
<p>I have created two hypothetical worlds, one making the case for maximising expected value despite being in a multiplicative world, and another where maximising the time-average growth rate is the optimal strategy. In both cases, the optimal strategy relies on the gene’s eye view. The variation comes from the probability structure of the environment.</p>
<p>I am hardly the first to propose this. I’m drawing on a rich history of research into the evolution of geometric growth rate maximisation in the biological literature. This in turn has been used by economic researchers such as <span class="citation" data-cites="robson2011">Robson and Samuelson (2011)</span> in the analysis of the evolution of preferences.</p>
<p>But, I like to think that this ergodicity economics exercise provides a nice opportunity to tie multiple threads together to provide a different perspective.</p>
<p>What’s next? I’ve been building a set of simulations examining mixed environments. What if the probabilistic structure of the environment is a mix of multiplicative and additive bets? You could think of the additive phase of the experiment I described earlier as comprising an few additive gambles in a multiplicative world. What if the environment switches between additive and multiplicative?</p>
<p>There isn’t a simple closed form solution to this problem. If you have a mix of additive and multiplicative bets, or even a non-constant multiplicative growth rate, an “ergodic observable” cannot easily be created. At present, it is best examined via simulation.</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-adamou2021" class="csl-entry">
Adamou, A., Berman, Y., Mavroyiannis, D., and Peters, O. (2021). Microfoundations of discounting. <em>Decision Analysis</em>, <em>18</em>(4), 257–272. <a href="https://doi.org/10.1287/deca.2021.0436">https://doi.org/10.1287/deca.2021.0436</a>
</div>
<div id="ref-brennan2011" class="csl-entry">
Brennan, T. J., and Lo, A. W. (2011). The origin of behavior. <em>The Quarterly Journal of Finance</em>, <em>01</em>(01), 55–108. <a href="https://doi.org/10.1142/S201013921100002X">https://doi.org/10.1142/S201013921100002X</a>
</div>
<div id="ref-cooper1982" class="csl-entry">
Cooper, W. S., and Kaplan, R. H. (1982). Adaptive <span>“</span>coin-flipping<span>”</span>: A decision-theoretic examination of natural selection for random individual variation. <em>Journal of Theoretical Biology</em>, <em>94</em>(1), 135–151. <a href="https://doi.org/10.1016/0022-5193(82)90336-8">https://doi.org/10.1016/0022-5193(82)90336-8</a>
</div>
<div id="ref-doctor2020" class="csl-entry">
Doctor, J. N., Wakker, P. P., and Wang, T. V. (2020). Economists<span>’</span> views on the ergodicity problem. <em>Nature Physics</em>, <em>16</em>(12), 1168–1168. <a href="https://doi.org/10.1038/s41567-020-01106-x">https://doi.org/10.1038/s41567-020-01106-x</a>
</div>
<div id="ref-ford2023" class="csl-entry">
Ford, M. C., and Kay, J. A. (2023). The Limitations of Growth- Optimal Approaches to Decision Making Under Uncertainty. <em>Econ Journal Watch</em>, <em>20</em>(2), 314–334. <a href="https://econjwatch.org/articles/the-limitations-of-growth-optimal-approaches-to-decision-making">https://econjwatch.org/articles/the-limitations-of-growth-optimal-approaches-to-decision-making</a>
</div>
<div id="ref-grafen1999" class="csl-entry">
Grafen, A. (1999). Formal Darwinism, the individual<span></span>as<span></span>maximizing<span></span>agent analogy and bet<span></span>hedging. <em>Proceedings of the Royal Society of London. Series B: Biological Sciences</em>, <em>266</em>(1421), 799–803. <a href="https://doi.org/10.1098/rspb.1999.0708">https://doi.org/10.1098/rspb.1999.0708</a>
</div>
<div id="ref-meder2021" class="csl-entry">
Meder, D., Rabe, F., Morville, T., Madsen, K. H., Koudahl, M. T., … Hulme, O. J. (2021). Ergodicity-breaking reveals time optimal decision making in humans. <em>PLoS Computational Biology</em>, <em>17</em>(9), e1009217. <a href="https://doi.org/10.1371/journal.pcbi.1009217">https://doi.org/10.1371/journal.pcbi.1009217</a>
</div>
<div id="ref-peters2019" class="csl-entry">
Peters, O. (2019). The ergodicity problem in economics. <em>Nature Physics</em>, <em>15</em>(12), 1216–1221. <a href="https://doi.org/10.1038/s41567-019-0732-0">https://doi.org/10.1038/s41567-019-0732-0</a>
</div>
<div id="ref-peters2023" class="csl-entry">
Peters, O. (2023). Insurance as an ergodicity problem. <em>Annals of Actuarial Science</em>, <em>17</em>(2), 215–218. <a href="https://doi.org/10.1017/S1748499523000131">https://doi.org/10.1017/S1748499523000131</a>
</div>
<div id="ref-peters2022" class="csl-entry">
Peters, O., and Adamou, A. (2022). The ergodicity solution of the cooperation puzzle. <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, <em>380</em>(2227), 20200425. <a href="https://doi.org/10.1098/rsta.2020.0425">https://doi.org/10.1098/rsta.2020.0425</a>
</div>
<div id="ref-robson2011" class="csl-entry">
Robson, A. J., and Samuelson, L. (2011). <em>The evolutionary foundations of preferences*</em> (J. Benhabib, A. Bisin, and M. O. Jackson, Eds.; Vol. 1, pp. 221–310). North-Holland. <a href="https://doi.org/10.1016/B978-0-444-53187-2.00007-3">https://doi.org/10.1016/B978-0-444-53187-2.00007-3</a>
</div>
<div id="ref-skjold" class="csl-entry">
Skjold, B., Steinkamp, S., Connaughton, C., Hulme, O. J., and Peters, O. (2024). <em>Ergodicity transformations predict human decision-making under risk</em>. <a href="https://doi.org/10.31219/osf.io/c96yd">https://doi.org/10.31219/osf.io/c96yd</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/the-psychological-and-genes-eye-view-of-ergodicity-economics.html</guid>
  <pubDate>Mon, 08 Jul 2024 10:00:00 GMT</pubDate>
</item>
<item>
  <title>Bryan Caplan’s The Case Against Education: A Review</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/bryan-caplans-the-case-against-education-a-review.html</link>
  <description><![CDATA[ 




<p>My first job out of university was as a lawyer. Later, when I switched to a non-legal role, I enrolled in a Master of Laws. I selected some subjects relevant to my new job and that might be useful if I wanted to return to a legal firm. Among other subjects, I studied constitutional theory, international trade law, human rights law and energy law.</p>
<p>How much do I know about those topics today? I can’t remember what we covered in constitutional theory, except for a recollection that we kicked off with some classic British philosophers. I know nothing about human rights law beyond the existence of a few international frameworks. I recall some of international trade law: the game-theoretic basis of the analysis and some basic principles, although I doubt I could write more than a page about what I learned. For energy law, I recall nothing.</p>
<p>Did I waste the time and money I spent on that Masters?</p>
<p>In his book <a href="https://en.wikipedia.org/wiki/The_Case_Against_Education">The Case Against Education</a>, Bryan Caplan argues that much (but not all) of the income premium for education is due to signalling. A Masters degree signals the intelligence and conscientiousness required to complete it. Even if the knowledge within is useless (and, in my case, largely forgotten), the fact I finished my studies signals I should be a productive worker.</p>
<p>That is how it played out. The signal from that Masters landed me a role in the Australian Treasury. They would not otherwise have looked at me with my underwhelming undergraduate record. When in Treasury, I worked on competition policy, an economic area with a legal tint. However, I used none of my legal knowledge. I also started post-graduate study in economics. I used none of that in Treasury either.</p>
<p>As occurred in my case, graduates get paid. In the United States in 2011, the average earnings of a high school graduate was $41,000. For a college graduate, it was $70,000. For someone with a Masters degree, it was $90,000.</p>
<p>The premium in Australia is less but still solid. My back on the envelope calculations using numbers from <a href="https://grattan.edu.au/wp-content/uploads/2018/04/904-dropping-out-the-benefits-and-costs-of-trying-university.pdf">this report</a> put the university graduate premium at about 40%.</p>
<p>Let’s take this large premium to education as given. Why do graduates get paid more?</p>
<p>Caplan compares three competing explanations, here spelled out in their pure form:</p>
<ul>
<li><p>Human capital: Education builds skills that are valued in the marketplace. Employers can observe this skill. We would expect to see an education premium that increases linearly with years of education.</p></li>
<li><p>Ability bias: Those who get more education have greater ability. Employers can observe ability, with the education premium simply a payment for that ability. If a person didn’t get more education, they’d still have the same skills and get paid more than those without those skills.</p></li>
<li><p>Signalling: Education signals underlying qualities that employers seek, such as cognitive ability and conscientiousness. Under pure signalling, high-ability people without education would not receive a premium for their ability as ability cannot be directly observed.</p></li>
</ul>
<p>Caplan argues that the share of signalling exceeds 50% and is “[p]robably more like 80%” of the education premium. However, he also makes the case that even if the share is closer to 30%, the education system still wastes a lot of money from a social perspective.</p>
<p>Below, I break down Caplan’s analysis of the human capital and signalling models. I’ll weave the ability model into my discussion of those two models, as both sides of the human capital-signalling debate concede that you need to control for ability bias. The presence of ability bias reduces the estimated return to education from human capital accumulation. Conversely, ability bias is required for the signalling model. If there it no ability bias, any difference in ability between people with different levels of education must come from the skills they learned during those studies. With no ability bias, there is no unobserved ability to signal.</p>
<section id="the-human-capital-model" class="level2">
<h2 class="anchored" data-anchor-id="the-human-capital-model">1. The human capital model</h2>
<p>Most economists subscribe to the human capital model. Education builds marketable skills. Those skills boost national productivity and income.</p>
<p>Caplan presents a series of stylised facts against the human capital model. These relate to student behaviour, the fading of education over time, and the lack of transfer of knowledge to the workplace.</p>
<section id="student-behaviour" class="level3">
<h3 class="anchored" data-anchor-id="student-behaviour">1.1. Student behaviour</h3>
<p>Students act as though they don’t care about building human capital. The best education in the world is free: no one would stop you if you rocked up to Princeton or Harvard and sat in class. But people don’t. Similarly, you can access free subject materials and lectures online from Harvard, MIT and many other top universities. Few ever use this.</p>
<p>Relatedly, most students try to consume as little education as they can. They want a good grade, but most will not do anything that does not lead to that grade (and many won’t even do that). They cheer when a class is cancelled.</p>
<p>Among my undergraduate students, that is what I see. I would cheer if more than a couple appeared mildly interested in the content. Most don’t even show up. In the undergraduate subject I taught last semester, 19 of 65 students attended the first (online) class. They didn’t have to wear their pants (none turned their cameras on). That is before they have any idea about my teaching style. I suspect many who turned up did so because some lecturers have attendance or participation requirements. As soon as they learned that I didn’t, they were gone.</p>
<p>Attendance does look different in the post-graduate subjects I teach. Many in that course want a change of job. And they don’t just want any job - they want a particular vocation where knowledge is typically tested through the application process and regularly on the job. But even that has limits. There aren’t many takers when I offer opportunities beyond the subjects themselves. Attendance is also stronger for the post-graduate students, but barely above 50%. It is perplexing under the human capital model as to why they would fork out over $50k for a degree in which they don’t engage.</p>
<p>Another student behaviour identified by Caplan is that students often seek the easiest classes. Easy markers are rewarded with student enrolment. While that reputation guides student choices inside the university, there is less visibility and harm to the signal externally. I suspect that is a driver of the decline in economics enrolment in Australia.</p>
<p>Then there is cheating. Under the human capital model, cheating doesn’t pay. If you don’t get the skills, you get found out. So why would students cheat?</p>
<p>One response to these behavioural observations is that these students are short-sighted (preferring to avoid short-term costs) or have incorrect beliefs about how their skills will be rewarded in the marketplace. Students make plenty of poor decisions. Just look at their choice of degrees. Perhaps their misjudgment of whether they should cheat or take an easy subject occurs because they are disciples of the signalling explanation for education. That said, I suspect these students are not making a grievous error about the role of signalling.</p>
</section>
<section id="from-the-classroom-to-the-workplace" class="level3">
<h3 class="anchored" data-anchor-id="from-the-classroom-to-the-workplace">1.2. From the classroom to the workplace</h3>
<p>When students are tested in an exam, they clearly have learned <em>something</em>.</p>
<p>But the important question for the human capital model is not how well they do in the exam. It is how they use that knowledge when they get out of the exam room and into the workplace.</p>
<p>And this is where the education enterprise becomes depressing.</p>
<p>First, knowledge fades. There is a well-known phenomenon called summer fade-out, where kids regress over the summer, forgetting material they had learned previously. (Since I first wrote that sentence, I have read that summer fade-out may be more of a problem of never learning in the first place <span class="citation" data-cites="workman2023">(Workman et al., 2023)</span>.) Similarly, I regularly teach students who appear to have no recollection of material taught in previous subjects despite passing the exam. They forgot.</p>
<p>There is substantial evidence that people don’t retain what they learned in school. Caplan refers to one study of algebra and geometry, where it was found that half the content was gone after five years (better than I expected), and nothing was left after 25. Similarly, tests of foreign language skills and civics show pitiful results for the time spent on these subjects at school.</p>
<p>The one buffer to forgetting is continual use: probably why most of us can continue to write, but recall nothing from our geometry lessons. This aligns with the idea of intermittent practice; repeated exposure over time is required to make a concept stick.</p>
<p>In discussing forgetting, Caplan draws an interesting contrast between failing and forgetting. Failing is penalised. Forgetting isn’t. As per my opening story about the lack of retention from the Master of Laws, there seems to be little penalty because I can’t recall the finer points of constitutional theory. A fail on my transcript would have been more consequential.</p>
<p>Even if we were to remember what we were taught, there is also the question of whether we would <em>use</em> what we are taught. Caplan uses the example of his field of economics, stating “I assure you that my profession makes near-zero effort to train our undergrads for the job market.” I share his scepticism about what is taught in economics. There are some useful skills: the stats and microeconomic frameworks among them. But when I worked in economic policy consulting and Treasury, I hardly used any of my economic education. Less than one per cent of economics students would pull out a macroeconomic or trade model in their later work. For me, that has changed now I’m working in academia. Learning the content of an economics degree is a great thing to learn if you need to teach the content of an economics degree.</p>
<p>More specifically, Caplan uses economics as a counterpoint to the wheat-chaff defence of the human capital model. This defence runs along the lines of: even if there is a lot of irrelevant content (chaff) in education, there is enough wheat to make it worthwhile. (As Caplan notes, this is no ringing endorsement.) Caplan’s response, however, is to observe that chaff pays. An economics degree pays almost as much as engineering, despite the chaff. Philosophy and religion degrees pay substantially, and the pay goes up for religion and philosophy graduates if they are mismatched (not working in a relevant field).</p>
<p>One common defence of education is that it teaches you how to think, even if specific knowledge is lost. You might not recall any geometry, but it helped build mental muscle that you can turn to the job at hand.</p>
<p>But this is where we come to the problem of transfer. Or, more particularly, the lack of evidence of transfer.</p>
<p>I like to think of transfer in a localised and general sense. The localised sense relates to what happens if I teach a concept and then ask for that concept to be used in a new context. The broader sense is that “mental muscle” sense, where my education equips me for the unrelated mental tasks in the broader world.</p>
<p>In both senses, the evidence is weak. When students are taught to answer a question and then immediately asked to answer a second question that can be solved with the same approach, they typically can’t answer the second. The degree of transfer goes down further with decreasing similarity, with time delay, with distractions (e.g.&nbsp;a problem between the two questions), if the second question is outside the classroom or if there are different teachers for the first and second questions. When you consider that the leap between school and the real world involves all of these hurdles, it’s hard to expect the direct application of learned concepts elsewhere.</p>
<p>But what of the broader sense of transfer, the building of critical thinking skills? Caplan discusses one interesting study where students in the first and fourth year of high school, college and graduate school were asked questions such as “Does violence on television significantly increase the likelihood of violence in real life?”. Their answers were then assessed for critical reasoning. Fourth-year high school students did better than those in the first year. However, there was no difference between first and fourth-year college students, and a minor difference between first and fourth-year graduate students. Education beyond high school barely shifts thinking skills.</p>
<p>Another study examined university students assessing the claim that students should “eat more nutritiously because the majority of students needing psychological counselling had poor dietary habits”. Despite many having six years of science in high school and college, plus advanced calculus, less than 1 per cent of students gave what was assessed as a “good scientific response”. Despite their years of education, college students are poor at applying their scientific and mathematical knowledge to outside problems.</p>
<p>Across the other studies Caplan examines, there is little promise outside of some examples with transfer of mathematical and statistical knowledge to other problems, although the tasks were generally softballs (e.g.&nbsp;asking a basic statistical sports question straight after a statistics course). There is some evidence of specific transfer if the testing is narrow enough relative to the study. Students that use a lot of statistics do get better at statistics. Humanities majors slightly improve at verbal reasoning. It’s a fairly uninspiring outcome for the effort invested.</p>
</section>
<section id="does-education-make-you-smarter" class="level3">
<h3 class="anchored" data-anchor-id="does-education-make-you-smarter">1.3. Does education make you smarter?</h3>
<p>If education under-delivers on both knowledge and transferable skills, what of a more general claim that it makes us smarter? Maybe the human capital built is raw processing power.</p>
<p>More years of education seems to boost IQ scores. However, Caplan is not convinced this gain is meaningful. School is effectively practice for IQ tests, directly teaching facts that are tested. In one study of Swedish men, time in school boosted synonym and technical comprehension subtests without raising spatial or logical subtest scores. Then there is fadeout. Caplan argues that most interventions that have been found to boost IQ see the gains disappear a few years later.</p>
<p>I’m not convinced by Caplan’s summary of the literature here. Here’s part of the abstract of a meta-analysis by Stuart Ritchie and Elliot Tucker-Drob <span class="citation" data-cites="ritchie2018">(2018)</span>:</p>
<blockquote class="blockquote">
<p>Across 142 effect sizes from 42 data sets involving over 600,000 participants, we found consistent evidence for beneficial effects of education on cognitive abilities of approximately 1 to 5 IQ points for an additional year of education. Moderator analyses indicated that the effects persisted across the life span and were present on all broad categories of cognitive ability studied. Education appears to be the most consistent, robust, and durable method yet to be identified for raising intelligence.</p>
</blockquote>
<p>This meta-analysis was published just before Caplan’s book, so might not have appeared in time, but it contests Caplan’s claims of fadeout and a narrow boost on those items that can be taught. The studies that made up the meta-analysis were available to Caplan, which raises question of how Caplan picked the studies. Why does he prefer some and not others?</p>
<p>I searched for whether Caplan later addressed Ritchie and Tucker-Drobs’s paper and found two times. The first was <a href="https://www.econlib.org/archives/2017/12/reply_to_noah_o.html">a response by Caplan</a> to Noah Smith. Smith tweeted Ritchie and Tucker-Drob’s finding with the comment “Bryan Caplan and the other education skeptics are going to need to revise their beliefs a bit, eh?”. Caplan states that the paper did lead him to update his view, “slightly”. Why only slightly? Because he had already accepted Stephen Ceci’s <span class="citation" data-cites="ceci1991">(1991)</span> findings of a 1 to 3 point gain per year of education. Caplan did quote Ceci in the book, although he did not directly reference that 1 to 3 point gain. Caplan’s main use of Ceci’s article in the book was to support of the idea that school teaches to the IQ test. Caplan repeats Ceci’s point about teaching to the test in his response to Smith.</p>
<p>Caplan was also asked about the paper by <a href="https://80000hours.org/podcast/episodes/bryan-caplan-case-for-and-against-education/">Robert Wiblin on the 80,000 hours podcast</a>. Caplan again notes that its only a slight update on his previous position, before repeating his points on school effectively being practice for IQ tests and fade-out. Between these two responses, it seems he has taken on the higher IQ estimate, but not Ritchie and Tucker Drob’s findings that the increase is across all components of IQ and persists across the lifespan.</p>
<p>I have to admit that I am sceptical about the upper bounds of Ritchie and Tucker-Drobs’s estimates. Even if the higher estimates were robust, I doubt they would hold through the entire educational experience and at the margins where most interventions are now targeted, such as increasing post-secondary education. If these effects persisted year by year, I would expect to see larger differences in IQ across cohorts with different levels of education than we do. Further, if education boosts IQ so markedly, why doesn’t it appear in other areas? For example, the lack of gain in critical thinking between first- and fourth-year college mentioned above does not align with a substantive IQ gain.</p>
<p>Part of this may be due to diminishing gains once we get beyond high school into graduate and post-graduate study. Ritchie and Tucker-Drobs’s evidence is largely drawn from high-school data, particularly those studies that indicate larger gains. Ritchie and Tucker-Drobs examined 28 studies. Of these, 7 involved controls for prior intelligence, 11 involved policy changes and 10 used school-age cutoff data.</p>
<p>The school-age cutoff data leads to estimates of around 5 IQ points, but by the nature of the device - variation in when people are born in the year relative to the age that they can leave school - means that these effects are at the high-school level.</p>
<p>The policy change studies, which generated a mean estimate around 2 IQ points, only had one study involving additional years of education beyond high school (<span class="citation" data-cites="kamhöfer2019">Kamhöfer et al. (2019)</span>, which was an unpublished working paper at the time of Ritchie and Tucker-Drob’s article).</p>
<p>The studies control for prior intelligence by measuring intelligence at two points in time generated a mean gain of 2 points per year of education on composite tests and 1 point on tests of fluid intelligence. These studies cover all years of education from the time of the first test, so they typically contain early high school years mixed in with any university education. However, there were three studies where the first intelligence tests were conducted at an age where their education would primarily be university education - the subjects were 18, 18 and 20 at the time of the first IQ test. These found gains of around 1 point per year. (I find the simpler study design of two IQ tests more compelling.)</p>
<p>Caplan’s final rejoinder to the idea that school increases intelligence is that the link between IQ and income is weak. Each IQ point leads to around a one percent increase in income. Even if each year of school raised IQ by, say, 3 IQ points, most of the education premium would remain unexplained.</p>
<p>Caplan’s source for this claim of limited income gain from IQ is drawn from Jones and Schneider <span class="citation" data-cites="jones2010">(2010)</span>. Jones and Schneider have a larger point, however. Despite the small individual gain from higher IQ, the gain to society is massive. An earlier paper by Jones and Schneider <span class="citation" data-cites="jones2006">(2006)</span> estimated a 6.1% increase in living standards from an increase of IQ by one point. Under this measure, the IQ gain from education seems to be a fantastic deal for society. (Caplan does cite Jones’s book “<a href="https://www.sup.org/books/title/?id=23082">The Hive Mind: How Your Nations IQ Matters So Much More Than Your Own</a>” about the large gains to a nation through higher IQ, but references it in support of a different point.)</p>
</section>
<section id="human-capital-and-ability-bias" class="level3">
<h3 class="anchored" data-anchor-id="human-capital-and-ability-bias">1.4. Human capital and ability bias</h3>
<p>Under the human capital model, employers pay for skills. Those skills are a combination of ability and education. Therefore, any measure of the effect of education on income needs to account for the differences in ability.</p>
<p>How might you control for ability, ensuring your estimate of the effect of education is not tainted by “ability bias”?</p>
<p>One way would be to get measures of ability, such as IQ, and measure the effect of education holding ability constant. Controlling for IQ shrinks the size of the education premium. High-quality IQ tests reduce it by 20 to 30 per cent. Measures that control for math, reading, vocabulary and the kitchen sink can get the education premium down by around 50 per cent.</p>
<p>But there is a problem with this approach. If education increases ability, we have reverse causation and should attribute more of the premium to education. Caplan argues, however, that this isn’t a concern. Studies that measure IQ before school completion and studies that measure IQ after school completion find similar levels of cognitive ability bias. If education was materially affecting ability, we would expect more ability bias in the studies with measurements after school completion.</p>
<p>Another approach to account for ability bias would be to find quasi-experimental situations from which causation might be inferred. For example, if a pair of identical twins receive different education, and you assume equal ability, is there a difference in outcome? If compulsory attendance laws are changed, what happens to the income of students who are now forced to stay in school?</p>
<p>This body of research results in what Caplan calls the “Card Consensus”. The Card Consensus comes from two reviews of the literature by David Card <span class="citation" data-cites="card1999 card2001">(1999, 2001)</span>, in which Card argues that ability bias is in the order of 10 per cent if it exists at all. It is the educational investment itself that drives the impressive returns to education. Caplan states that most elite labour economists now embrace this perspective.</p>
<p>How does Card reconcile the studies he reviews with those Caplan cites? Card’s approach is somewhat dismissive. As Caplan notes in a footnote, Card’s 1999 article states:</p>
<blockquote class="blockquote">
<p>One strand of literature that I do not consider are studies of the return to schooling that attempt to control for ability using observed test scores.</p>
</blockquote>
<p>I suspect Card’s dismissiveness matches that of much of the economics profession, who have a strong preference for the types of natural experiments that Card relies on. Assuming the assumptions underlying those causal methodologies hold, they should be less vulnerable to confounding.</p>
<p>Caplan’s response is to question the robustness of the studies on which Card’s review is built. For example, Caplan cites research noting that the twin who receives more education is typically smarter; twins are not completely identical. However, accounting for differences in twin ability only shaves about 15% of the education premium <span class="citation" data-cites="sandewall2014">(Sandewall et al., 2014)</span>. Similarly, studies capitalising on time of birth or changes in the ability of students to leave school are vulnerable to the patterns in birth by time of year <span class="citation" data-cites="bound1995">(Bound et al., 1995)</span> and a breach of the assumption that there are common trends across states <span class="citation" data-cites="stephensjr.2014">(Stephens Jr. and Yang, 2014)</span>. Caplan also footnotes a comment by <span class="citation" data-cites="stephensjr.2014">Stephens Jr. and Yang (2014)</span> noting “schooling law changes outside of the United States finds either small or zero returns”.</p>
<p>Given the shakiness of the quasi-experimental research, Caplan points to what he feels is the stronger body of evidence. However, Caplan doesn’t deal with the major critique of his preferred data: Caplan’s data on ability bias is observational. We have correlation, not evidence of causation. Caplan’s argument is logical but lacks an instrument to pull causation out. That is what Card’s body of research attempts to do.</p>
<p>However, I lean toward Caplan’s preferred evidence. Economists are right that to isolate causation, you need an appropriate methodology. But those methodologies have assumptions that, on reflection (and as noted above), often don’t hold. Then you throw in a good dose of publication bias - for example, this recent working paper by <span class="citation" data-cites="clark2024">(Clark and Nielsen, 2024)</span> suggests substantial publication bias in the literature on the returns to education - and we’re likely seeing inflated estimates of the return. I have to admit that it would take stronger evidence than that presented by Card and friends to dislodge me from my view that ability bias is real and that the returns to education measured in those experiments are untainted.</p>
<p>Caplan does have one final thread to his critique of the Card Consensus, which is to consider what a lack of ability bias means: if you measure the ability of those deciding to further their education and those who don’t, you won’t see any difference in ability. Of the educated and less educated people you know, were they (on average) of equal ability when they made their education decisions? It doesn’t match experience.<sup>1</sup></p>
<p>Caplan quotes a paragraph from Joshua Angrist and Jörn-Steffen Pischke’s book <a href="LINK">Master Metrics: The Path from Cause to Effect</a>, which reads:</p>
<blockquote class="blockquote">
<p>Some people cut their schooling short so as to pursue more immediately lucrative activities. Sir Mick Jagger abandoned his pursuit of a degree at the London School of Economics in 1963 to play with an outfit known as the Rolling Stones. . . . No less impressive, Swedish épée fencer Johan Harmenberg left MIT after 2 years of study in 1979, winning a gold medal in the 1980 Moscow Olympics, instead of earning an MIT diploma. Harmenberg went on to become a biotech executive and successful researcher. These examples illustrate how people with high ability—musical, athletic, entrepreneurial, or otherwise—may be economically successful without the benefit of an education. This suggests that . . . ability bias, can be negative as easily as positive.</p>
</blockquote>
<p>Angrist and Pischke scrape together a few outliers. Do you believe the claim of ability bias being as likely to be negative as positive? I don’t.</p>
</section>
</section>
<section id="the-signalling-model" class="level2">
<h2 class="anchored" data-anchor-id="the-signalling-model">2. The signalling model</h2>
<p>Having laid out the case against the human capital model, what is the case for the signalling model?</p>
<p>Much of the case comes from how signalling explains many of the mysteries identified in the previous section. Useless subjects? They demonstrate ability. Forgotten what you learnt? Again, the fact you could learn the master once do it indicates ability. Why hasn’t online education hasn’t taken off? Because people want credentials, not skills. Online education doesn’t signal the conformity and persistence required for a college degree.</p>
<p>I find those arguments compelling at face value, although Caplan provides several others in support. These include the skeepskin effect, malemployment and the gap between the personal and national education premium.</p>
<section id="the-sheepskin-effect" class="level3">
<h3 class="anchored" data-anchor-id="the-sheepskin-effect">2.1 The sheepskin effect</h3>
<p>The payoff for each year of education is not equal. The twelfth grade pays more than grades 9, 10 and 11 combined. The final year of college pays more than twice as much as the first three year combined. Graduation signals conformity and that you takes norms seriously. As a result, you get a special bonus called the “sheepskin effect” (diplomas used to be printed on sheepskin) for finishing. Students know this. Students tend not to quit after year 11 or their second last year of college. When close to the finish line, they crawl over it.</p>
<p>Ability bias rears its head here as a potential explanation for the sheepskin effect. What if graduates have better prospects than dropouts? Caplan argues that, correcting for ability bias, the sheepskin effect remains. Controlling for ability bias reduce the payoff for both years of education and the graduation diploma, leaving the <em>relative</em> premium for that sheepskin largely unchanged.</p>
</section>
<section id="malemployment" class="level3">
<h3 class="anchored" data-anchor-id="malemployment">2.2. Malemployment</h3>
<p>Many workers are overqualified. Depending on the measurement technique, between 10 and 35% of workers have more education than required for their job. And “malemployment” is increasing. The level of education required to get a job has risen faster than the amount needed to do it.</p>
<p>Malemployment could occur under both the human capital model and signalling model. In the human capital model, malemployment occurs when people fail to acquire skills in school. In contrast, the signalling model points to an arms race in qualifications, where you need more education than your competitor. Being a high-school graduate when everyone else dropped out signals ability and perseverance. Graduating from high school when almost everyone completes a bachelor’s degree suggests you are a poor student.</p>
<p>How do we distinguish between the two? Caplan suggests the answer lies in whether the labour market rewards education an employee does not use. This would only occur under the signalling model. And the evidence seems to point in this direction. Bartenders with degrees earn more. College graduates out-earn high school graduates, regardless of their occupation and even for jobs that don’t require school.</p>
</section>
<section id="the-personal-education-premium-versus-the-national" class="level3">
<h3 class="anchored" data-anchor-id="the-personal-education-premium-versus-the-national">2.3 The personal education premium versus the national</h3>
<p>Under the human capital model, education is good news for both the individual and the nation. Education increases both the worker’s income and the nation’s productivity.</p>
<p>The signalling model also suggests education is good for the individual, making you appear more productive. But as their productivity doesn’t go up, we see nothing at the national level. Productivity stays the same.</p>
<p>What does the data show? Caplan compares estimates of the effect of a year of education on individual income with estimates of a year of education on national income. The comparison is stark: a year of personal education increases income by around 8 to 12%, while it increases national income by only 1 to 3%. Crudely, that puts the human capital-signalling mix at around 20:80.</p>
<p>That signalling arms races are socially inefficient was the centrepiece of Robert Frank’s book <a href="https://www.jasoncollins.blog/posts/franks-the-darwin-economy">The Darwin Economy</a>. If the order remains the same but everyone invests more in the signal, we’ve burnt resources for no gain. Caplan digs into this in much more detail in a chapter on the social returns to education I note below.</p>
</section>
</section>
<section id="who-does-education-pay-for" class="level2">
<h2 class="anchored" data-anchor-id="who-does-education-pay-for">3. Who does education pay for?</h2>
<section id="the-individual-return-to-education" class="level3">
<h3 class="anchored" data-anchor-id="the-individual-return-to-education">3.1 The individual return to education</h3>
<p>In 1973 Michael Spence published one of the papers that led to his 2001 Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel. The paper, <em>Job Market Signalling</em> <span class="citation" data-cites="spence1973">(1973)</span>, provided a simple model of how employers could use education to identify high-productivity workers. In effect, he developed the formal signalling model.</p>
<p>The key element of the model is that the cost of obtaining education differs between low- and high-productivity workers. For example, a low-intelligence worker might find the lectures hard. A low-conscientiousness worker might not have the persistence to study and stick through the full degree.</p>
<p>In biology, this idea become known as the handicap principle <span class="citation" data-cites="zahavi1975">(Zahavi, 1975)</span>. To be an honest signal, it needs to impose a “handicap” beyond what someone who does not have the trait can bear.</p>
<p>The consequence of this differential cost and ability to incur the handicap is that education may not be a good deal for everyone. Education must impose a cost that some can’t bear. Some students will benefit from more education, but some don’t.</p>
<p>Caplan spends most of the chapter on the selfish return to education calculating the benefits to education for what he calls excellent, good, fair and poor students. An excellent student is the typical Masters holder. The good student is the typical college graduate who does not continue to further education. A fair student graduates high school but does not attempt college. And the poor student is the typical high-school dropout.</p>
<p>Through a range of calculations, Caplan ultimately concludes the high-school graduation is a great deal for all students. College, however, is only a good deal for good and excellent students. Why doesn’t college pay for poor or fair students? Largely, they don’t complete. They lose years of wage earning, incur student debt and don’t even get the sheepskin to show for it. Finally, Masters degrees are OK for excellent students and a waste for others.</p>
<p>There are plenty of factors that swing these broad calculations. Foer example, studying a subject with a high return (e.g.&nbsp;engineering, economics) makes it a better deal. Lower tuition is helpful (going to a more expensive college doesn’t pay).</p>
</section>
<section id="the-social-return-to-education" class="level3">
<h3 class="anchored" data-anchor-id="the-social-return-to-education">3.2. The social return to education</h3>
<p>As hinted in the comparison of individual versus national returns to education, the social return to education appears weak. Caplan calculates that it is OK for high school, pathetically low for undergraduate study and negative for Masters. This return also varies across students; boosting the education of poor students is even worse. Even under low estimates of the share of signalling in the education premium, it is hard to resurrect the case for Masters degrees.</p>
<p>Caplan looks hard for the social benefits, looking beyond the economic measures considered in analyses of national income. He looks at workforce participation and tax payments. A material gain could come from a reduction in crime, with even minor crime reductions having large social benefit. These broader benefit don’t change the case.</p>
<p>We could return here to the question of a national IQ boost noted above. Caplan does not revisit the potential boost to IQ in this chapter, but to the extent the boost in IQ is real, we should see it in the various factors he analyses, such as higher national income and lower crime.</p>
</section>
</section>
<section id="education-good-for-the-soul" class="level2">
<h2 class="anchored" data-anchor-id="education-good-for-the-soul">4. Education good for the soul</h2>
<p>When I question whether some students should be in university, one of the most common responses I hear is that education is good for the soul. It broadens horizons. Caplan has heard those same claims. For example, through school we are exposed to high culture and ideas. We read books and are exposed to political questions we won’t likely come across elsewhere. This exposure has the benefit of demonstrating the richness of the world for people who otherwise exhibit little curiosity.</p>
<p>There are two problems with this. The first is that it doesn’t work. We’re mandating culture for those who aren’t interested. During high school (a regional Western Australian school), I read Shakespeare, Pinter, Beckett, Camus and Bronte. My modal estimate of how many of my cohort of 150 students would have read any of those since graduating is three (one being me). If I’m incorrect, I won’t be off by more than a couple of people. I would guess most wouldn’t even recall that they read Camus, Pinter and Beckett. Contrast that with pop culture, barely featured in education.</p>
<p>On ideas, there is little evidence that education changes political views (despite educators leaning left). Caplan also looks at religion and voting and finds little evidence that education changes us.</p>
<p>The second problem is that the “broader horizon” is actually quite narrow. The music, art and poetry comes from ossified lists. Attempts to “modernise” just bring in a new kind of narrowness.</p>
<p>Caplan clarifies that he is not cynical not about education, but about students (the Philistines) and the teachers (the majority uninspiring and not even excited themselves about what they are teaching). The alternative is to genuinely broaden their horizons. How about exposing people to plausible careers? Expose math students to insurance. Expose boys to nursing. Expose them to things that might actually feature in their future.</p>
</section>
<section id="caplans-policy-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="caplans-policy-recommendations">5. Caplan’s policy recommendations</h2>
<p>Caplan’s first-best policy is the separation of education from government. He is a libertarian.</p>
<p>Moving to the feasible, his second-best policy is a combination of vocational education and “less”.</p>
<section id="vocational-education" class="level3">
<h3 class="anchored" data-anchor-id="vocational-education">Vocational education</h3>
<p>How do people get good at their jobs? By doing their jobs! This argument could be applied more broadly than vocational education. Ask any white collar worker where they learnt their skills. I learnt how to be a lawyer in a law firm.</p>
<p>Why is vocational education so effective? Because you’re learning the skills you will use, and rather than learning by listening, you are learning by doing.</p>
<p>A critique of vocational education is that it is narrow and targeted to one career. But, traditional education is narrow and targeted toward to no career. As Caplan notes, education often teaches little about the world in which we live.</p>
<p>So how does vocational education stack up financially? Caplan crunches some numbers to show how vocational students stack up against comparable students who didn’t study a trade. The outcome: more pay, more likely to graduate, less unemployment and even less crime. Employment outcomes after age 50 aren’t quite as good, but the 30-years before that more than makes up for it.</p>
<p>For an Australian context, here’s some <a href="https://andrewnorton.net.au/2023/08/21/the-accord-equity-target-that-cannot-and-perhaps-should-not-be-achieved/">analysis by Andrew Norton</a>: the top quartile of people with a Certifcate IV (a post-graduate trade degree) earn more than the median Bachelor degree graduate over their lifetime. It’s hard to know to what extent we’re getting insight into a counterfactual about choosing vocational versus university education, but I suspect there are many Bachelors students who would have been better off in a trade.</p>
<p><a href="img/male-qual-comparison-1.jpg.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://www.jasoncollins.blog/posts/img/male-qual-comparison-1.jpg.webp" class="img-fluid"></a></p>
<p>Caplan’s final argument on vocational education is to let kids work earlier. As soon as my kids are old enough, I’m sending them down to the local McDonald’s or some other employer to start earning some money. There are skills such as turning up (something most students today don’t learn) on time (something students still struggle with on assignment submissions) well worth learning.</p>
</section>
<section id="less" class="level3">
<h3 class="anchored" data-anchor-id="less">Less</h3>
<p>When people get into a signalling competition, they waste resources. They invest more in the signal, yet the ranking and outcome don’t change.</p>
<p>As a result, in <a href="https://www.jasoncollins.blog/posts/franks-the-darwin-economy">The Darwin Economy</a>, Robert Frank argues for constraints to signalling contests. If people spend too much on conspicuous consumption and positional goods, apply a progressive consumption tax. Only 20% of people can be in the top 20%.</p>
<p>Caplan applies a related argument, arguing for education austerity (the opposite of the near-universal call for more educational funding). Stop subsidising the arms race with taxpayer money. Only 20% can be among the 20% most educated.</p>
<p>I spent some time thinking out what “less” could look like in my (Australian) context. First, provide zero support for post-graduate study. If universities want to use post-graduate courses as a cash cow, let them go for it, but we could remove tax deductions for domestic students. I would also be tempted to reshape the current student loan scheme for these post-graduate courses to require either faster repayment or a market-based interest rate.</p>
<p>Across my post-graduate study, I likely paid in the order of $100,000AUD (about $65,000USD) and got around $35,000 back in tax deductions. I then paid the remainder back through inflation-indexed loans. Studying increased my near-term income and smoothed it over time, as the tax deductions were immediate and the loan repayments were in the future. Absent the tax deductions, I wouldn’t have completed the Masters of Law, but I probably would have still done the economics (assuming my path hadn’t diverged). My study probably hasn’t boosted wages, given my choices, nor government tax receipts, but it has undoubtedly given me more mobility and put me closer to where I want to be.</p>
<p>Less would also involve killing off targets for getting more students to university (the opposite of current trends), support more vocational training and have more of that vocational training happening at high school level. Absent continued growth in the number of international students, the university sector would shrink. That’s not a bad thing. If we simply up everyone’s signal without a commensurate increase in productivity, we’re not helping those we push into tertiary education.</p>
<p>As I’ve implied above, I suspect the balance between the human capital and signalling models changes as we move through the levels of education. I believe Caplan’s arguments are more robust in the university sector and he doesn’t refer to much evidence for years of high school education below those where you can drop out. Students learn some reading, writing and math (although to somewhat disappointing levels), so I’d be reluctant to start slashing too much there. Still, there seems scope to get rid of some of the fluff and let kids play around.</p>
<p>Beyond that, I could be convinced to do more. But what I’ve proposed is already beyond the bounds of current feasibility. We could tweak toward less, see what happens, then tweak some more.</p>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-bound1995" class="csl-entry">
Bound, J., Jaeger, D. A., and Baker, R. M. (1995). Problems with instrumental variables estimation when the correlation between the instruments and the endogenous explanatory variable is weak. <em>Journal of the American Statistical Association</em>, <em>90</em>(430), 443–450. <a href="https://doi.org/10.1080/01621459.1995.10476536">https://doi.org/10.1080/01621459.1995.10476536</a>
</div>
<div id="ref-card1999" class="csl-entry">
Card, D. (1999). <em>Chapter 30 - the causal effect of education on earnings</em> (O. C. Ashenfelter and D. Card, Eds.; Vol. 3, pp. 1801–1863). Elsevier. <a href="https://www.sciencedirect.com/science/article/pii/S1573446399030114">https://www.sciencedirect.com/science/article/pii/S1573446399030114</a>
</div>
<div id="ref-card2001" class="csl-entry">
Card, D. (2001). Estimating the return to schooling: Progress on some persistent econometric problems. <em>Econometrica</em>, <em>69</em>(5), 1127–1160. <a href="https://www.jstor.org/stable/2692217">https://www.jstor.org/stable/2692217</a>
</div>
<div id="ref-ceci1991" class="csl-entry">
Ceci, S. J. (1991). How much does schooling influence general intelligence and its cognitive components? A reassessment of the evidence. <em>Developmental Psychology</em>, <em>27</em>(5), 703–722. <a href="https://doi.org/10.1037/0012-1649.27.5.703">https://doi.org/10.1037/0012-1649.27.5.703</a>
</div>
<div id="ref-clark2024" class="csl-entry">
Clark, G., and Nielsen, C. A. A. (2024). The Returns to Education: A Meta-study. <em>Working Papers</em>. <a href="https://ideas.repec.org//p/hes/wpaper/0249.html">https://ideas.repec.org//p/hes/wpaper/0249.html</a>
</div>
<div id="ref-jones2006" class="csl-entry">
Jones, G., and Schneider, W. (2006). Intelligence, human capital, and economic growth: A bayesian averaging of classical estimates (BACE) approach: Journal of economic growth. <em>Journal of Economic Growth</em>, <em>11</em>(1), 71–93. <a href="https://doi.org/10.1007/s10887-006-7407-2">https://doi.org/10.1007/s10887-006-7407-2</a>
</div>
<div id="ref-jones2010" class="csl-entry">
Jones, G., and Schneider, W. J. (2010). Iq in the production function: Evidence from immigrant earnings: Economic inquiry. <em>Economic Inquiry</em>, <em>48</em>(3), 743–755. <a href="https://doi.org/10.1111/j.1465-7295.2008.00206.x">https://doi.org/10.1111/j.1465-7295.2008.00206.x</a>
</div>
<div id="ref-kamhöfer2019" class="csl-entry">
Kamhöfer, D. A., Schmitz, H., and Westphal, M. (2019). Heterogeneity in marginal non-monetary returns to higher education. <em>Journal of the European Economic Association</em>, <em>17</em>(1), 205–244. <a href="https://doi.org/10.1093/jeea/jvx058">https://doi.org/10.1093/jeea/jvx058</a>
</div>
<div id="ref-ritchie2018" class="csl-entry">
Ritchie, S. J., and Tucker-Drob, E. M. (2018). How Much Does Education Improve Intelligence? A Meta-Analysis. <em>Psychological Science</em>, <em>29</em>(8), 1358–1369. <a href="https://doi.org/10.1177/0956797618774253">https://doi.org/10.1177/0956797618774253</a>
</div>
<div id="ref-sandewall2014" class="csl-entry">
Sandewall, Ö., Cesarini, D., and Johannesson, M. (2014). The co-twin methodology and returns to schooling <span></span> testing a critical assumption. <em>Labour Economics</em>, <em>26</em>, 1–10. <a href="https://doi.org/10.1016/j.labeco.2013.10.002">https://doi.org/10.1016/j.labeco.2013.10.002</a>
</div>
<div id="ref-spence1973" class="csl-entry">
Spence, M. (1973). Job market signaling: Quarterly journal of economics. <em>Quarterly Journal of Economics</em>, <em>87</em>(3), 355–374. <a href="https://doi.org/10.2307/1882010">https://doi.org/10.2307/1882010</a>
</div>
<div id="ref-stephensjr.2014" class="csl-entry">
Stephens Jr., M., and Yang, D.-Y. (2014). Compulsory education and the benefits of schooling<span></span>: American economic review. <em>American Economic Review</em>, <em>104</em>(6), 1777–1792. <a href="https://doi.org/10.1257/aer.104.6.1777">https://doi.org/10.1257/aer.104.6.1777</a>
</div>
<div id="ref-workman2023" class="csl-entry">
Workman, J., Hippel, P. T. von, and Merry, J. (2023). Findings on summer learning loss often fail to replicate, even in recent data. <em>Sociological Science</em>, <em>10</em>, 251–285. <a href="https://doi.org/10.15195/v10.a8">https://doi.org/10.15195/v10.a8</a>
</div>
<div id="ref-zahavi1975" class="csl-entry">
Zahavi, A. (1975). Mate selection<span></span>a selection for a handicap. <em>Journal of Theoretical Biology</em>, <em>53</em>(1), 205–214. <a href="https://doi.org/10.1016/0022-5193(75)90111-3">https://doi.org/10.1016/0022-5193(75)90111-3</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I have heard Card described as someone smart enough to construct a strong case for whatever position he wants to hold. His <a href="https://projects.iq.harvard.edu/files/diverse-education/files/legal_-_card_report_revised_filing.pdf">brief to the Supreme Court</a> arguing that affirmative action involves no discrimination is a case in point.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/bryan-caplans-the-case-against-education-a-review.html</guid>
  <pubDate>Fri, 19 Apr 2024 02:00:00 GMT</pubDate>
</item>
<item>
  <title>The preregistration halo</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/the-preregistration-halo.html</link>
  <description><![CDATA[ 




<p>When we analyse experimental data, we have many choices. What observations do we exclude? What variables do we compare? What statistical tests do we use? And so on. These choices lead us into what is often called the <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf">garden of forking paths</a>.</p>
<p>The problem is that some paths lead to a “significant” result. Hurrah! Publication on the way. Others lead nowhere. So when we read a published paper, you might ask: did they choose their path because it led to a significant result?</p>
<p>One solution to this problem is to <a href="https://en.wikipedia.org/wiki/Preregistration_(science)">preregister</a> the analysis. Specify the analysis before seeing the data.</p>
<p>If preregistration is made public, we can see all research on a topic. We won’t be limited to just the studies authors get published. Preregistration constrains the analysis by making it harder for authors to p-hack or hypothesise their way to a significant result. Or, at least, it makes it transparent that they have done so.</p>
<p>But, preregistration is no guarantee of good science. It doesn’t solve many of the real problems in science (<a href="https://worksinprogress.co/issue/biases-the-wrong-model/">for example</a>). Preregistration can’t rescue weak theory. Many preregistrations remain private. Other preregistrations are left to wither on the vine. Here’s a plot of the status of preregistrations submitted to the <a href="https://www.socialscienceregistry.org">American Economic Association’s RCT registry</a>. The data goes up to 1 January 2024.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(readr)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># load data file, which is a subset of the AEA registry to 1 January 2024, available from https://doi.org/10.7910/DVN/HPYPGH</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># code to create subset from the raw csv file as follows, although not executed as part of this document - raw file too large to maintain on website</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># trials &lt;- read_csv("trials.csv")</span></span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#remove columns not used in this analysis + RCT_ID</span></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># trials &lt;- trials %&gt;% </span></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  select(RCT_ID, "First registered on", "Intervention end date", "End date", Status)</span></span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#save as cvs named "trials-processed-jan-2024.csv"</span></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># write_csv(trials, "trials-subset-jan-2024.csv")</span></span>
<span id="cb1-17"></span>
<span id="cb1-18">trials <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_csv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data/trials-subset-jan-2024.csv"</span>)</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># set order for charts so completed is first, then abandoned, then other</span></span>
<span id="cb1-21">trials <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> trials <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb1-22">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rename</span>(</span>
<span id="cb1-23">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">intervention_end_date =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Intervention end date"</span>,</span>
<span id="cb1-24">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">first_registered_on =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"First registered on"</span>,</span>
<span id="cb1-25">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">end_date =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"End date"</span></span>
<span id="cb1-26">    ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb1-27">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(</span>
<span id="cb1-28">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">first_registered_year =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">year</span>(first_registered_on),</span>
<span id="cb1-29">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">intervention_end_year =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">year</span>(intervention_end_date),</span>
<span id="cb1-30">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">end_year =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">year</span>(end_date)</span>
<span id="cb1-31">    ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb1-32">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Status =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(Status <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abandoned"</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> Status <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"withdrawn"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abandoned_or_withdrawn"</span>, Status)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb1-33">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Status =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">factor</span>(Status, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">levels =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"on_going"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abandoned_or_withdrawn"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"in_development"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"completed"</span>)))</span>
<span id="cb1-34"></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># colourblind palette</span></span>
<span id="cb1-36">cbPalette <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#999999"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#E69F00"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#56B4E9"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#009E73"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#F0E442"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#0072B2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#D55E00"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#CC79A7"</span>)</span>
<span id="cb1-37"></span>
<span id="cb1-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot of status by year of registration</span></span>
<span id="cb1-39"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(trials, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill=</span>Status, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>first_registered_year)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb1-40">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_bar</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">position=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">stat=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"count"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb1-41">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_continuous</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">limits =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2012.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2023.5</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2013</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2023</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-42">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_fill_manual</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values=</span>cbPalette) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-43">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_continuous</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">labels =</span> scales<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">percent_format</span>()) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-44">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Year of registration"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Percentage of trials"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb1-45">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_minimal</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="the-preregistration-halo_files/figure-html/unnamed-chunk-1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://www.jasoncollins.blog/posts/the-preregistration-halo_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot of status by reported end year</span></span>
<span id="cb2-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(trials, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill=</span>Status, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>end_year)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb2-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_bar</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">position=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">stat=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"count"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb2-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_continuous</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">limits =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2012.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2025.5</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2013</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2025</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb2-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_fill_manual</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values=</span>cbPalette) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_continuous</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">labels =</span> scales<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">percent_format</span>()) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"End date"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Percentage of trials"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_minimal</span>()</span></code></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="the-preregistration-halo_files/figure-html/unnamed-chunk-2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://www.jasoncollins.blog/posts/the-preregistration-halo_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>The proposed “end date” entered by registrants is likely the best benchmark for when we should see a result. Around half of the trials proposed to end between 2014 and 2019 have been marked as completed. The completion rate declines in more recent years. The registry gives a glimpse of the file drawer, but we see a non-random selection of what’s in it.</p>
<p>Eliot Abrams, Jonathan Libgoer and John List <span class="citation" data-cites="abrams2020">(2020)</span> also catalogued some of the issues with the AEA Registry. Over 90% of RCTs don’t register. Only 50% of those who register do so before the intervention begins. And most preregistrations lack detail.</p>
<p>Now to the recent story, via <a href="https://statmodeling.stat.columbia.edu/2023/11/21/of-course-its-preregistered-just-give-me-a-sec/">Jessica Hullman</a></p>
<p>John Protzko and friends <span class="citation" data-cites="protzko2023">(2023)</span> published a paper in Nature Human Behaviour, <em>High replicability of newly discovered social-behavioural findings is achievable</em>. Part of the abstract reads:</p>
<blockquote class="blockquote">
<p>This paper reports an investigation by four coordinated laboratories of the prospective replicability of 16 novel experimental findings using rigour-enhancing practices: confirmatory tests, large sample sizes, preregistration and methodological transparency. In contrast to past systematic replication efforts that reported replication rates averaging 50%, replication attempts here produced the expected effects with significance testing (P &lt; 0.05) in 86% of attempts, slightly exceeding the maximum expected replicability based on observed effect sizes and sample sizes.</p>
</blockquote>
<p>In the text, they note that they preregistered their analyses. We have a preregistered analysis of the benefits of preregisteration (or so it seems):</p>
<blockquote class="blockquote">
<p>All confirmatory tests, replications and analyses were preregistered both in the individual studies (Supplementary Information section 3 and Supplementary Table 2) and for this meta-project.</p>
</blockquote>
<p>However, Joseph Bak-Coleman and Berna Devezer <span class="citation" data-cites="bak-coleman2023">(2023)</span> noted there are many forking paths in the analysis. This is particularly the case around the choice of metrics. Those chosen do not match past practice. Bak-Coleman and Devezer note that “preregistration could provide a justification for preferring one metric over another”. However, a problem arises when we look at the preregistration:</p>
<blockquote class="blockquote">
<p>Although the authors claim “All confirmatory tests, replications and analyses were preregistered”, the analysis on which titular claim depends was not preregistered. There is no mention of examining the relationship between replicability and rigor-improving methods, nor even how replicability would be operationalized despite extensive descriptions of the calculations of other quantities. With nothing indicating this comparison or metric it rests on were planned a priori, it is hard to distinguish the core claim in this paper from selective reporting and hypothesizing after the results are known.</p>
</blockquote>
<p>It seems the reviewers didn’t bother to check that the analysis matched the pre-registration.</p>
<p>Protzko and friends are now searching for a preregistration that might match their analysis. An editor’s note now appended to the paper reads:</p>
<blockquote class="blockquote">
<p>Editor’s Note: Readers are alerted that this paper is subject to criticisms that are being considered by the editors. The criticisms relate to the preregistration and corresponding reporting of hypotheses, predictions, and analyses. We are investigating the concerns raised and an editorial response will follow the resolution of these issues.</p>
</blockquote>
<p>Funnily enough, Protzko and friends provide evidence in support of preregistration. We have an analysis with many forking paths. A preregistration might have provided some constraint. Unfortunately, this case for preregistration is not the one that they intended.</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-abrams2020" class="csl-entry">
Abrams, E., Libgober, J., and List, J. A. (2020). Research registries: Facts, myths, and possible improvements. <em>NBER Working Paper</em>. <a href="https://doi.org/10.3386/w27250">https://doi.org/10.3386/w27250</a>
</div>
<div id="ref-bak-coleman2023" class="csl-entry">
Bak-Coleman, J., and Devezer, B. (2023). <em>Causal claims about scientific rigor require rigorous causal evidence.</em> <a href="https://doi.org/10.31234/osf.io/5u3kj">https://doi.org/10.31234/osf.io/5u3kj</a>
</div>
<div id="ref-protzko2023" class="csl-entry">
Protzko, J., Krosnick, J., Nelson, L., Nosek, B. A., Axt, J., … Schooler, J. W. (2023). High replicability of newly discovered social-behavioural findings is achievable. <em>Nature Human Behaviour</em>, 1–9. <a href="https://doi.org/10.1038/s41562-023-01749-9">https://doi.org/10.1038/s41562-023-01749-9</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/the-preregistration-halo.html</guid>
  <pubDate>Fri, 26 Jan 2024 07:00:00 GMT</pubDate>
</item>
<item>
  <title>A bunch of links</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/a-bunch-of-links-2.html</link>
  <description><![CDATA[ 




<p>Social science a mess, journals no good, the meaningless of the label “misinformation”, Flipper Zero, and cleaning up the list of named “biases”:</p>
<ol type="1">
<li><a href="https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">Social science is a mess and it’s not getting better</a>. A few years old, but a lot of gold. A few nuggets:</li>
</ol>
<blockquote class="blockquote">
<p>Economics topped the charts in terms of expectations, and it was by far the strongest field. There are certainly large improvements to be made — a 2/3 replication rate is not something to be proud of. But reading their papers you get the sense that at least they’re trying, which is more than can be said of some other fields. … A unique weakness of economics is the frequent use of absurd instrumental variables. I doubt there’s anyone (including the authors) who is convinced by that stuff, so let’s cut it out.</p>
</blockquote>
<blockquote class="blockquote">
<p>Going into this, my view of evolutionary psychology was shaped by people like Cosmides, Tooby, DeVore, Boehm, and so on. You know, evolutionary psychology! But the studies I skimmed from evopsych journals were mostly just weak social psychology papers with an infinitesimally thin layer of evolutionary paint on top. Few people seem to take the “evolutionary” aspect really seriously.</p>
</blockquote>
<ol start="2" type="1">
<li><p><a href="https://getsyeducated.substack.com/p/pnas-is-not-a-good-journal">PNAS is Not a Good Journal</a>. The 69 Nature branded journals aren’t any good either.</p></li>
<li><p>The misinformation label has become almost meaningless. Fact checking is often more about “vibe” than whether a claim is factual. Dan Williams <a href="https://www.conspicuouscognition.com/p/misinformation-researchers-are-wrong">makes the case</a> that any attempt to divide content into misleading and non-misleading buckets is too subjective.</p></li>
<li><p>I’ve recently come across <a href="https://flipperzero.one">Flipper Zero</a>. I’ve spent a lot of time trying to understand the implications of generative AI and other tech while sitting in front of my laptop, but there’s something to be said about tinkering in the physical world.</p></li>
<li><p>A step toward cleaning up the huge list of named “biases” floating around: <a href="https://doi.org/10.1177/17456916221148147">Toward Parsimony in Bias Research: A Proposed Common Framework of Belief-Consistent Information Processing for a Set of Biases</a>. Some of the clean-up probably doesn’t even need a theoretical framework, just the simple act of recognising that people have named the same phenomena multiple times.</p></li>
</ol>



 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/a-bunch-of-links-2.html</guid>
  <pubDate>Fri, 19 Jan 2024 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Books I read in 2023</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/books-i-read-in-2023.html</link>
  <description><![CDATA[ 




<p>These are the books I enjoyed the most in 2023, although they were published in different years:</p>
<ul>
<li>Edward Abbey, <em>Desert Solitaire</em>: I love the sense of place that Abbey creates.</li>
<li>Paige Harden, <em>The Genetic Lottery</em>: Harden’s politics seep through the text, and it is slightly irritating to be constantly labelled a eugenicist. However, it contains an accessible explanation of the science with many great examples.</li>
<li>Ray Bradbury, <em>The Martian Chronicles</em>: I bought it for the kids, but I suspect it’s beyond them. Wonderful stories.</li>
</ul>
<p>The book I invested in the most was Douglas Hofstadter’s, <em>Godel, Escher, Bach</em>. It was a good book to work through during 12 days of surfing on an isolated island. Too much clever for the sake of being clever and an unclear thesis (even after reading the 20-year anniversary foreword that stated what the thesis was), but enough interesting ideas to keep me going.</p>
<p>Below is the list of books I read in 2023 (with a star if I have read them before). For the first time in a few years, the volume of my reading of books cover-to-cover has increased, with 36 total (23 non-fiction, 13 fiction).</p>
<p><em>Non-Fiction</em></p>
<ul>
<li>Edward Abbey, <em>Desert Solitaire</em></li>
<li>Peter Attia, <em>Outlive: The Science and Art of Longevity</em></li>
<li>Jordan Belfort, <em>The Wolf of Wall Street</em></li>
<li>Dale Bredesen, <em>The End of Alzheimer’s</em></li>
<li>Janet Browne, <em>Charles Darwin: Voyaging</em>*</li>
<li>Janet Browne, <em>Charles Darwin: The Power of Place</em></li>
<li>Ross Douthat, <em>The Decadent Society</em></li>
<li>Dave Grohl, <em>The Storyteller: Tales of Life and Music</em></li>
<li>Paige Harden, <em>The Genetic Lottery</em></li>
<li>Douglas Hofstadter, <em>Godel, Escher, Bach</em></li>
<li>Chuck Klosterman, <em>The Nineties</em></li>
<li>Jon Krakuer, <em>Into Thin Air</em></li>
<li>Michael Lewis, <em>Liar’s Poker</em>*</li>
<li>John List, <em>The Voltage Effect</em></li>
<li>Andrew Lo, <em>Adaptive Markets</em></li>
<li>Gordon Menzies, <em>Western Fundamentalism</em></li>
<li>Douglas Murray, <em>The War on the West</em></li>
<li>Benjamin Newell, David Lagnado and David Shanks, <em>Straight Choices: The Psychology of Decision Making</em></li>
<li>Jenny Odell, <em>Saving Time</em></li>
<li>Lionel Page, <em>Optimally Irrational</em></li>
<li>Richard Reeves, <em>Of Boys and Men</em></li>
<li>Richard Thaler, <em>The Winner’s Curse</em></li>
<li>Richard Wrangham, <em>Catching Fire</em></li>
</ul>
<p><em>Fiction</em></p>
<ul>
<li>Edward Abbey, <em>The Monkeywrench Gang</em></li>
<li>Edward Abbey, <em>Fire on the Mountain</em></li>
<li>Ray Bradbury, <em>The Martian Chronicles</em></li>
<li>Douglas Coupland, <em>Generation X</em>*</li>
<li>Aldous Huxley, <em>Brave New World</em></li>
<li>George RR Martin, <em>A Dance with Dragons</em></li>
<li>George RR Martin, <em>A Feast for Crows</em></li>
<li>Baroness Orczy, <em>The Scarlet Pimpernel</em></li>
<li>George Orwell, <em>1984</em></li>
<li>Robert Louis Stevenson, <em>Treasure Island</em>*</li>
<li>JRR Tolkein, <em>The Fellowship of the Ring</em>*</li>
<li>JRR Tolkein, <em>The Two Towers</em>*</li>
<li>JRR Tolkein, <em>The Return of the King</em>*</li>
</ul>
<p>Previous annual book lists: <a href="../posts/top-10-books-in-2010.html">2010</a>, <a href="../posts/best-books-i-read-in-2011.html">2011</a>, <a href="../posts/the-best-books-i-read-in-2012.html">2012</a>, <a href="../posts/best-books-i-read-in-2013.html">2013</a>, <a href="../posts/best-books-i-read-in-2014.html">2014</a>, <a href="../posts/best-books-i-read-in-2015.html">2015</a>, <a href="../posts/best-books-i-read-in-2016.html">2016</a>, <a href="../posts/best-books-i-read-in-2017.html">2017</a>, <a href="../posts/books-i-read-in-2018.html">2018</a>, <a href="../posts/best-books-i-read-in-2019.html">2019</a>, <a href="../posts/best-books-i-read-in-2020.html">2020</a>, <a href="../posts/best-books-i-read-in-2021.html">2021</a>, <a href="../posts/books-i-read-in-2022.html">2022</a></p>



 ]]></description>
  <guid>https://www.jasoncollins.blog/posts/books-i-read-in-2023.html</guid>
  <pubDate>Thu, 18 Jan 2024 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Behavioral science policy recommendations early in the pandemic were LARGELY CORRECT, if you ignore those that were not</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/behavioral-science-policy-recommendations-early-in-the-pandemic-were-largely-correct-if-you-ignore-those-that-were-not.html</link>
  <description><![CDATA[ 




<p>In late April 2020, a group of behavioural scientists <span class="citation" data-cites="vanbavel2020">(Van Bavel et al., 2020)</span> published a paper in Nature Human Behaviour, “Using social and behavioural science to support COVID-19 pandemic response”. They provided a range of suggestions for policy makers.</p>
<p>The paper sparked some debates about the readiness of behavioural science to inform the pandemic response. One of these critiques was in an article by <span class="citation" data-cites="ijzerman2020">IJzerman et al. (2020)</span>, which advised caution when applying behavioural science to policy.</p>
<p>A new article in Nature <span class="citation" data-cites="ruggeri2023">(Ruggeri et al., 2023)</span> has reviewed the policy recommendations in that April 2020 paper. Part of the abstract reads:</p>
<blockquote class="blockquote">
<p>In April 2020, an influential paper proposed 19 policy recommendations (‘claims’) detailing how evidence from behavioural science could contribute to efforts to reduce impacts and end the COVID-19 pandemic. Here we assess 747 pandemic-related research articles that empirically investigated those claims. We report the scale of evidence and whether evidence supports them to indicate applicability for policymaking. Two independent teams, involving 72 reviewers, found evidence for 18 of 19 claims, with both teams finding evidence supporting 16 (89%) of those 18 claims.</p>
</blockquote>
<p>It’s a tick for that 2020 paper.</p>
<p>But, I wondered how long it would take for someone to extend this finding about a specific set of claims in ONE paper to a claim that “behavioural science was right!”.</p>
<p>It didn’t take long. Here’s one statement from the lead author of the Nature paper:</p>
<blockquote class="blockquote">
<p>Behavioral science policy recommendations early in the pandemic were LARGELY CORRECT. Our global collaboration in <a href="https://twitter.com/Nature?ref_src=twsrc%5Etfw">@Nature</a> covers 747 studies with an average sample size over 16,000! Evidence supports 16 of 19 claims, with lessons for science &amp; policy. <a href="https://t.co/OzS7njsrzv">https://t.co/OzS7njsrzv</a> <a href="https://t.co/3xoGQHBJFB">pic.twitter.com/3xoGQHBJFB</a></p>
<p>— Kai Ruggeri (@kairuggeri) <a href="https://twitter.com/kairuggeri/status/1734968618730013093">December 13, 2023</a></p>
</blockquote>
<p>A quick peruse of twitter can find others of a similar vein.</p>
<p>It takes a relatively short memory to forget that, whatever the merits of this single paper, the behavioural science community was the source of plenty of rubbish.</p>
<p>Here’s <a href="https://www.bloomberg.com/view/articles/2020-02-28/coronavirus-panic-caused-by-probability-neglect">one classic</a> from a co-author of both the 2020 paper and the Nature review, Cass Sunstein, published on 29 February 2020:</p>
<blockquote class="blockquote">
<p>At this stage, no one can specify the magnitude of the threat from the coronavirus. But one thing is clear: A lot of people are more scared than they have any reason to be. They have an exaggerated sense of their own personal risk.</p>
</blockquote>
<p>Based on an experiment involving 156 undergraduate students receiving electric shocks, Sunstein suggested people exhibited “probability neglect” in worrying about the coming pandemic.</p>
<p>Four weeks later <a href="https://www.bloomberg.com/opinion/articles/2020-03-26/coronavirus-lockdowns-look-smart-under-cost-benefit-scrutiny">he was writing</a>: “This Time the Numbers Show We Can’t Be Too Careful”. No acknowledgment that the earlier prognostication might not have been on the mark. He just moved on as if nothing had happened.</p>
<p>I posted more about these claims <a href="https://www.jasoncollins.blog/posts/the-limits-of-behavioural-science-coronavirus-edition">here</a> and <a href="https://www.jasoncollins.blog/posts/arent-we-smart-fellow-behavioural-scientists">here</a>.</p>
<p>The Van Bavel et al.&nbsp;article was a good target for review. Praise its sobriety.</p>
<p>But a review of a single paper is not a foundation for a general claim that the behavioural science community covered itself in glory. That would require a much broader study of what came out of it. That includes thought bubbles from Cass Sunstein and other behavioural scientists on public platforms. It includes outputs of the various behavioural insights teams, many of which were central to government pandemic responses. It includes the broader body of published behavioural science recommendations.</p>
<p>Such a broad review is a considerable effort. (Reviewing the single paper in such depth was impressive). But it wouldn’t take long to see that a general claim of correctness is overreach. Just look at some of the claims by those authors themselves.</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-ijzerman2020" class="csl-entry">
IJzerman, H., Lewis, N. A., Przybylski, A. K., Weinstein, N., DeBruine, L., … Anvari, F. (2020). Use caution when applying behavioural science to policy. <em>Nature Human Behaviour</em>, <em>4</em>(11), 1092–1094. <a href="https://doi.org/10.1038/s41562-020-00990-w">https://doi.org/10.1038/s41562-020-00990-w</a>
</div>
<div id="ref-ruggeri2023" class="csl-entry">
Ruggeri, K., Stock, F., Haslam, S. A., Capraro, V., Boggio, P., … Willer, R. (2023). A synthesis of evidence for policy from behavioural science during COVID-19. <em>Nature</em>, 1–14. <a href="https://doi.org/10.1038/s41586-023-06840-9">https://doi.org/10.1038/s41586-023-06840-9</a>
</div>
<div id="ref-vanbavel2020" class="csl-entry">
Van Bavel, J. J., Baicker, K., Boggio, P. S., Capraro, V., Cichocka, A., … Willer, R. (2020). Using social and behavioural science to support COVID-19 pandemic response. <em>Nature Human Behaviour</em>, <em>4</em>(5), 460–471. <a href="https://doi.org/10.1038/s41562-020-0884-z">https://doi.org/10.1038/s41562-020-0884-z</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/behavioral-science-policy-recommendations-early-in-the-pandemic-were-largely-correct-if-you-ignore-those-that-were-not.html</guid>
  <pubDate>Thu, 21 Dec 2023 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Do students learn less from experts?</title>
  <dc:creator>Jason Collins</dc:creator>
  <link>https://www.jasoncollins.blog/posts/do-students-learn-less-from-experts.html</link>
  <description><![CDATA[ 




<p>I firmly believe in going straight to the source before sharing a story I’ve heard elsewhere. Here is another example of why.</p>
<p>In a recent <a href="https://behavioralscientist.org/a-better-way-to-ask-for-advice-learn-from-the-best/">article in Behavioral Scientist</a>, Adam Grant writes:</p>
<blockquote class="blockquote">
<p>In a clever study, economists wanted to find out whether students really learn more from experts. They collected data on every freshman at Northwestern University from 2001 to 2008. They investigated whether freshmen did better in their second course in a subject if their introductory class was taught by more qualified instructors.</p>
<p>You might assume that students would be better off learning the basics from an expert (a tenure‑track or tenured professor) than a nonexpert (a lecturer with less specialized knowledge). But the data showed the opposite: students who took their initial class with an expert ended up with poorer grades in the next class.</p>
<p>The pattern was robust across fields: students learned less from introductory classes taught by experts in every subject. It held across years—with over 15,000 students—and in courses with tougher as well as easier grading. And the experts were especially bad at teaching students who were less academically prepared.</p>
<p>It turns out that if you’re taking a new road, the best experts are often the worst guides.</p>
</blockquote>
<p>I’ve been compiling some thoughts on how universities don’t take teaching seriously, so was interested in finding the source of this story.</p>
<p>There is no link to the paper in the Behavioral Scientist article, but the paper appears to be one by David Figlio, Morton Schapiro and Kevin Soter <span class="citation" data-cites="figlio2015">(2015)</span> from The Review of Economics and Statistics, titled “Are Tenure Track Professors Better Teachers?”. The basic facts match”: 15,662 freshman students between fall 2011 and fall 2008.</p>
<p>Figlio and friends describe the result in the abstract as follows:</p>
<blockquote class="blockquote">
<p>We find consistent evidence that students learn relatively more from contingent faculty in their first-term courses.</p>
</blockquote>
<p>Under Adam Grant’s interpretation of this paper, the tenure track and tenured faculty are the experts. (I’ll call them “tenured” for brevity.) The contingent faculty are the non-experts.</p>
<p>But who are these contingent faculty? Given this is Northwestern University, a selective and highly-ranked university, it can attract decent contingent faculty. Further, “a substantial majority of contingent faculty at Northwestern are full-time faculty members with long-term contracts and benefits and therefore may have a stronger commitment to the institution than some of their contingent counterparts at other institutions.” Many of those who are part-time have long-term relationships with the university, teaching in addition to their professional careers. They are not duds and it is questionable to label them as non-experts.</p>
<p>Then we dig into the details of what is driving the difference. The abstract continues:</p>
<blockquote class="blockquote">
<p>This result is driven by the fact that the bottom quarter of tenure track/tenured faculty (as indicated by our measure of teaching effectiveness) has lower “value added” than their contingent counterparts.</p>
</blockquote>
<p>The value add distribution is virtually identical for the top three quarters of tenured and contingent faculty.</p>
<p>What does this mean? We’ve got a subset of tenured faculty who teach poorly. As per Grant’s story, is this a cohort suffering from the curse of expertise? I suppose it’s possible, but this makes the curse somewhat less than general, with most experts able to overcome it. But the authors suggest another explanation:</p>
<blockquote class="blockquote">
<p>In some ways, this is exactly what we might have expected: contingent faculty members who are hired to teach and who perform relatively poorly are less likely to be renewed than are those who perform well, while tenure track faculty who are relatively poor teachers may be promoted and retained for reasons other than their teaching ability.</p>
</blockquote>
<p>I would have hypothesised the same. They are not duds because they are experts. They are simply poor teachers or don’t care. They aren’t fired as they perform in other dimensions that the university cares about. They face an incentive structure different to the contingent staff.</p>
<p>Unfortunately, there were no administrative records to confirm this selection effect, although Figlio and friends did find that the relative gap between contingent and tenured staff emerges among teachers who have been teaching for six or more years. That’s consistent with selection. It could also be consistent with Grant’s story of expertise if you assumed that the tenured faculty gained expertise of a different kind from experienced contingent faculty. Still, there’s no direct evidence of this, and even if there were, it only affects the bottom quarter of the faculty.</p>
<p>Putting it together, there is little evidence in that paper that experts are worse teachers. There may be some underlying curse of knowledge, but this paper doesn’t have the right tests to pick it out.</p>
<p>I also poked around in some of the cited and citing literature and didn’t see anything there to support the claim. It might exist - I didn’t search thoroughly - but if something decent existed, I would have expected Grant to use that instead. Here are two of the interesting ones:</p>
<ul>
<li><span class="citation" data-cites="carrell2010">Carrell and West (2010)</span> find that “that less experienced and less qualified professors produce students who perform significantly better in the contemporaneous course being taught, whereas more experienced and highly qualified professors produce students who perform better in the follow-on related curriculum.” Somewhat ambiguous, but I’d put more weight on long-term performance and suggest a tick for expertise.</li>
<li><span class="citation" data-cites="feld2019">Feld et al. (2019)</span> found that “students are almost as effective as senior instructors”, although “exclusively using them will likely negatively affect student outcomes.” Not a big tick to the benefits of expertise, but also not in line with a story that experts are worse teachers.</li>
</ul>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2">
<div id="ref-carrell2010" class="csl-entry">
Carrell, Scott&nbsp;E., and West, James&nbsp;E. (2010). Does professor quality matter? Evidence from random assignment of students to professors. <em>Journal of Political Economy</em>, <em>118</em>(3), 409–432. <a href="https://doi.org/10.1086/653808">https://doi.org/10.1086/653808</a>
</div>
<div id="ref-feld2019" class="csl-entry">
Feld, J., Salamanca, N., and Zölitz, U. (2019). Students are almost as effective as professors in university teaching. <em>Economics of Education Review</em>, <em>73</em>, 101912. <a href="https://doi.org/10.1016/j.econedurev.2019.101912">https://doi.org/10.1016/j.econedurev.2019.101912</a>
</div>
<div id="ref-figlio2015" class="csl-entry">
Figlio, D. N., Schapiro, M. O., and Soter, K. B. (2015). Are Tenure Track Professors Better Teachers? <em>Review of Economics and Statistics</em>, <em>97</em>(4), 715–724. <a href="https://doi.org/10.1162/REST_a_00529">https://doi.org/10.1162/REST_a_00529</a>
</div>
</div></section></div> ]]></description>
  <guid>https://www.jasoncollins.blog/posts/do-students-learn-less-from-experts.html</guid>
  <pubDate>Thu, 02 Nov 2023 09:00:00 GMT</pubDate>
</item>
</channel>
</rss>
