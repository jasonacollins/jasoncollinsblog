<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jason Collins">
<meta name="dcterms.date" content="2025-10-24">

<title>Is following artificial intelligence advice “anchoring bias”? – Jason Collins blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-9be722aa83fbcc428616ae682c30a50a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-C50MEPDMZ9"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-C50MEPDMZ9', { 'anonymize_ip': true});
</script>
<meta name="quarto:status" content="draft">


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Is following artificial intelligence advice “anchoring bias”? – Jason Collins blog">
<meta property="og:description" content="Behavioural economics, data science and artificial intelligence.">
<meta property="og:image" content="https://www.jasoncollins.blog/posts/img/is-following-ai-advice-anchoring/rastogi-et-al-2022-fig-2a.png">
<meta property="og:site_name" content="Jason Collins blog">
<meta property="og:image:height" content="460">
<meta property="og:image:width" content="644">
<meta name="twitter:title" content="Is following artificial intelligence advice “anchoring bias”? – Jason Collins blog">
<meta name="twitter:description" content="Behavioural economics, data science and artificial intelligence.">
<meta name="twitter:image" content="https://www.jasoncollins.blog/posts/img/is-following-ai-advice-anchoring/rastogi-et-al-2022-fig-2a.png">
<meta name="twitter:image-height" content="460">
<meta name="twitter:image-width" content="644">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Jason Collins blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../subscribe.html"> 
<span class="menu-text">Subscribe</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../teaching.html"> 
<span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Is following artificial intelligence advice “anchoring bias”?</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jason Collins </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 24, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Want to demonstrate human “irrationality”? Ask half of your audience the following question:</p>
<blockquote class="blockquote">
<p>Was Elvis older or younger than age 45 when he died?</p>
</blockquote>
<p>Ask the other half:</p>
<blockquote class="blockquote">
<p>Was Elvis older or younger than age 75 when he died?</p>
</blockquote>
<p>Then ask both groups:</p>
<blockquote class="blockquote">
<p>How old was Elvis when he died?</p>
</blockquote>
<p>Those asked if Elvis was older or younger than age 45 tend to estimate a lower age than those asked about age 75.</p>
<p>This is an illustration of the “anchoring and adjustment” heuristic. When people estimate a quantity, they often start from an initial value (the anchor) and adjust from that anchor to get a final answer. The heuristic can be biased where we use weak anchors or insufficiently adjust from the anchor.</p>
<p>One famous experiment on anchors was by <span class="citation" data-cites="tversky1974">Tversky and Kahneman (<a href="#ref-tversky1974" role="doc-biblioref">1974</a>)</span>. They spun a wheel with numbers between 0 and 100 on it, but rigged to stop at either 10 or 65. They then asked people whether the proportion of African countries who were members of the United Nations was above or below that number (this experiment was in the 1970s). The participants were also asked for a numerical estimate. Those who saw 10 on the wheel estimated 25 percent. Those who saw 65 estimated 45 percent. The (assumed) randomness of the anchor was a nice experimental feature. In my Elvis example above, the respondent might assume I chose the number (45 or 75) for a reason. There might be information in that number. There is no such information in the spinning of the wheel.</p>
<p>Insufficient adjustment from the anchor can be thought of as the complement of using an irrelevant anchor. If there is any trace of an irrelevant anchor in your answer, you haven’t adjusted enough. However, many anchors we use are sensible - we just don’t adjust enough for our particular case.</p>
<p>Although anchoring is often called a “bias”, it is better to think of anchoring as a heuristic that can backfire in some task environments. If you’re considering making an offer for a four-bedroom house, it’s not a bad strategy to start with the sale price of the neighbouring three-bedroom house. Adjust for the extra bedroom and any other differences between the two. <span class="citation" data-cites="griffiths2015">Griffiths et al. (<a href="#ref-griffiths2015" role="doc-biblioref">2015</a>)</span> argued that anchoring and adjustment can be “resource-rational”, as accounting for the computational cost makes anchoring and adjustment an optimal estimation strategy.</p>
<p>Which brings me to the question of anchoring to artificial intelligence (AI) advice.</p>
<p>A challenge in human-AI interaction is calibrating the user’s trust in the AI system. When should a user trust the AI? When should they deviate from the AI recommendation? Most experimental evidence suggests we don’t calibrate well. Complementary performance - the human-AI combination outperforming the human or AI alone - is hard to achieve. The most common result is the AI boosting human performance, but not to the level of the AI alone. Deviations from the AI advice are more likely to degrade than improve performance.</p>
<p><span class="citation" data-cites="rastogi2022">Rastogi et al. (<a href="#ref-rastogi2022" role="doc-biblioref">2022</a>)</span> proposed that one obstacle to complementary performance is “anchoring bias”. People do not explore the alternative hypotheses once the AI decision has provided an anchor.</p>
<p>To examine this question, <span class="citation" data-cites="rastogi2022">Rastogi et al. (<a href="#ref-rastogi2022" role="doc-biblioref">2022</a>)</span> conducted two experiments, which I walk through below.</p>
<section id="experiment-1" class="level2">
<h2 class="anchored" data-anchor-id="experiment-1">Experiment 1</h2>
<p>The authors asked a group of <a href="https://www.mturk.com/">Amazon Mechanical Turk</a> workers to use student data to predict whether the student would pass or fail a class. The data, drawn from a <a href="https://archive.ics.uci.edu/dataset/320/student+performance">student performance dataset</a>, included student characteristics, past performance and demographics. The workers were also provided with an AI model recommendation (logistic regression) based on the 10 most important student features (e.g.&nbsp;mother’s and father’s education, hours spent studying weekly).</p>
<p>At the start of the session, the authors asked participants to give estimates for 15 training examples. Their training instructions were described by the authors as follows:</p>
<blockquote class="blockquote">
<p>To induce anchoring bias, the participant was informed at the start of the training section that the AI model was 85% accurate (we carefully chose the training trials to ensure that the AI was indeed 85% accurate over these trials), while the model’s actual accuracy is 70.8% over the entire training set and 66.5% over the test set. Since our goal is to induce anchoring bias and the training time is short, we stated a high AI accuracy.</p>
</blockquote>
<p>After each training estimate, the workers were shown the correct answer and the estimate made by the AI.</p>
<p>Effectively, participants are told the AI is 85% accurate and then see performance through the training set that aligns with that accuracy. Though you could frame this as “not a lie”, the participants are deliberately deceived about the capability of the AI (we’re not provided with the exact wording to make a finer judgment). I have another post in the pipeline on deception in human-AI experiments (surprisingly common) and a little more to say below. But to foreshadow some of my argument, I would not call someone biased if they used information designed to deceive them.</p>
<p>After training, the test section involved 36 trials. The AI accuracy in these trials was even lower than the 66% measured in testing as for eight trials the AI prediction was “flipped”, giving an AI prediction task accuracy of 58%. If the workers “anchored” to those eight flipped trials, their performance would be even worse than if given the actual AI predictions.</p>
<p>The primary hypothesis the authors tested in Experiment 1 is whether anchoring is reduced if the workers were given more time to make their prediction. Workers were given 10, 15, 20 or 25 seconds to make their prediction. If they were less likely to follow the erroneous prediction in those flipped trials, that would be evidence of reduced anchoring.</p>
<p>The results at first glance, as presented in the following figure, supports the hypothesis. Workers with 25 seconds were more likely to deviate from the incorrect recommendation. This might be thought of as being in line with <span class="citation" data-cites="griffiths2015">Griffiths et al. (<a href="#ref-griffiths2015" role="doc-biblioref">2015</a>)</span>, in that more resources enable more calculation and adjustment.</p>
<p><a href="img/is-following-ai-advice-anchoring/rastogi-et-al-2022-fig-2a.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="img/is-following-ai-advice-anchoring/rastogi-et-al-2022-fig-2a.png" class="img-fluid"></a></p>
<p>(I also suspect there is an error in this chart. The average disagreement for the non-probe trials is unbelievably low.)</p>
<p>There is one reported statistical test stating that time alleviates anchoring bias for those trials. There is no p-value reported, but based on the reported confidence intervals, it only just scrapes into statistical significance.</p>
<p>(To get on my high horse about pre-registration here, I can think of a lot of ways to test the effect of time on anchoring. A linear regression on a bootstrapped 5000 re-samples isn’t the first one that would come to mind. Why this choice? What of other options? )</p>
<p>The authors do not provide broader accuracy data or tests of anchoring beyond the Figure. We can see that more transparently in the data from Experiment 2, and it suggests that reducing “anchoring bias” on incorrect recommendations may not be without trade-offs.</p>
<p>(This incomplete reporting - like the lack of pre-registration - is typical of many experiments I have read in the human-computer interaction literature. The authors report limited results and the absence of publicly available data means that the best you can do is speculate on the robustness of the tests. Given we don’t even get accuracy data, we don’t get much chance to check other angles either.)</p>
<p>Measuring “adjustment” is also quite difficult here, as there is only one type of adjustment - disagreeing with the AI recommendation. Are participants using as anchoring and adjustment heuristic - or is it assume the AI is right unless there is clear evidence to the contrary?</p>
</section>
<section id="experiment-2" class="level2">
<h2 class="anchored" data-anchor-id="experiment-2">Experiment 2</h2>
<p>In experiment 2, the authors test a broader set of interventions to reduce “anchoring bias”. They also report richer data (in the form of a more detailed chart), so we’re able to see a little more of the dynamic.</p>
<p>This experiment used the same task as Experiment 1, except the AI model was trained excluding the second, third and fourth most relevant features for the prediction (hours spent studying weekly, hours spent going out with friends weekly, enrolment in extra educational support). This gave the workers three features that the AI did not have access to, creating potential for complementary performance via the information asymmetry.</p>
<p>The authors don’t state the accuracy of this degraded AI, but the workers are again told at the start of their training that the AI has 85% accuracy. However, the accuracy of the degraded AI on the sample for the participants’ main task was around 60%.</p>
<p>Workers were then places in the following conditions.</p>
<ul>
<li><strong>Human only</strong>: Workers provide their prediction without an AI prediction. They are given 25 seconds for each prediction</li>
<li><strong>Constant time</strong>: Workers provide their prediction with the help of the AI prediction, with 18 second per prediction.<br>
</li>
<li><strong>Random time</strong>: AI assistance with the time allocation randomly set to either 10 seconds or 25 seconds each trial.<br>
</li>
<li><strong>Confidence-based time</strong>: AI assistance with 10 or 25 seconds depending of AI confidence (low confidence = more time).<br>
</li>
<li><strong>Confidence-based time with explanation</strong>: As for confidence-based time but the AI confidence is explicitly provided (“low” or “high”).</li>
</ul>
<p>Each of these conditions aligns with a hypothesis that they might reduce anchoring.</p>
<ul>
<li>H2: Anchoring bias has a negative effect on human-AI collaborative decision-making accuracy when AI is incorrect.</li>
<li>H3: If the human decision-maker has complementary knowledge then allocating more time can help them sufficiently adjust away from the AI prediction.</li>
<li>H4: Confidence-based time allocation yields better performance than Human alone and AI alone.</li>
<li>H5: Confidence-based time allocation yields better human-AI team performance than constant time and random time allocations.</li>
<li>H6: Confidence-based time allocation with explanation yields better human-AI team performance than the other conditions.</li>
</ul>
<p>The results are summarised in these two figures (it takes a while to get your head around what they’re saying, I’ll highlight the most important bits below).</p>
<p><a href="img/is-following-ai-advice-anchoring/rastogi-et-al-2022-fig-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="img/is-following-ai-advice-anchoring/rastogi-et-al-2022-fig-4.png" class="img-fluid"></a></p>
<p>The most interesting interpretation relates to the central hypothesis, H2, that anchoring bias has a negative effect on human-AI collaborative decision-making accuracy when AI is incorrect. The human only group has higher accuracy than all of the AI groups on instances where the AI is incorrect. The authors take this as evidence in support of H2.</p>
<p>But is “anchoring bias” leading to this negative effect? To not have lower accuracy when the AI is incorrect than the human only condition, workers in the AI conditions would need to completely ignore the AI for those incorrect recommendations. The anchor is completely removed. But is that reasonable when the authors have informed the workers that the AI is 85% accurate - not to mention that is confirmed by their training experience? Labelling the giving of any weight to a piece of information - information that should have some weight - “anchoring bias” seems a stretch.</p>
<p>I am not sure “anchoring” in the best word to use in this situation, and I would not append bias to the label. Is any use of information for a particular decision, when that information degrades the decision “anchoring bias”? It is extending the label anchoring to mean accounting for any information. To call is a bias, I would examine a model of P(accuracy less than 85% | experimenter told us accuracy 85% + D)that updates over time. This includes the information given to them by the experimenters! They call it an anchor. I call it a prior. If I was in an economics experiment, the norm against deception would have my prior that the accuracy is actually 85% quite high.</p>
<p>If one of my kids tells me they’ve got a normal coin and flip two heads, I’m updating only marginally from my strong prior that the coin is fair. What is the level of trust of experimental participants in experimenters? What is the appropriate level of trust? (One reason deception is frowned upon in economics is because it degrades trust in experimenters, leading to an additional variable you need to account for in your analysis.)</p>
<p>Turning back to the hypothesis, the results also point to a complementary hypothesis:</p>
<blockquote class="blockquote">
<p>Anchoring bias has a positive effect on human-AI collaborative decision-making accuracy when AI is correct.</p>
</blockquote>
<p>Again, for this not to be true, we would need the person to completely ignore the AI. And unsurprisingly, eyeballing the figure, my hypothesis is true. The AI conditions all markedly outperform the human-only group on estimates where the AI recommendation is correct.</p>
<p>There’s actually an interesting pattern across all the conditions. Whenever you decrease the probability of following an incorrect AI recommendation, you also decrease the probability of following a correct recommendation. The result is that performance across all conditions is largely the same. Because the AI in this experiment is degraded to a quality similar to that of humans alone, reliance on the AI is largely a wash.</p>
<p>Finally, the authors provide another interesting interpretation when they state that they achieve complementary knowledge. This is an interesting thread in this experiment. Due to the three excluded variables, the human has more information that the AI. There are a lot of real-world application where the human will have information the AI doesn’t - an AI-financial adviser for example - so finding ways to enhance the use of unshared information is vital to achieving complementary performance. In this case, we get complementary knowledge in that the humans do as well as the AI alone despite the fact they don’t always follow the AI. Unforinately, we don’t get complemtnary performance - that is, outperformance by the human-AI team of both the human and AI alone. But that seems a prospective path.</p>
</section>
<section id="the-problem-is-more-often-insufficient-anchoring" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-is-more-often-insufficient-anchoring">The problem is more often insufficient anchoring</h2>
<p>This experiment involved an AI with capability on par with unassisted humans. But in most statistical tasks such as the one in this experiment, the AI outperforms the human. Further, human-AI teams tend to underperform the AI alone.</p>
<p>In other words, experiments typically find that people adjust too much! Here’s some data from <span class="citation" data-cites="dietvorst2018">Dietvorst et al. (<a href="#ref-dietvorst2018" role="doc-biblioref">2018</a>)</span>. People were more likely to use an algorithm if they could adjust it. That led to higher performance, largely because of this greater likelihood of selecting the model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption><span class="citation" data-cites="dietvorst2018">Dietvorst et al. (<a href="#ref-dietvorst2018" role="doc-biblioref">2018</a>)</span> Figure 2b</figcaption>
<p><a href="img/is-following-ai-advice-anchoring/dietvorst-et-al-2018-fig-2b.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="@dietvorst2018 Figure 2b"><img src="img/is-following-ai-advice-anchoring/dietvorst-et-al-2018-fig-2b.png" class="img-fluid figure-img" width="400" alt="Dietvorst et al. (2018) Figure 2b"></a></p>
</figure>
</div>
<p>But how does the performance of those who selected the model compare to the model itself. Here is a chart I have generated from the experimental data provided in the <a href="https://pubsonline.informs.org/doi/suppl/10.1287/mnsc.2016.2643/suppl_file/mnsc.2016.2643-sm-data.zip">supplementary materials</a>. (And again noting that business schools are <a href="why-i-dont-trust-most-human-ai-interaction-experimental-research.qmd">far ahead of the human-computer interaction crowd</a> when it comes to best practice data sharing.) In the “Adjust by 10” group, the participant;s adjustments were a wash, with their performance on par with the unadjusted model. But for those in the “Change 10” group, their changes increased the error. The AI alone was a stronger performer.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the data - specify na values to handle periods as missing</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/Overcoming_Algorithm_Aversion_Data-study-1-data.csv"</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">na =</span> <span class="fu">c</span>(<span class="st">""</span>, <span class="st">"NA"</span>, <span class="st">"."</span>))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert necessary columns to numeric (many are stored as strings due to periods)</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(ModelBonus, ModelAAEEstimate, HumanAAEEstimate,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                  ModelConfidence, HumanConfidence, Age, Gender, Education,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                  AAE, ModelAAE, HumanAAE, Bonus, BonusFromModel, BonusFromHuman,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                  CorrelationWithModel, AvDiffFromModel, AvAdjustmentSize,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                  AdjustmentDividedByPotential, HumModelCorrelation, HumModelAvDiff,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                  AvgLargest10Changes, AnyBonus), </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                as.numeric))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Define condition labels</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>condition_labels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"1"</span> <span class="ot">=</span> <span class="st">"Can't change"</span>, </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"2"</span> <span class="ot">=</span> <span class="st">"Adjust by 10"</span>, </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"3"</span> <span class="ot">=</span> <span class="st">"Change 10"</span>, </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"4"</span> <span class="ot">=</span> <span class="st">"Use freely"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for participants who chose the model (ModelBonus == 1)</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>model_choosers <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(ModelBonus <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate summary statistics by condition</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>summary_stats <span class="ot">&lt;-</span> model_choosers <span class="sc">%&gt;%</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Condition) <span class="sc">%&gt;%</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">n =</span> <span class="fu">n</span>(),</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">ModelAAE_mean =</span> <span class="fu">mean</span>(ModelAAE, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">AAE_mean =</span> <span class="fu">mean</span>(AAE, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">ModelAAE_sd =</span> <span class="fu">sd</span>(ModelAAE, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">AAE_sd =</span> <span class="fu">sd</span>(AAE, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">Difference =</span> AAE_mean <span class="sc">-</span> ModelAAE_mean,</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">PercentChange =</span> (Difference <span class="sc">/</span> ModelAAE_mean) <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">AvgAdjustmentSize =</span> <span class="fu">mean</span>(AvAdjustmentSize, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ConditionLabel =</span> condition_labels[<span class="fu">as.character</span>(Condition)])</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Add info about total participants per condition</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>total_by_condition <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Condition) <span class="sc">%&gt;%</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">total_n =</span> <span class="fu">n</span>())</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>summary_stats <span class="ot">&lt;-</span> summary_stats <span class="sc">%&gt;%</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(total_by_condition, <span class="at">by =</span> <span class="st">"Condition"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">PropChoseModel =</span> n <span class="sc">/</span> total_n)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for plotting</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> summary_stats <span class="sc">%&gt;%</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(AAE_mean) <span class="sc">&amp;</span> Condition <span class="sc">!=</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span>  <span class="co"># Remove can't change condition and any conditions with no data</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Condition, ConditionLabel, ModelAAE_mean, AAE_mean) <span class="sc">%&gt;%</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(ModelAAE_mean, AAE_mean),</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"ErrorType"</span>,</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"AAE"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    <span class="at">ErrorType =</span> <span class="fu">case_when</span>(</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>      ErrorType <span class="sc">==</span> <span class="st">"ModelAAE_mean"</span> <span class="sc">~</span> <span class="st">"Model (no adjustment)"</span>,</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>      ErrorType <span class="sc">==</span> <span class="st">"AAE_mean"</span> <span class="sc">~</span> <span class="st">"Actual (with adjustment)"</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    <span class="at">ErrorType =</span> <span class="fu">factor</span>(ErrorType, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Model (no adjustment)"</span>, <span class="st">"Actual (with adjustment)"</span>))</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(plot_data, <span class="fu">aes</span>(<span class="at">x =</span> ConditionLabel, <span class="at">y =</span> AAE, <span class="at">fill =</span> ErrorType)) <span class="sc">+</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">position =</span> <span class="st">"dodge"</span>, <span class="at">width =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Model (no adjustment)"</span> <span class="ot">=</span> <span class="st">"#3498db"</span>, </span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>                              <span class="st">"Actual (with adjustment)"</span> <span class="ot">=</span> <span class="st">"#e74c3c"</span>)) <span class="sc">+</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Error Rates for Model Choosers by Adjustment Condition"</span>,</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Comparing model performance with and without adjustments"</span>,</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Condition"</span>,</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Average Absolute Error (AAE)"</span>,</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Error Type"</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">hjust =</span> <span class="fl">0.5</span>),</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.subtitle =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>, <span class="at">hjust =</span> <span class="fl">0.5</span>),</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>),</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>()</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">max</span>(plot_data<span class="sc">$</span>AAE, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="sc">*</span> <span class="fl">1.1</span>), </span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>                     <span class="at">breaks =</span> <span class="fu">pretty_breaks</span>(<span class="at">n =</span> <span class="dv">5</span>)) <span class="sc">+</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add percentage change labels on top of bars</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> summary_stats <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(AAE_mean) <span class="sc">&amp;</span> Condition <span class="sc">!=</span> <span class="dv">1</span>),</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> ConditionLabel, <span class="at">y =</span> AAE_mean <span class="sc">+</span> <span class="fl">0.5</span>, </span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>                <span class="at">label =</span> <span class="fu">paste0</span>(<span class="fu">ifelse</span>(Difference <span class="sc">&gt;=</span> <span class="dv">0</span>, <span class="st">"+"</span>, <span class="st">""</span>), </span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">round</span>(PercentChange, <span class="dv">1</span>), <span class="st">"%"</span>)),</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>            <span class="at">inherit.aes =</span> <span class="cn">FALSE</span>,</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>            <span class="at">size =</span> <span class="fl">3.5</span>,</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>            <span class="at">fontface =</span> <span class="st">"bold"</span>)</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(p)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><a href="is-following-ai-advice-anchoring_files/figure-html/dietvorst-error-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="is-following-ai-advice-anchoring_files/figure-html/dietvorst-error-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>This is a typical finding. Here’s a plot of a meta-analysis by <span class="citation" data-cites="vaccaro2024">Vaccaro et al. (<a href="#ref-vaccaro2024" role="doc-biblioref">2024</a>)</span>. Across 370 effect sizes from 106 studies, human-AI combinations more typically underperformed the best of the human or AI than outperformed. (Those positive human-AI teams typically came from creative rather than decision tasks.)</p>
<p><a href="img/is-following-ai-advice-anchoring/vaccaro-et-al-2024-fig-1a.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="img/is-following-ai-advice-anchoring/vaccaro-et-al-2024-fig-1a.png" class="img-fluid" width="600"></a></p>
<p>Bringing this back to the anchoring experiment, if the AI actually had accuracy of 85% as the experimental participants were informed, I suspect we would be talking about a different problem: insufficient anchoring. Anchoring and overadjustment. That’s a very different problem to solve.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-dietvorst2018" class="csl-entry" role="listitem">
Dietvorst, B. J., Simmons, J. P., and Massey, C. (2018). Overcoming Algorithm Aversion: People Will Use Imperfect Algorithms If They Can (Even Slightly) Modify Them. <em>Management Science</em>, <em>64</em>(3), 1155–1170. <a href="https://doi.org/10.1287/mnsc.2016.2643">https://doi.org/10.1287/mnsc.2016.2643</a>
</div>
<div id="ref-griffiths2015" class="csl-entry" role="listitem">
Griffiths, T. L., Lieder, F., and Goodman, N. D. (2015). Rational Use of Cognitive Resources: Levels of Analysis Between the Computational and the Algorithmic. <em>Topics in Cognitive Science</em>, <em>7</em>(2), 217–229. <a href="https://doi.org/10.1111/tops.12142">https://doi.org/10.1111/tops.12142</a>
</div>
<div id="ref-rastogi2022" class="csl-entry" role="listitem">
Rastogi, C., Zhang, Y., Wei, D., Varshney, K. R., Dhurandhar, A., …. (2022). Deciding fast and slow: The role of cognitive biases in AI-assisted decision-making. <em>Proc. ACM Hum.-Comput. Interact.</em>, <em>6</em>(CSCW1), 83:183:22. <a href="https://doi.org/10.1145/3512930">https://doi.org/10.1145/3512930</a>
</div>
<div id="ref-tversky1974" class="csl-entry" role="listitem">
Tversky, A., and Kahneman, D. (1974). Judgment under Uncertainty: Heuristics and Biases. <em>Science</em>, <em>185</em>(4157), 1124–1131. <a href="https://doi.org/10.1126/science.185.4157.1124">https://doi.org/10.1126/science.185.4157.1124</a>
</div>
<div id="ref-vaccaro2024" class="csl-entry" role="listitem">
Vaccaro, M., Almaatouq, A., and Malone, T. (2024). When combinations of humans and AI are useful: A systematic review and meta-analysis. <em>Nature Human Behaviour</em>, 1–11. <a href="https://doi.org/10.1038/s41562-024-02024-1">https://doi.org/10.1038/s41562-024-02024-1</a>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.jasoncollins\.blog");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "jasonacollins/jasoncollinsblog";
    script.dataset.repoId = "R_kgDOIbjYgQ";
    script.dataset.category = "Announcements";
    script.dataset.categoryId = "DIC_kwDOIbjYgc4CSiuB";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "0";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "bottom";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://creativecommons.org/licenses/by/4.0/">
<p>Copyright: CC-BY</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>