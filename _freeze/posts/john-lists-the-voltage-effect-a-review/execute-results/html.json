{
  "hash": "5b83d620ef9e4f77c5808e319a53050f",
  "result": {
    "markdown": "---\ntitle: \"John List's The Voltage Effect: A review\"\nauthor: \"Jason Collins\"\ndate: 2023-04-28 09:00:00+10:00\ndraft: true\naliases:\n  - /john-lists-the-voltage-effect-a-review/\nbibliography: references.bib\n---\n\n\nOver a decade ago when I first started reading the behavioural economics literature, John List quickly became one of my favourite academics. Whenever I read an interview with List he always seemed to ask great, critical questions. He was rarely happy taking others' assumptions as given. I saw him as someone who, on hearing \"in my experience....\", would be the first to say \"should we run an experiment?\".\n\nMy impression of List has somewhat changed in the last year. His [Twitter posts](https://twitter.com/Econ_4_Everyone) have more of a promotional and congratulatory (of others) flavour than I would have expected given the image I had in my mind. But I suppose that's the angle you need to take when are pushing a new book.\n\nThat new book is *The Voltage Effect: How to Make Good Ideas Great and Great Ideas Scale*.\n\nThe term Voltage Effect comes from the literature on implementation science. The \"electric\" potential of what appears to be a promising intervention will often dissipate when rolled out into the real world. In List's case, this \"voltage drop\" occurs between the initial pilot of an economic intervention and the full-scale roll out of the intervention. Why are those roll-outs so often disappointing despite the initial promise?\n\nList seems the right person to answer that question. List pioneered the use of field experiments in economics. He was the Chief Economist for Uber, then Lyft and now Walmart. (I believe the Walmart role post-dates this book.) He has a catalogue of field trials and implementation experience that would not be matched by anyone apart from a few development economists. \n\nBut rather than being the author of this book, I would rather see List in another role. I'd love to read a review of this book by ..... John List.\n\nWhy?\n\nIn the first half of the book, List describes five problems that can cause voltage drops. In the second half, he gives four \"secrets\" to high-voltage scaling. I found myself agreeing with most of his high-level points in the first half and seeing some potential in those in the second.\n\nBut the problem is that these points aren't drawn from experiments themselves. They come from List's experience.\n\nWhat I love about John List is that he runs experiments to see if things are true. Throughout the book, List has stories where someone makes a claim and List responds \"Let's run an experiment\". But when he tries to talk about what works at the level above the experiment - which of course is the theme of the book - we have to listen to John List say \"Well, in my experience ...\". I have a lot of respect for List's experience, but I kept finding myself thinking, \"Maybe that's true, but I'm not convinced ... could we run an experiment?\".\n\n## The five problems that cause voltage drops\n\nList's five barriers to scaling all make sense (to me). Watch out for false positives. Know your audience. Make sure the ingredients to your implementation can scale. Consider spillovers. And understand what scaling will cost.\n\nList's discussion of the need to watch for false positives was interesting. Many ideas might seem promising during trials. But the statistical frameworks that we use can lead to false positives. Don't be afraid to use a second trial or staged implementation to check that the first trial wasn't a fluke. You should seek *independent* replication of your own work. And consider the incentives of those who are pushing any particular idea.\n\nI agree with this advice, although perhaps with a different emphasis. List doesn't give much ink to the replication crisis or mention that the behavioural science literature is littered with false positives. Some of the literature you're using as inspiration is likely rubbish. List does recognise scientific misconduct - telling the story of Brian Wansink - but doesn't hint at just how untrustworthy much of the literature is even in the absence of fraud.\n\nI am also sceptical of List's reasons why false positives can cause such problems. One reason he gives is confirmation bias, which prevents us from seeing evidence that might challenge our assumptions. He even gives us an evolutionary spin:\n\n> This tendency might appear counter to our own interests, but in the context of our species’s long-ago Darwinian history, confirmation bias makes perfect sense. Our brain evolved to reduce uncertainty and streamline our responses. For our ancestors, a shadow might have meant a predator, so if they assumed it was one and started running, this assumption could have saved their lives. If they stopped to gather more information and really think about it, they might have ended up as dinner.\n\nI'm not sure what is being described in that paragraph is confirmation bias. But more notably, we seem to have entered \"drop a bias\" territory - see a behaviour and tell a post-fact story about what bias is supposedly causing this problem. List tells us about the bandwagon effect, where we jump on board with others, effectively leaving the selection of the ideas to a few people rather than the collective group. We hear about sunk cost bias. List even shoehorns the winner's curse into the story, a phenomena in common-value auctions (an auction where the auctioned good has the same value to everyone) whereby the winner tends to overpay. The winner will tend to have the most optimistic estimate of the value of the good - and if you've got a higher estimate than everyone else, there's a decent chance you've overestimated. How does this apply to scaling false positives? After reading the section several times, I'm not sure.[^1]\n\n[^1]: A related point might be that if you are running many comparisons, the most promising will likely have an exaggerated effect size, but there are simple statistical methods (that I expect people like List would be using) to correct for this.\n\nAnd where's the experimental evidence that this is actually what is happening? I'm not sure a meta-experiment is possible, but at this point List's stories feel loose.\n\nList's second barrier to scaling relates to\" knowing your audience\". This is essentially a story of heterogeneity in your sample and the population in which the intervention will be rolled out. How broadly will your intervention work when you move from your trial sample to full-scale implementation? This includes a perspective across time: your current and future audience might differ.\n\nThe third barrier is whether all the elements of the intervention can scale. Is the pilot representative of the circumstances at scale? For example, if your educational intervention pilot involves all of the good teachers, it likely won't work when it scales and the weaker teachers become involved. If you are monitoring compliance in the pilot - the experimenters are watching - failure to do so when it rolls out may result in a substantial voltage drop. I have seen this myself, where the deck was stacked in the pilot.\n\nTo illustrate this point, List tells the story of the restaurant chain Jamie's Italian. Initially, the key to the restaurants were the simple ingredients and recipes - easily replicable at larger scale. Brand and fame can also scale. But later on the unscalable part of the operation - Jamie Oliver himself - became stretched, and the whole enterprise came down.\n\nI understand why people include stories like this in pop-science books - I use examples like this myself - but the question remains as to whether that was what really happened. List describes the new managing director of the enterprise as \"woefully unqualified\". But what's the metric for \"unqualfied\" beyond the post-fact assessment based on the chain's failure. Is this just the (negative) halo of the outcome being extended to those involved? (There's me dropping a bias...) I'll return to this point of story-telling in a bit.\n\nThe fourth barrier is the presence of spillovers. List has a nice story from Uber to illustrate. An initial trial of giving $5 coupons to a group of Uber riders was a success: the riders used Uber more, with the increased earnings more than offsetting the cost of the coupons. However, when rolled out at scale, the earnings increase did not materialise. The spike in demand caused by the coupons caused an increase in fares and wait times, which reduced demand.\n\nThe final barrier concerns the ultimate cost of scaling. Sometimes expected economies of scale don't materialise. There simply might not be enough of what you need at reasonable cost: for example, what is the cost of hiring enough \"good\" teachers to implement at scale?\n\n## The four secrets to scaling\n\nFrom the barriers List then moves to the secrets to success. I was more ambivalent toward the four secrets to scaling but there is still some wisdom in them.\n\nThe first is having incentives that scale. This isn't just about the size of the incentives, but considering how they can be made more powerful (e.g. by using loss aversion) and whether non-monetary incentives such as social norms can be leveraged. Most of this is relatively uncontroversial material, except perhaps for the following claim:\n\n> [T]he fact that human psychology doesn't vary much across groups (most people experience loss aversion to a similar degree, and nearly everyone cares about their social image) makes this type of incentive strategy highly scalable. In contrast, the level of financial rewards necessary to incentivize one's employees will vary widely from person to person, and for some might be unduly high.\n\nHere's one study I'd point to questioning this claim:\n\nXX\n\nI'm sure there are cases where a behavioural strategy will outperform a simple incentive. But as a general claim about variability, I don't buy it.\n\nThe second secret, to an economist at least, seems a no brainer. When calculating costs and benefits, look to the margins. Ask what benefit the last dollar spent gets you. Don't simply compare total costs and benefits as, even if the total benefits are greater, you could be spending less for greater net benefit.\n\nThe third secret is optimal quitting. Don't sink more time into the wrong idea. We get stories about PayPal and Twitter emerging from other failing strategies, and List's own decision to give up on a professional golf career. We get another dose of biases here - sunk cost and ambiguity aversion - but sound advice all the same. The challenge is - as List highlights - determining the optimal point to quit is hard.\n\nThe chapter on the secret of scaling culture opens with the story of two Brazilain villages, Cabuçu and Santo Estêvão.\n\nCabuçu is a small fishing community in which the men fish in groups of three to eight. This teamwork is needed to manage the boats on the choppy Atlantic waters, set the nets and pull in the large fish. A single fisherman would fail.\n\nSanto Estêvão sits inland of Cabuçu on the Paraguaçu rover. The villagers from Santo Estêvão catch small fish alone on the calm waters.\n\nList and colleagues ran games in the two villages to test whether their style of fishing, shaped by the environment each found themselves in, was reflected in their level of trust and cooperation. They found that the villagers from Cabuçu proposed more equal offers in the Ultimatum game, contributed more in public goods games, invested more in the trust game (and sent back more) and donated more to charity. The habit of cooperation in their work flowed over into other domains.\n\nList leverages this story into one of scaling up workplace cultures. How the organisation works will affect the values underlying that organisation.\n\nThis leads to the case of Uber and Travis Kalanick. The story in a nutshell was that a series of scandals in early 2017 - claims of sexism and sexual harassment, a lawsuit by Waymo alleging the theft of trade secrets, video of Kalanick berating an Uber driver who challenged him on driver compensation, and most damaging, the revelation of software designed to evade law enforcement and regulators - ultimately led to Kalanick resigning as CEO.\n\nList pins this on \n\nThrough the chapter on scaling culture, the story that ended with Travis  Uber v Lyft market capitalisation. \n\nIt's a nice story, but I do find it amusing hearing a story about how the $XXb market cap company does things better than the $XXb market cap company. Kalanick is worth $XXb. There's a lot of \"halo effect\" story telling going on here - problems emerge, must have been the culture, a disaster waiting to happen. And yet by the clearly measurable outcome, Uber is a massive success for Kalanick. It reminds me of those criticizing the range of choice on Amazon of paralysing consumers with choice\n\nAll said - and re-reading above what seems like a critical review - there is a lot to like in the book and I think some good advice. I'm just not sure all of it is true. The \n\n## Other thoughts lying around\n\n- In his discussion of confirmation bias as a reason why false positives can cause such problems, List states \"Because we have limited brainpower to process all of this, we use mental shortcuts to make quick, often gut-level decisions. One such mental shortcut is to essentially filter out or ignore the information that is inconsistent with our expectations or assumptions.\" That second sentence is almost the opposite of perceptual control theory / predictive processing, which is based on the idea that our brain responds to differences from our expectations.\n\n- List states: \"If that suggestion sounds outrageous, consider an explosive study conducted by researchers at Johns Hopkins Medicine in 2016, which estimated that more than 250,000 Americans die each year from medical errors, making such errors the third-leading cause of death behind heart disease and cancer!\" This stat is dodgy at best. [Make link]\n\n- List writes: \"K&T quote - search for word \"harebrained\"\n\n- List jumps on the diversity bandwagon: \"I mean diversity in all senses: race, sex, age, ethnicity, religion, class background, sexual orientation, gender identity, neurotype, and other characteristics. Diversity in people’s backgrounds equates to cognitive diversity when they are together, which produces not just greater innovation but also greater resilience.\" List wants all these types of diversity to achieve \"cognitive diversity\", but doesn't mention cognitive diversity itself. We could measure it! And as usual, you almost never see \"political views\" on the list. Among the many disciplines and groups I have worked with during my career (law, economics, data science, regulators, policy advisers, environmental campaigners), the behavioural scientists/economists would be the most cognitively uniform group of the lot.\n\nGive me code to show a Venn diagram illustrating the link between human and machine intelligence:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(VennDiagram)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in library(VennDiagram): there is no package called 'VennDiagram'\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# create diagram\n\nvenn.diagram(\n\nx = list(\n\n\"Human\n\nIntelligence\" = 1,\n\n\"Machine\n\nIntelligence\" = 1,\n\n\"Human + Machine\n\nIntelligence\" = 1\n\n),\n\nfilename = \"venn_diagram.png\",\n\noutput = TRUE,\n\nimagetype = \"png\",\n\nheight = 480,\n\nwidth = 480,\n\nunits = \"px\",\n\ncol = \"transparent\",\n\nfill = c(\"cornflowerblue\", \"green\", \"yellow\"),\n\nalpha = c(0.5, 0.5, 0.5),\n\nlabel.col = c(\"orange\", \"white\", \"darkblue\"),\n\ncex = 1.5,\n\nfontfamily = \"serif\",\n\ncat.col = c(\"darkblue\", \"darkgreen\", \"orange\"),\n\ncat.cex = 1.5,\n\ncat.fontfamily = \"serif\",\n\ncat.default.pos = \"outer\",\n\ncat.pos = c(0, 180, 45),\n\ncat.dist = c(0.03, 0.03, 0.03),\n\nrotation.degree = 0,\n\nind = TRUE,\n\next.text = TRUE,\n\next.line = 1.5,\n\next.dist = -0.05,\n\next.length = 0.8,\n\next.line.lwd = 2,\n\next.line.lty = \"dashed\",\n\next.line.col = \"darkblue\",\n\nlwd = 2,\n\nlty = \"dashed\",\n\nline.lty = \"dashed\",\n\nline.lwd = 2,\n\nline.col = \"darkblue\",\n\nfill.alpha = c(0.5, 0.5, 0.5),\n\nscaled = TRUE,\n\nmargin = 0.05,\n\nmain = \"Venn diagram\",\n\nsub = \"Human and machine intelligence\",\n\nsub.cex = 1.5,\n\nsub.col = \"darkblue\",\n\nnewpage = TRUE\n\n)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in venn.diagram(x = list(`Human\\n\\nIntelligence` = 1, `Machine\\n\\nIntelligence` = 1, : could not find function \"venn.diagram\"\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}