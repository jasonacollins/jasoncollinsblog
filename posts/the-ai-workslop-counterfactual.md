---
title: "The AI workslop counterfactual"
author: "Jason Collins"
date: 2025-10-27 09:00:00+11:00
draft: true
aliases:
  - /the-ai-workslop-counterfactual
---

Amidst the debates about whether large language models are world changing or a bust, we get the occassional snippet of real-world data. These are inevitably accompanied by an eye-catching headline (e.g. [MIT report: 95% of generative AI pilots at companies are failing](https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/)) and a less-than-robust methodology (based on 52 structured interviews at conferences, analysis of 300+ public AI initiatives and surveys with 153 leaders). There's something to be learned from these reports, but the headline isn't it.

A recent entry into this genre of eye-catching with questionable research methodology is a Harvard Business Review article [AI-Generated "Workslop" is Destroying Productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity). Workslop is "AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task".

The authors provide some numbers to highlight the costs. Forty percent of survey respondents had received workslop in the last month. Fifteen percent of the work they receive is workslop. Price in the estimated almost two hours each respondent spends dealing with workshop and that's $186 per employee per month, or $9 million per year for a 10,000 worker organisation. (That 10% of respondents said receiving workslop made them think of their colleagues as each of more creative, capable, reliable, trustworthy and intelligent also suggests some survey respondent slop.)

So how did the authors come to these conclusions? To start, let's look at the survey (which at the time of posting was available [online](https://stanforduniversity.qualtrics.com/jfe/form/SV_4Mjwa0jWw2Pu3TE) for you to take.) The survey was completed by 1,150 US-based full-time employees who self-selected into completing the survey

The first substantive quesitons asks:

> Have you received work content that you believe is AI-generated that looks like it  completes a task at work, but is actually unhelpful, low quality, and/or seems like  the sender didn't put in enough effort?

You are asked how much of the work you received from colleagues fits that description. After being asked who it was from and some details, the repsondent is then asked how much time it took to deal with this work. Later, after some questions on feelings and mental effort, respondents are aslled hopw much time they have spent in the last month dealign with workslop.

The question that immediately comes to mind is what is the counterfactual. Even if these workslop figures are correct, how much 

Was the AI workslop better than what would be delivered. 

(As an academic with many students with English as a second language is that when students have in AI assignment slop, at least it's readable.)

AI workslop might even have advantages. Rather than waiting weeks to realise you are going to be served rubbish, you might get the signal faster, allowing you to get someone else to step in or at least update how much effort you have to do yourself.

The self selection

