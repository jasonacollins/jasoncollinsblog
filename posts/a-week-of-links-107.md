---
title: 'A week of links'
author: "Jason Collins"
date: 2025-09-05 16:00:00+10:00
draft: false
images: [""]
---
This week, language, language models and replication:

1. [How To Become A Mechanistic Interpretability Researcher](https://www.neelnanda.io/mechanistic-interpretability/getting-started): So much great material in here, even if you're just interested in getting across LLM foundations.

2. From that list, [ARENA's AI Safety course](https://www.arena.education/curriculum) is fantastic - again, even if you are just interested in LLM foundations.

3. [Do Machine Learning Models Memorize or Generalize?](https://pair.withgoogle.com/explorables/grokking/): A great explainer on grokking.

4. After hearing it mentioned on [Dwarkesh's podcast episode](https://www.dwarkesh.com/p/sholto-douglas-trenton-bricken) with Sholto Douglas and Trenton Bricken, I've been reading [The Symbolic Species by Terrence Deacon](https://www.dwarkesh.com/p/symbolic-species). I've learnt a lot about language, although I must admit that my eyes glaze over (as always) during the extended discussion of brain parts. Definitely worth the read (and listen to the podcast episode too).

5. [On the process and value of direct close replications: A rejoinder to Shafir and Cheekâ€™s (2024) commentary on Chandrashekar et al. (2021)](https://www.cambridge.org/core/journals/judgment-and-decision-making/article/on-the-process-and-value-of-direct-close-replications-a-rejoinder-to-shafir-and-cheeks-2024-commentary-on-chandrashekar-et-al-2021/024729A4F4D39748587CEEFC1F5C327C): So often failures to replicate experimental results are met with a load of waffle about context, precise experimental conduct and the like. Shafir and Cheek provided one such example. Chandrashekar and Gilad Feldman provide a fantastic response.