---
title: "Ariely's The Honest Truth About Dishonesty"
author: "Jason Collins"
date: 2016-04-22 09:00:51+00:00
draft: false
aliases:
  - /arielys-the-honest-truth-about-dishonesty
---

I rate the third of Dan Ariely's books, *The Honest Truth About Dishonesty: How We Lie to Everyone - Especially Ourselves*, somewhere between his first two books.

One of the strengths of Ariely's books is that he is largely writing about his own experiments, and not simply scraping through the same barrel as every other pop behavioural science author. The Honest Truth has a smaller back catalogue of experiments to draw from than [Predictably Irrational](https://www.jasoncollins.blog/arielys-predictably-irrational/), so it sometimes meanders in the same way as [The Upside of Irrationality](https://www.jasoncollins.blog/arielys-upside-irrationality/). But the thread that ties The Honest Truth together - how and why we cheat - and Ariely's investigations into it gave those extended riffs more substance than the story telling that filled some parts of The Upside.

The basic story of the book is that we like to see ourselves as honest, but are quite willing and able to indulge in a small amount of cheating where we can rationalise it. This amount of cheating is quite flexible based on situational factors, such as what other people are doing, and is not purely the result of a cost-benefit calculation.

The experiment that crops up again and again through the book is a task to find numbers in a series of matrices. People then shred the answers before collecting payment based on how many the completed. Most people cheat a little, possibly because they can rationalise that they could have solved more, or had almost completed the next one. Few cheat to the maximum, even when it is clear they have the opportunity to do so.

For much of the first part of the book, Ariely frames his research against the Simple Model of Rational Crime (or 'SMORC') - where people do a rational cost-benefit analysis as to whether to commit the crime. He shows experiments where people don't cheat to the maximum amount when they have no chance of being caught - almost no-one says that they solved all the puzzles (amusingly, a few say they solved 20 out of 20, but no-one says 18 or 19). And most people do not increase their level of cheating when the potential gains increase.

As Ariely works through the various experiments attempting to isolate parts of the SMORC and show they don't hold, I never felt fully satisfied. It is always possible to see how people might rationally respond in a way that thwarts the experimental design.

For example, Ariely found that changes in the stake with no change in enforcement did not result in an increase in cheating. But if I am in an environment with more money, I might assume there is more monitoring and enforcement, even if I can't see it. However, I believe Ariely is right in arguing that the decision is not a pure cost-benefit analysis.

One of the more interesting parts of the book concerned how increasing the degrees of separation from the monetary outcome increases cheating. Having people collect tokens, which could be later exchanged for cash, increased cheating. In that light, a decision to cheat in an area such as financial services, where the ultimate cost is cash but there are many degrees of separation (e.g. manipulating an interest rate benchmark which changes the price I get on a trade which affects my profit and loss which affects the size of my bonus), might not feel like cheating at all.

As is the case when I read any behavioural science book, the part that leaves me slightly cold is that I'm not sure I can trust some of the results. The recent replication failures involving priming and [ego depletion](/failure-to-replicate-ego-depletion-edition/) - and both phenomena feature in the book - resulted in me taking some of the results with a grain of salt. How many will stand the test of time? \[Update: not so well. See [here](/does-a-moral-reminder-decrease-cheating/) and [here](/a-default-of-disbelief/) for examples.\]
